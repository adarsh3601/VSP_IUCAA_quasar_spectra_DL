{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d54333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColDefs(\n",
      "    name = 'RA'; format = 'D'\n",
      "    name = 'DEC'; format = 'D'\n",
      "    name = 'PLATE'; format = 'J'\n",
      "    name = 'FIBER'; format = 'J'\n",
      "    name = 'MJD'; format = 'J'\n",
      "    name = 'ZQSO'; format = 'E'\n",
      "    name = 'ERR_ZQSO'; format = 'E'\n",
      "    name = 'INDEX_QSO'; format = 'J'\n",
      "    name = 'SPEC_SNR_MEDIAN'; format = 'E'\n",
      "    name = 'MED_SDEVIATION_RED'; format = 'E'\n",
      "    name = 'MED_SDEVIATION_BLUE'; format = 'E'\n",
      "    name = 'NABS'; format = 'J'\n",
      "    name = 'ZABS'; format = '10E'\n",
      "    name = 'ERR_ZABS'; format = '10E'\n",
      "    name = 'VDISP'; format = '10E'\n",
      "    name = 'ERR_VDISP'; format = '10E'\n",
      "    name = 'CRITERION_MGII'; format = '10B'\n",
      "    name = 'CRITERION_MGII_FEII'; format = '10B'\n",
      "    name = 'CRITERION_FEII'; format = '10B'\n",
      "    name = 'SIGNAL_MGII_2803'; format = '10E'\n",
      "    name = 'SIGNAL_MGII_2796'; format = '10E'\n",
      "    name = 'SNR_MGII_2803'; format = '10E'\n",
      "    name = 'SNR_MGII_2796'; format = '10E'\n",
      "    name = 'REW_MGI_2853'; format = '10E'\n",
      "    name = 'ERR_REW_MGI_2853'; format = '10E'\n",
      "    name = 'REW_MGII_2803'; format = '10E'\n",
      "    name = 'ERR_REW_MGII_2803'; format = '10E'\n",
      "    name = 'REW_MGII_2796'; format = '10E'\n",
      "    name = 'ERR_REW_MGII_2796'; format = '10E'\n",
      "    name = 'REW_FEII_2600'; format = '10E'\n",
      "    name = 'ERR_REW_FEII_2600'; format = '10E'\n",
      "    name = 'REW_FEII_2586'; format = '10E'\n",
      "    name = 'ERR_REW_FEII_2586'; format = '10E'\n",
      "    name = 'REW_FEII_2383'; format = '10E'\n",
      "    name = 'ERR_REW_FEII_2383'; format = '10E'\n",
      "    name = 'REW_FEII_2374'; format = '10E'\n",
      "    name = 'ERR_REW_FEII_2374'; format = '10E'\n",
      "    name = 'REW_FEII_2344'; format = '10E'\n",
      "    name = 'ERR_REW_FEII_2344'; format = '10E'\n",
      "    name = 'VDISP_MGI_2853'; format = '10E'\n",
      "    name = 'ERR_VDISP_MGI_2853'; format = '10E'\n",
      "    name = 'VDISP_MGII_2803'; format = '10E'\n",
      "    name = 'ERR_VDISP_MGII_2803'; format = '10E'\n",
      "    name = 'VDISP_MGII_2796'; format = '10E'\n",
      "    name = 'ERR_VDISP_MGII_2796'; format = '10E'\n",
      "    name = 'VDISP_FEII_2600'; format = '10E'\n",
      "    name = 'ERR_VDISP_FEII_2600'; format = '10E'\n",
      "    name = 'VDISP_FEII_2586'; format = '10E'\n",
      "    name = 'ERR_VDISP_FEII_2586'; format = '10E'\n",
      "    name = 'VDISP_FEII_2383'; format = '10E'\n",
      "    name = 'ERR_VDISP_FEII_2383'; format = '10E'\n",
      "    name = 'VDISP_FEII_2374'; format = '10E'\n",
      "    name = 'ERR_VDISP_FEII_2374'; format = '10E'\n",
      "    name = 'VDISP_FEII_2344'; format = '10E'\n",
      "    name = 'ERR_VDISP_FEII_2344'; format = '10E'\n",
      ")\n",
      "26761\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "hdul1 = fits.open('QSObased_Trimmed_SDSS_DR7_107.fits')\n",
    "print(hdul1[1].columns)\n",
    "Ra1 = hdul1[1].data['RA']\n",
    "DEC1 = hdul1[1].data['DEC']\n",
    "Plate1 = hdul1[1].data['PLATE']\n",
    "Fiber1 = hdul1[1].data['FIBER']\n",
    "MJD1 = hdul1[1].data['MJD']\n",
    "Zabs = hdul1[1].data['ZABS']\n",
    "Nabs = hdul1[1].data['NABS']\n",
    "Zqso1 = hdul1[1].data['ZQSO']\n",
    "Rew_2796 = hdul1[1].data['REW_MGII_2796']\n",
    "err_Rew_2796 = hdul1[1].data['ERR_REW_MGII_2796']\n",
    "Rew_2803 = hdul1[1].data['REW_MGII_2803']\n",
    "err_Rew_2803 = hdul1[1].data['ERR_REW_MGII_2803']\n",
    "sig_2803 = hdul1[1].data['SIGNAL_MGII_2803']\n",
    "print(len(MJD1))\n",
    "from astropy.io import fits\n",
    "hdul2 = fits.open('./Searched_Quasars_SDSS_DR7_107.fits')\n",
    "#print(hdul2[1].columns)\n",
    "Ra2 = hdul2[1].data['RA']\n",
    "DEC2 = hdul2[1].data['DEC']\n",
    "Plate2 = hdul2[1].data['PLATE']\n",
    "Fiber2 = hdul2[1].data['FIBER']\n",
    "MJD2 = hdul2[1].data['MJD']\n",
    "Zqso2 = hdul2[1].data['ZQSO']\n",
    "#print(len(MJD2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80eb267b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 3, 1,\n",
       "       3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 2, 2, 2, 3, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nabs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf97f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "Plate1 = list(Plate1)\n",
    "Fiber1 = list(Fiber1)\n",
    "for i in range(len(MJD1)):\n",
    "    if len(str(Plate1[i]))==3:\n",
    "        Plate1[i] = '0'+str(Plate1[i])\n",
    "    if len(str(Fiber1[i]))==3:\n",
    "        Fiber1[i] = '0'+str(Fiber1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fb8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "Plate2 = list(Plate2)\n",
    "Fiber2 = list(Fiber2)\n",
    "for i in range(len(MJD2)):\n",
    "    if len(str(Plate2[i]))==3:\n",
    "        Plate2[i] = '0'+str(Plate2[i])\n",
    "    if len(str(Fiber2[i]))==3:\n",
    "        Fiber2[i] = '0'+str(Fiber2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a4c889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for i in range(len(MJD2)):\n",
    "    if len(str(Plate2[i]))==3 or len(str(Fiber2[i]))==3:\n",
    "        k=k+1\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79019964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for i in range(len(MJD1)):\n",
    "    if len(str(Plate1[i]))==3 or len(str(Fiber1[i]))==3:\n",
    "        k=k+1\n",
    "        \n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6f9fa",
   "metadata": {},
   "source": [
    "# Removing narrow abosorbtion lines using criteria $ EW> 3*\\sigma_{EW}$  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85f532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5881857ad73846b78640e01f17f8c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26761\n",
      "1780\n",
      "25010\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "path = []\n",
    "discard = []\n",
    "for i in tqdm(range(len(MJD1))):\n",
    "    path.append('spec-'+str(Plate1[i])+ '-' +str(MJD1[i])+ '-'+str(Fiber1[i])+'.fits')\n",
    "    for j in range(len(Rew_2796[i])):\n",
    "        if Rew_2796[i][j] < 3*err_Rew_2796[i][j] and Rew_2803[i][j] < 3*err_Rew_2803[i][j]:\n",
    "                   name = 'spec-'+str(Plate1[i])+ '-' +str(MJD1[i])+ '-'+str(Fiber1[i])+'.fits'\n",
    "                   discard.append(name)\n",
    "\n",
    "print(len(path))\n",
    "print(len(discard))\n",
    "ew_checked = list(set(path) - set(discard))\n",
    "print(len(ew_checked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d42c022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b5bb79f49345f68cbf35de6ac1a52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8194\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "fits_files = []\n",
    "list_dir = os.listdir('run2/mg2/')\n",
    "for i in tqdm(ew_checked):\n",
    "    for j in list_dir:\n",
    "        if i == j:\n",
    "            fits_files.append(j)\n",
    "           \n",
    "print(len(fits_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1095f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21947\n",
      "15235\n",
      "8194\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files_non = os.listdir('run2/JHU-2/')\n",
    "print(len(files_non))\n",
    "fits_files2 = list(set(files_non)-set(list_dir))\n",
    "print(len(fits_files2))\n",
    "fits_files2 = fits_files2[:len(fits_files)]\n",
    "print(len(fits_files2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8764a2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadc4786e84b4073a549900f5ea2bc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8194\n"
     ]
    }
   ],
   "source": [
    "list_Z_emi1 = []\n",
    "\n",
    "for i in tqdm(range(len(MJD1))):\n",
    "    for j in fits_files:\n",
    "        if 'spec-'+str(Plate1[i])+ '-' +str(MJD1[i])+ '-'+str(Fiber1[i])+'.fits' == j :\n",
    "            list_Z_emi1.append(Zqso1[i])\n",
    "print(len(list_Z_emi1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c88fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17eda878a9c24e76957a09542c946843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6986\n"
     ]
    }
   ],
   "source": [
    "list_Z_emi2 = []\n",
    "list_Z = []\n",
    "for i in tqdm(range(len(MJD2))):\n",
    "    for j in fits_files2:\n",
    "        if 'spec-'+str(Plate2[i])+ '-' +str(MJD2[i])+ '-'+str(Fiber2[i])+'.fits' == j :\n",
    "            list_Z_emi2.append(Zqso2[i])    \n",
    "            list_Z.append(j)\n",
    "print(len(list_Z_emi2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34a0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_files = fits_files[:len(list_Z)]\n",
    "list_Z_emi1 = list_Z_emi1[:len(fits_files)]\n",
    "fits_files2 = list_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a2ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c661f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f7bf550a80486e9ea73a9f4dfbaffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_7688\\3816170317.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  specs.append(np.array(X)/np.array(Y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6986 6986 0\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "specs = []\n",
    "waves = []\n",
    "\n",
    "unchanged = 0\n",
    "\n",
    "for f in tqdm(range(len(fits_files))):\n",
    "    spectra = fits.open('run2/mg2/'+ fits_files[f] )\n",
    "    wave = 10**spectra[1].data['loglam']\n",
    "    flux = spectra[1].data['flux']\n",
    "    model = spectra[1].data['model']\n",
    "    if list_Z_emi1[f] <=1:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 4250 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "    \n",
    "    elif 1< list_Z_emi1[f] <= 1.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 3100 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    elif 1.8< list_Z_emi1[f] <= 2.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 2250 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    elif 2.8< list_Z_emi1[f] <= 4.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 1500 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    else:\n",
    "        unchanged = unchanged + 1\n",
    "        specs.append(flux/model)\n",
    "        waves.append(wave)\n",
    "    \n",
    "print(len(specs), len(waves), unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41c7279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd87fa14d18a46f7a5f434b7cc0a89ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6986 6986 0\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "specs2 = []\n",
    "waves2 = []\n",
    "\n",
    "unchanged2 = 0\n",
    "\n",
    "for f in tqdm(range(len(fits_files2))):\n",
    "    spectra = fits.open('run2/JHU-2/'+ fits_files2[f] )\n",
    "    wave = 10**spectra[1].data['loglam']\n",
    "    flux = spectra[1].data['flux']\n",
    "    model = spectra[1].data['model']\n",
    "    if list_Z_emi1[f] <=1:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 4250 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "    \n",
    "    elif 1< list_Z_emi1[f] <= 1.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 3100 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "        \n",
    "    elif 1.8< list_Z_emi1[f] <= 2.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 2250 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "        \n",
    "    elif 2.8< list_Z_emi1[f] <= 4.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 1500 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "        \n",
    "    else:\n",
    "        unchanged2 = unchanged2 + 1\n",
    "        specs2.append(flux/model)\n",
    "        waves2.append(wave)\n",
    "    \n",
    "print(len(specs2), len(waves2), unchanged2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc704f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba24f00eed3446db5ead65958b523c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6975 6975 0\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "specs = []\n",
    "waves = []\n",
    "\n",
    "\n",
    "unchanged = 0\n",
    "\n",
    "for f in tqdm(range(len(fits_files))):\n",
    "    spectra = fits.open('run2/mg2/'+ fits_files[f] )\n",
    "    wave = 10**spectra[1].data['loglam']\n",
    "    flux = spectra[1].data['flux']\n",
    "    model = spectra[1].data['model']\n",
    "    if list_Z_emi1[f] <=1:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 4250 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "    \n",
    "    elif 1< list_Z_emi1[f] <= 1.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 3100 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    elif 1.8< list_Z_emi1[f] <= 2.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 2250 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803:\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    elif 2.8< list_Z_emi1[f] <= 4.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 1500 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803:\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    else:\n",
    "        unchanged = unchanged + 1\n",
    "        specs.append(flux/model)\n",
    "        waves.append(wave)\n",
    "    \n",
    "print(len(specs), len(waves), unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "642fa713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b22908091a9451fabc423ed6d166fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6975 6975 0\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "specs2 = []\n",
    "waves2 = []\n",
    "\n",
    "unchanged2 = 0\n",
    "\n",
    "for f in tqdm(range(len(fits_files2))):\n",
    "    spectra = fits.open('run2/JHU-2/'+ fits_files2[f] )\n",
    "    wave = 10**spectra[1].data['loglam']\n",
    "    flux = spectra[1].data['flux']\n",
    "    model = spectra[1].data['model']\n",
    "    if list_Z_emi1[f] <=1:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 4250 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803:\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "    \n",
    "    elif 1< list_Z_emi1[f] <= 1.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 3100 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803:\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "        \n",
    "    elif 1.8< list_Z_emi1[f] <= 2.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 2250 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803:\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "        \n",
    "    elif 2.8< list_Z_emi1[f] <= 4.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 1500 and wave[i]> list_Z_emi1[f]*1216 and wave[i] < list_Z_emi1[f]*2803:\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs2.append(np.array(X)/np.array(Y))\n",
    "        waves2.append(Z)\n",
    "        \n",
    "    else:\n",
    "        unchanged2 = unchanged2 + 1\n",
    "        specs2.append(flux/model)\n",
    "        waves2.append(wave)\n",
    "    \n",
    "print(len(specs2), len(waves2), unchanged2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1a63694",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_files = []\n",
    "list_Z_emi1 = []\n",
    "fits_files2 = []\n",
    "list_Z = []\n",
    "waves = []\n",
    "waves2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb331d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6975 6975\n"
     ]
    }
   ],
   "source": [
    "X = specs+specs2\n",
    "Y = waves + waves2\n",
    "print(len(specs),len(waves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff449580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b1cd300400>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(waves[0], specs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6d9d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(waves[2]), len(specs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29a33eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = [i for i in specs if (i != 0).all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbce7f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91766\\AppData\\Local\\Temp\\ipykernel_17416\\1761564204.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  X.remove(i)\n",
      "C:\\Users\\91766\\AppData\\Local\\Temp\\ipykernel_17416\\1761564204.py:5: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  X.remove(i)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "k =0\n",
    "X_temp = X\n",
    "for i in tqdm(X):\n",
    "    if len(i)==0:\n",
    "        X.remove(i)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f41e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74a1ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1967\n",
      "2873\n",
      "2884\n",
      "2337\n",
      "2229\n",
      "3554\n",
      "3130\n",
      "2776\n",
      "3365\n",
      "2512\n",
      "2570\n",
      "3267\n",
      "2635\n",
      "2381\n",
      "1678\n",
      "1822\n",
      "2601\n",
      "1584\n",
      "1585\n",
      "3627\n",
      "2028\n",
      "2112\n",
      "2029\n",
      "2006\n",
      "1505\n",
      "3214\n",
      "3627\n",
      "1832\n",
      "1853\n",
      "2549\n",
      "3585\n",
      "1732\n",
      "1532\n",
      "1689\n",
      "2729\n",
      "1999\n",
      "2652\n",
      "1968\n",
      "2205\n",
      "2461\n",
      "1829\n",
      "1509\n",
      "2898\n",
      "1730\n",
      "1892\n",
      "2370\n",
      "2286\n",
      "1912\n",
      "1521\n",
      "1543\n",
      "2172\n",
      "3626\n",
      "1786\n",
      "2127\n",
      "2882\n",
      "3332\n",
      "2220\n",
      "3158\n",
      "1794\n",
      "1755\n",
      "1958\n",
      "1698\n",
      "2940\n",
      "2392\n",
      "1868\n",
      "2177\n",
      "1875\n",
      "2421\n",
      "2767\n",
      "1760\n",
      "3381\n",
      "1899\n",
      "1671\n",
      "3365\n",
      "1694\n",
      "2054\n",
      "2706\n",
      "1858\n",
      "1874\n",
      "3265\n",
      "2716\n",
      "3525\n",
      "1505\n",
      "1814\n",
      "3567\n",
      "1571\n",
      "2350\n",
      "1960\n",
      "3201\n",
      "1802\n",
      "2158\n",
      "1663\n",
      "1586\n",
      "1647\n",
      "3551\n",
      "2613\n",
      "1778\n",
      "2281\n",
      "2275\n",
      "2131\n",
      "3244\n",
      "3185\n",
      "3244\n",
      "2405\n",
      "2702\n",
      "1771\n",
      "1905\n",
      "1570\n",
      "1718\n",
      "2317\n",
      "1540\n",
      "1771\n",
      "1768\n",
      "2149\n",
      "2225\n",
      "2076\n",
      "1546\n",
      "1585\n",
      "2239\n",
      "2350\n",
      "1821\n",
      "2658\n",
      "2155\n",
      "2640\n",
      "2059\n",
      "2005\n",
      "2898\n",
      "1768\n",
      "3058\n",
      "2019\n",
      "2680\n",
      "1506\n",
      "1599\n",
      "1829\n",
      "2052\n",
      "1994\n",
      "1870\n",
      "2046\n",
      "1625\n",
      "2646\n",
      "2282\n",
      "2709\n",
      "1609\n",
      "2059\n",
      "3590\n",
      "1600\n",
      "1772\n",
      "1760\n",
      "1974\n",
      "2730\n",
      "3565\n",
      "2224\n",
      "2806\n",
      "2388\n",
      "1665\n",
      "2514\n",
      "2381\n",
      "1981\n",
      "2086\n",
      "2168\n",
      "2093\n",
      "2947\n",
      "2668\n",
      "2679\n",
      "1682\n",
      "1693\n",
      "1569\n",
      "1580\n",
      "1697\n",
      "1625\n",
      "2693\n",
      "2642\n",
      "1663\n",
      "2093\n",
      "2089\n",
      "2848\n",
      "2527\n",
      "3103\n",
      "1785\n",
      "2743\n",
      "1733\n",
      "2311\n",
      "2731\n",
      "2268\n",
      "1813\n",
      "3032\n",
      "2045\n",
      "2969\n",
      "3234\n",
      "2074\n",
      "1762\n",
      "1629\n",
      "2261\n",
      "2557\n",
      "2923\n",
      "2138\n",
      "2876\n",
      "1948\n",
      "2659\n",
      "2644\n",
      "2762\n",
      "2386\n",
      "2468\n",
      "2167\n",
      "1762\n",
      "2017\n",
      "2319\n",
      "1527\n",
      "2672\n",
      "1990\n",
      "2407\n",
      "2772\n",
      "1514\n",
      "1776\n",
      "1604\n",
      "2273\n",
      "1940\n",
      "1773\n",
      "2622\n",
      "2657\n",
      "1561\n",
      "1586\n",
      "3062\n",
      "2750\n",
      "2646\n",
      "2613\n",
      "1554\n",
      "3627\n",
      "2209\n",
      "2059\n",
      "3098\n",
      "1525\n",
      "3073\n",
      "2604\n",
      "1559\n",
      "2817\n",
      "2103\n",
      "3503\n",
      "3117\n",
      "2642\n",
      "3137\n",
      "1519\n",
      "2174\n",
      "1532\n",
      "2436\n",
      "1881\n",
      "3050\n",
      "2291\n",
      "2399\n",
      "3171\n",
      "2746\n",
      "1961\n",
      "2076\n",
      "1816\n",
      "2820\n",
      "1520\n",
      "1682\n",
      "2674\n",
      "1679\n",
      "1788\n",
      "2060\n",
      "2558\n",
      "1953\n",
      "1564\n",
      "3135\n",
      "3613\n",
      "1935\n",
      "3627\n",
      "2076\n",
      "1784\n",
      "1553\n",
      "1698\n",
      "1650\n",
      "2038\n",
      "2283\n",
      "3061\n",
      "1757\n",
      "2158\n",
      "1950\n",
      "2163\n",
      "3350\n",
      "1777\n",
      "1511\n",
      "1544\n",
      "1969\n",
      "2966\n",
      "2301\n",
      "1633\n",
      "3119\n",
      "1831\n",
      "1598\n",
      "3366\n",
      "2347\n",
      "2224\n",
      "2400\n",
      "1860\n",
      "3192\n",
      "3004\n",
      "2177\n",
      "2045\n",
      "1552\n",
      "2154\n",
      "2161\n",
      "1799\n",
      "2772\n",
      "2339\n",
      "1635\n",
      "1809\n",
      "1704\n",
      "2063\n",
      "1972\n",
      "1619\n",
      "1562\n",
      "1722\n",
      "3191\n",
      "1992\n",
      "2166\n",
      "2529\n",
      "2681\n",
      "1563\n",
      "1784\n",
      "1710\n",
      "1793\n",
      "3094\n",
      "2696\n",
      "2164\n",
      "1736\n",
      "1866\n",
      "2845\n",
      "2044\n",
      "1594\n",
      "1858\n",
      "3192\n",
      "1848\n",
      "2632\n",
      "2519\n",
      "2778\n",
      "2104\n",
      "3448\n",
      "1905\n",
      "1973\n",
      "2070\n",
      "1929\n",
      "2014\n",
      "1688\n",
      "1729\n",
      "1923\n",
      "2581\n",
      "2046\n",
      "2587\n",
      "3208\n",
      "1778\n",
      "1724\n",
      "2220\n",
      "3254\n",
      "2237\n",
      "2935\n",
      "2357\n",
      "1826\n",
      "3511\n",
      "2456\n",
      "1677\n",
      "2094\n",
      "1594\n",
      "1907\n",
      "3145\n",
      "2489\n",
      "2808\n",
      "2996\n",
      "3627\n",
      "2065\n",
      "2259\n",
      "2063\n",
      "2275\n",
      "2575\n",
      "1784\n",
      "1907\n",
      "2573\n",
      "1757\n",
      "1760\n",
      "3627\n",
      "1614\n",
      "3313\n",
      "1916\n",
      "1701\n",
      "2797\n",
      "1831\n",
      "1662\n",
      "2946\n",
      "2570\n",
      "1661\n",
      "3412\n",
      "1830\n",
      "1664\n",
      "3095\n",
      "1888\n",
      "1503\n",
      "1676\n",
      "2283\n",
      "2383\n",
      "2091\n",
      "1533\n",
      "1525\n",
      "1646\n",
      "1854\n",
      "3080\n",
      "1576\n",
      "1776\n",
      "2007\n",
      "2192\n",
      "1893\n",
      "1910\n",
      "2237\n",
      "2841\n",
      "1845\n",
      "3532\n",
      "2204\n",
      "2766\n",
      "1823\n",
      "2637\n",
      "2365\n",
      "1731\n",
      "2331\n",
      "3351\n",
      "2833\n",
      "2627\n",
      "2103\n",
      "1962\n",
      "1606\n",
      "2481\n",
      "2072\n",
      "1983\n",
      "2736\n",
      "1540\n",
      "1588\n",
      "2153\n",
      "3627\n",
      "2789\n",
      "2495\n",
      "2837\n",
      "3278\n",
      "1586\n",
      "2261\n",
      "2297\n",
      "1692\n",
      "1744\n",
      "2224\n",
      "3505\n",
      "2092\n",
      "3086\n",
      "1876\n",
      "1965\n",
      "2097\n",
      "2934\n",
      "1846\n",
      "1814\n",
      "2713\n",
      "2502\n",
      "1753\n",
      "3582\n",
      "2140\n",
      "2868\n",
      "1847\n",
      "1956\n",
      "2001\n",
      "3274\n",
      "2454\n",
      "3041\n",
      "3099\n",
      "2930\n",
      "2352\n",
      "2140\n",
      "2322\n",
      "2228\n",
      "3199\n",
      "3046\n",
      "1715\n",
      "2622\n",
      "3139\n",
      "3094\n",
      "3447\n",
      "3364\n",
      "2429\n",
      "1865\n",
      "1522\n",
      "1686\n",
      "2450\n",
      "3172\n",
      "1620\n",
      "2090\n",
      "1670\n",
      "1715\n",
      "1868\n",
      "2515\n",
      "1569\n",
      "2135\n",
      "2227\n",
      "2556\n",
      "2643\n",
      "3446\n",
      "2334\n",
      "2023\n",
      "2072\n",
      "2347\n",
      "2123\n",
      "2052\n",
      "1905\n",
      "1574\n",
      "1728\n",
      "3154\n",
      "2541\n",
      "1658\n",
      "2066\n",
      "2258\n",
      "1615\n",
      "2454\n",
      "2263\n",
      "3027\n",
      "3270\n",
      "2242\n",
      "2457\n",
      "1533\n",
      "2066\n",
      "2597\n",
      "2489\n",
      "2110\n",
      "1569\n",
      "2749\n",
      "2237\n",
      "3193\n",
      "3058\n",
      "2999\n",
      "2155\n",
      "2200\n",
      "3610\n",
      "3090\n",
      "1842\n",
      "1816\n",
      "3627\n",
      "1621\n",
      "2156\n",
      "1668\n",
      "2124\n",
      "3543\n",
      "2785\n",
      "1791\n",
      "2268\n",
      "3441\n",
      "1753\n",
      "1580\n",
      "1517\n",
      "2482\n",
      "1984\n",
      "1930\n",
      "1594\n",
      "3195\n",
      "2787\n",
      "2575\n",
      "2161\n",
      "1826\n",
      "1644\n",
      "2473\n",
      "1986\n",
      "2971\n",
      "3326\n",
      "2020\n",
      "1555\n",
      "1939\n",
      "2422\n",
      "2838\n",
      "2247\n",
      "3458\n",
      "2404\n",
      "1907\n",
      "1950\n",
      "2489\n",
      "1536\n",
      "2451\n",
      "2506\n",
      "1936\n",
      "1574\n",
      "2677\n",
      "2395\n",
      "2436\n",
      "1789\n",
      "1997\n",
      "2199\n",
      "2028\n",
      "2484\n",
      "1788\n",
      "2302\n",
      "2151\n",
      "2181\n",
      "1587\n",
      "1730\n",
      "2925\n",
      "2204\n",
      "3016\n",
      "2293\n",
      "2687\n",
      "1559\n",
      "1725\n",
      "3297\n",
      "2835\n",
      "3627\n",
      "3617\n",
      "1602\n",
      "2059\n",
      "2075\n",
      "1892\n",
      "1560\n",
      "3483\n",
      "1756\n",
      "1696\n",
      "1872\n",
      "1753\n",
      "1865\n",
      "1604\n",
      "2786\n",
      "1508\n",
      "2307\n",
      "2085\n",
      "2763\n",
      "1569\n",
      "1507\n",
      "3000\n",
      "1761\n",
      "3031\n",
      "1653\n",
      "1839\n",
      "1743\n",
      "1826\n",
      "1559\n",
      "2976\n",
      "1913\n",
      "1837\n",
      "1867\n",
      "1730\n",
      "2178\n",
      "2492\n",
      "2972\n",
      "2150\n",
      "1792\n",
      "2096\n",
      "1674\n",
      "1939\n",
      "2235\n",
      "1602\n",
      "3165\n",
      "2810\n",
      "1692\n",
      "1850\n",
      "2887\n",
      "1687\n",
      "1727\n",
      "2078\n",
      "3128\n",
      "3627\n",
      "3405\n",
      "3205\n",
      "2166\n",
      "3019\n",
      "1565\n",
      "1563\n",
      "1591\n",
      "2038\n",
      "1760\n",
      "2526\n",
      "1830\n",
      "3009\n",
      "3350\n",
      "1924\n",
      "2687\n",
      "1613\n",
      "3627\n",
      "1678\n",
      "1761\n",
      "2512\n",
      "1753\n",
      "2766\n",
      "2350\n",
      "3527\n",
      "1697\n",
      "2784\n",
      "2217\n",
      "2854\n",
      "1931\n",
      "1939\n",
      "2232\n",
      "3472\n",
      "1597\n",
      "2411\n",
      "2075\n",
      "3106\n",
      "1656\n",
      "1567\n",
      "2290\n",
      "1658\n",
      "2833\n",
      "2225\n",
      "2373\n",
      "1712\n",
      "2528\n",
      "1798\n",
      "3064\n",
      "2307\n",
      "2321\n",
      "2968\n",
      "2057\n",
      "1848\n",
      "3177\n",
      "2665\n",
      "1781\n",
      "1853\n",
      "1693\n",
      "2151\n",
      "1972\n",
      "1740\n",
      "1667\n",
      "2237\n",
      "3627\n",
      "2528\n",
      "2377\n",
      "2324\n",
      "1584\n",
      "2687\n",
      "2320\n",
      "2413\n",
      "2517\n",
      "1937\n",
      "1714\n",
      "2040\n",
      "1718\n",
      "3335\n",
      "1723\n",
      "2086\n",
      "1687\n",
      "1871\n",
      "1597\n",
      "3446\n",
      "1867\n",
      "2230\n",
      "3171\n",
      "1840\n",
      "1942\n",
      "3316\n",
      "3627\n",
      "3195\n",
      "3389\n",
      "2518\n",
      "3090\n",
      "3082\n",
      "2502\n",
      "2466\n",
      "1741\n",
      "3154\n",
      "2430\n",
      "3309\n",
      "2977\n",
      "2196\n",
      "3031\n",
      "2075\n",
      "1717\n",
      "2331\n",
      "2090\n",
      "3482\n",
      "3460\n",
      "2796\n",
      "2456\n",
      "3627\n",
      "1856\n",
      "1915\n",
      "1841\n",
      "1725\n",
      "2509\n",
      "2081\n",
      "2680\n",
      "1765\n",
      "3215\n",
      "1805\n",
      "2167\n",
      "1938\n",
      "3447\n",
      "2062\n",
      "1665\n",
      "1541\n",
      "3013\n",
      "2122\n",
      "2384\n",
      "1895\n",
      "2870\n",
      "3435\n",
      "1645\n",
      "3179\n",
      "2388\n",
      "1855\n",
      "2314\n",
      "1692\n",
      "2193\n",
      "1848\n",
      "2943\n",
      "2622\n",
      "3248\n",
      "1563\n",
      "3092\n",
      "1973\n",
      "1650\n",
      "2650\n",
      "1596\n",
      "1580\n",
      "2719\n",
      "2144\n",
      "2067\n",
      "2826\n",
      "1638\n",
      "2506\n",
      "1553\n",
      "1896\n",
      "2189\n",
      "2688\n",
      "3215\n",
      "2056\n",
      "3080\n",
      "3626\n",
      "1528\n",
      "1519\n",
      "3123\n",
      "2105\n",
      "1779\n",
      "3539\n",
      "2268\n",
      "3300\n",
      "2608\n",
      "1589\n",
      "2339\n",
      "1777\n",
      "3410\n",
      "1631\n",
      "1865\n",
      "3220\n",
      "2094\n",
      "1544\n",
      "1752\n",
      "1755\n",
      "1526\n",
      "2033\n",
      "1939\n",
      "3129\n",
      "3627\n",
      "1816\n",
      "1575\n",
      "1602\n",
      "1681\n",
      "2835\n",
      "1936\n",
      "2040\n",
      "1638\n",
      "1980\n",
      "3620\n",
      "1581\n",
      "2539\n",
      "2862\n",
      "1908\n",
      "1709\n",
      "3245\n",
      "2218\n",
      "2451\n",
      "1760\n",
      "1689\n",
      "2478\n",
      "1663\n",
      "1791\n",
      "2659\n",
      "1531\n",
      "1708\n",
      "1914\n",
      "1843\n",
      "2083\n",
      "1867\n",
      "2712\n",
      "2084\n",
      "2298\n",
      "1658\n",
      "2081\n",
      "1815\n",
      "1564\n",
      "1643\n",
      "1660\n",
      "2680\n",
      "1982\n",
      "2194\n",
      "2134\n",
      "1502\n",
      "2252\n",
      "2316\n",
      "2036\n",
      "2449\n",
      "3627\n",
      "1521\n",
      "2219\n",
      "2549\n",
      "2486\n",
      "3253\n",
      "1837\n",
      "3357\n",
      "2060\n",
      "2362\n",
      "1564\n",
      "1844\n",
      "1638\n",
      "2501\n",
      "2446\n",
      "1551\n",
      "3286\n",
      "2455\n",
      "3533\n",
      "1543\n",
      "1702\n",
      "2047\n",
      "2011\n",
      "1862\n",
      "1890\n",
      "1975\n",
      "1850\n",
      "3335\n",
      "1637\n",
      "1625\n",
      "3409\n",
      "1937\n",
      "1559\n",
      "3213\n",
      "3024\n",
      "1740\n",
      "1694\n",
      "2056\n",
      "1911\n",
      "3626\n",
      "3346\n",
      "1656\n",
      "1942\n",
      "2590\n",
      "2480\n",
      "1792\n",
      "2064\n",
      "1580\n",
      "2805\n",
      "1687\n",
      "2323\n",
      "2577\n",
      "2003\n",
      "3438\n",
      "2148\n",
      "2752\n",
      "3080\n",
      "2555\n",
      "3299\n",
      "1719\n",
      "2458\n",
      "2187\n",
      "1566\n",
      "1692\n",
      "2002\n",
      "3216\n",
      "2350\n",
      "1994\n",
      "1654\n",
      "3394\n",
      "3322\n",
      "2846\n",
      "1575\n",
      "1916\n",
      "1917\n",
      "1533\n",
      "2518\n",
      "2488\n",
      "2158\n",
      "1526\n",
      "1520\n",
      "1558\n",
      "1673\n",
      "1687\n",
      "1718\n",
      "1954\n",
      "1863\n",
      "1744\n",
      "2176\n",
      "2012\n",
      "2341\n",
      "2056\n",
      "1902\n",
      "3234\n",
      "2286\n",
      "3223\n",
      "1903\n",
      "3292\n",
      "1625\n",
      "2806\n",
      "1790\n",
      "2021\n",
      "3152\n",
      "3003\n",
      "1560\n",
      "1649\n",
      "1838\n",
      "1653\n",
      "1659\n",
      "2927\n",
      "3627\n",
      "3215\n",
      "2885\n",
      "2136\n",
      "2103\n",
      "2753\n",
      "2807\n",
      "1777\n",
      "3218\n",
      "2679\n",
      "3627\n",
      "2968\n",
      "1526\n",
      "3035\n",
      "2531\n",
      "2482\n",
      "2063\n",
      "1681\n",
      "3445\n",
      "1775\n",
      "1940\n",
      "1523\n",
      "1560\n",
      "1643\n",
      "3265\n",
      "3571\n",
      "1616\n",
      "1880\n",
      "1640\n",
      "3571\n",
      "3282\n",
      "2512\n",
      "3627\n",
      "3070\n",
      "2317\n",
      "2408\n",
      "1692\n",
      "3256\n",
      "2767\n",
      "2415\n",
      "1745\n",
      "1773\n",
      "3040\n",
      "2643\n",
      "3230\n",
      "3358\n",
      "3627\n",
      "2290\n",
      "1923\n",
      "2684\n",
      "2766\n",
      "1640\n",
      "1788\n",
      "1638\n",
      "3047\n",
      "1826\n",
      "2202\n",
      "1568\n",
      "2863\n",
      "1544\n",
      "2743\n",
      "2635\n",
      "2841\n",
      "1524\n",
      "1651\n",
      "2321\n",
      "3627\n",
      "2776\n",
      "1661\n",
      "2131\n",
      "2439\n",
      "2646\n",
      "2976\n",
      "1951\n",
      "1583\n",
      "2050\n",
      "1599\n",
      "1998\n",
      "2845\n",
      "2486\n",
      "1823\n",
      "1891\n",
      "2388\n",
      "2355\n",
      "1700\n",
      "1549\n",
      "2607\n",
      "1853\n",
      "2379\n",
      "1612\n",
      "1717\n",
      "2185\n",
      "3627\n",
      "2802\n",
      "2206\n",
      "1703\n",
      "1702\n",
      "1900\n",
      "1622\n",
      "2415\n",
      "1808\n",
      "2579\n",
      "2030\n",
      "1695\n",
      "3563\n",
      "2361\n",
      "2157\n",
      "2449\n",
      "3144\n",
      "2039\n",
      "1934\n",
      "3627\n",
      "3627\n",
      "2041\n",
      "1776\n",
      "1781\n",
      "2649\n",
      "2221\n",
      "2032\n",
      "2799\n",
      "1703\n",
      "1534\n",
      "1519\n",
      "1973\n",
      "2462\n",
      "3045\n",
      "3627\n",
      "1751\n",
      "3627\n",
      "1770\n",
      "1800\n",
      "2651\n",
      "2967\n",
      "2187\n",
      "3536\n",
      "1759\n",
      "3571\n",
      "1955\n",
      "1944\n",
      "1953\n",
      "1539\n",
      "1971\n",
      "2319\n",
      "1561\n",
      "3093\n",
      "1784\n",
      "2167\n",
      "2480\n",
      "1819\n",
      "2820\n",
      "2022\n",
      "1530\n",
      "1744\n",
      "2081\n",
      "2837\n",
      "1788\n",
      "1600\n",
      "2853\n",
      "3329\n",
      "1582\n",
      "1772\n",
      "3106\n",
      "3458\n",
      "1521\n",
      "3160\n",
      "3139\n",
      "1732\n",
      "2773\n",
      "2140\n",
      "2256\n",
      "2416\n",
      "3017\n",
      "2789\n",
      "2340\n",
      "1959\n",
      "1675\n",
      "3204\n",
      "1560\n",
      "2297\n",
      "3141\n",
      "1520\n",
      "1587\n",
      "1522\n",
      "1729\n",
      "2913\n",
      "1689\n",
      "2251\n",
      "2338\n",
      "1757\n",
      "1742\n",
      "1551\n",
      "1990\n",
      "1602\n",
      "2516\n",
      "3491\n",
      "1626\n",
      "2516\n",
      "1623\n",
      "1690\n",
      "1532\n",
      "1806\n",
      "1835\n",
      "1904\n",
      "2978\n",
      "1906\n",
      "1613\n",
      "1793\n",
      "1561\n",
      "2342\n",
      "1663\n",
      "1940\n",
      "1968\n",
      "1545\n",
      "2808\n",
      "2365\n",
      "3391\n",
      "1637\n",
      "1508\n",
      "1704\n",
      "2677\n",
      "3558\n",
      "1952\n",
      "3561\n",
      "1555\n",
      "1980\n",
      "2667\n",
      "1962\n",
      "1668\n",
      "1757\n",
      "1925\n",
      "3171\n",
      "3352\n",
      "1852\n",
      "3261\n",
      "2648\n",
      "2907\n",
      "1972\n",
      "2056\n",
      "3491\n",
      "3627\n",
      "2627\n",
      "3208\n",
      "1680\n",
      "2033\n",
      "1795\n",
      "3146\n",
      "1898\n",
      "3550\n",
      "3268\n",
      "3285\n",
      "2392\n",
      "1731\n",
      "2115\n",
      "3196\n",
      "1870\n",
      "2872\n",
      "1651\n",
      "2062\n",
      "2055\n",
      "3323\n",
      "1976\n",
      "1842\n",
      "1962\n",
      "2105\n",
      "2193\n",
      "2120\n",
      "3437\n",
      "1695\n",
      "1653\n",
      "3392\n",
      "1560\n",
      "2703\n",
      "1850\n",
      "2841\n",
      "1711\n",
      "1842\n",
      "3593\n",
      "2291\n",
      "2972\n",
      "3405\n",
      "2796\n",
      "1981\n",
      "1932\n",
      "1955\n",
      "1957\n",
      "1704\n",
      "2094\n",
      "2428\n",
      "1595\n",
      "1867\n",
      "1808\n",
      "1571\n",
      "2206\n",
      "1913\n",
      "3435\n",
      "1620\n",
      "2545\n",
      "3382\n",
      "1568\n",
      "2740\n",
      "2315\n",
      "2495\n",
      "1718\n",
      "1593\n",
      "1947\n",
      "3071\n",
      "1812\n",
      "2546\n",
      "1531\n",
      "1512\n",
      "1622\n",
      "2008\n",
      "1951\n",
      "1896\n",
      "2931\n",
      "1590\n",
      "3013\n",
      "2329\n",
      "1623\n",
      "1744\n",
      "3093\n",
      "1547\n",
      "1743\n",
      "2727\n",
      "2263\n",
      "1539\n",
      "1929\n",
      "1922\n",
      "1722\n",
      "3312\n",
      "1657\n",
      "2236\n",
      "1731\n",
      "2030\n",
      "2264\n",
      "2261\n",
      "1581\n",
      "2363\n",
      "2516\n",
      "1723\n",
      "1524\n",
      "1530\n",
      "2223\n",
      "2248\n",
      "1791\n",
      "2384\n",
      "1745\n",
      "1910\n",
      "2179\n",
      "1576\n",
      "1697\n",
      "1805\n",
      "1571\n",
      "1857\n",
      "2478\n",
      "1734\n",
      "2250\n",
      "1585\n",
      "1823\n",
      "2495\n",
      "1730\n",
      "1783\n",
      "2017\n",
      "1764\n",
      "2662\n",
      "1935\n",
      "1569\n",
      "1634\n",
      "1901\n",
      "2695\n",
      "3460\n",
      "2620\n",
      "1870\n",
      "2865\n",
      "2178\n",
      "2420\n",
      "2724\n",
      "2094\n",
      "2087\n",
      "1523\n",
      "1749\n",
      "2552\n",
      "1689\n",
      "2846\n",
      "1514\n",
      "1740\n",
      "2925\n",
      "1994\n",
      "2337\n",
      "3113\n",
      "1599\n",
      "2653\n",
      "3471\n",
      "2494\n",
      "1826\n",
      "3501\n",
      "3618\n",
      "2014\n",
      "2327\n",
      "2273\n",
      "3275\n",
      "2327\n",
      "3396\n",
      "3627\n",
      "2617\n",
      "1598\n",
      "3401\n",
      "2117\n",
      "3512\n",
      "3382\n",
      "2018\n",
      "2930\n",
      "1845\n",
      "1966\n",
      "2175\n",
      "1627\n",
      "1675\n",
      "2388\n",
      "1898\n",
      "1973\n",
      "2818\n",
      "1679\n",
      "2832\n",
      "1753\n",
      "1501\n",
      "3320\n",
      "2746\n",
      "1779\n",
      "2791\n",
      "1609\n",
      "3454\n",
      "1608\n",
      "3179\n",
      "2105\n",
      "3454\n",
      "1556\n",
      "2856\n",
      "1992\n",
      "2173\n",
      "3602\n",
      "1623\n",
      "2376\n",
      "1705\n",
      "1954\n",
      "3323\n",
      "1712\n",
      "2505\n",
      "1662\n",
      "2588\n",
      "2894\n",
      "2907\n",
      "1679\n",
      "1522\n",
      "1522\n",
      "1522\n",
      "2132\n",
      "1997\n",
      "1709\n",
      "1527\n",
      "2138\n",
      "2004\n",
      "2777\n",
      "2470\n",
      "1721\n",
      "1991\n",
      "2655\n",
      "2600\n",
      "2544\n",
      "1937\n",
      "1762\n",
      "1534\n",
      "1507\n",
      "2370\n",
      "1847\n",
      "2690\n",
      "1659\n",
      "3520\n",
      "2629\n",
      "2098\n",
      "2680\n",
      "2122\n",
      "1717\n",
      "1939\n",
      "2497\n",
      "3096\n",
      "2561\n",
      "1609\n",
      "3255\n",
      "3274\n",
      "1509\n",
      "2184\n",
      "3021\n",
      "3590\n",
      "1870\n",
      "1546\n",
      "3195\n",
      "2791\n",
      "1780\n",
      "3281\n",
      "1735\n",
      "2214\n",
      "1531\n",
      "2876\n",
      "2949\n",
      "3057\n",
      "1789\n",
      "1546\n",
      "2020\n",
      "2007\n",
      "3254\n",
      "2263\n",
      "1812\n",
      "3391\n",
      "1785\n",
      "1712\n",
      "3306\n",
      "2552\n",
      "1569\n",
      "2181\n",
      "2860\n",
      "2148\n",
      "2341\n",
      "1674\n",
      "1502\n",
      "2335\n",
      "2236\n",
      "2470\n",
      "3516\n",
      "3230\n",
      "1943\n",
      "1655\n",
      "3369\n",
      "1634\n",
      "2001\n",
      "2009\n",
      "2889\n",
      "2480\n",
      "2754\n",
      "2536\n",
      "1888\n",
      "1613\n",
      "2680\n",
      "3581\n",
      "3446\n",
      "1679\n",
      "1768\n",
      "2288\n",
      "1763\n",
      "2307\n",
      "2415\n",
      "2901\n",
      "1677\n",
      "1858\n",
      "2354\n",
      "1848\n",
      "1943\n",
      "1586\n",
      "1819\n",
      "3488\n",
      "1527\n",
      "1616\n",
      "2085\n",
      "1644\n",
      "2468\n",
      "2176\n",
      "3627\n",
      "3520\n",
      "1611\n",
      "1867\n",
      "1758\n",
      "2966\n",
      "3386\n",
      "1939\n",
      "2147\n",
      "3627\n",
      "3336\n",
      "1849\n",
      "1662\n",
      "1838\n",
      "1919\n",
      "2293\n",
      "2156\n",
      "2192\n",
      "3424\n",
      "1535\n",
      "1659\n",
      "3048\n",
      "1554\n",
      "2306\n",
      "2871\n",
      "2446\n",
      "2829\n",
      "3383\n",
      "2449\n",
      "3045\n",
      "3107\n",
      "1764\n",
      "2360\n",
      "1615\n",
      "3422\n",
      "1976\n",
      "1599\n",
      "1830\n",
      "2684\n",
      "2480\n",
      "2736\n",
      "1850\n",
      "1731\n",
      "2096\n",
      "1884\n",
      "2590\n",
      "1951\n",
      "3296\n",
      "1957\n",
      "3010\n",
      "2593\n",
      "1896\n",
      "3380\n",
      "1554\n",
      "2432\n",
      "1903\n",
      "2318\n",
      "3185\n",
      "1741\n",
      "1912\n",
      "1738\n",
      "2735\n",
      "2795\n",
      "1783\n",
      "2189\n",
      "1943\n",
      "2544\n",
      "2035\n",
      "1971\n",
      "1811\n",
      "1501\n",
      "1749\n",
      "2162\n",
      "2022\n",
      "1687\n",
      "3627\n",
      "2977\n",
      "1914\n",
      "2605\n",
      "1732\n",
      "3627\n",
      "1868\n",
      "1868\n",
      "3000\n",
      "1701\n",
      "2818\n",
      "1704\n",
      "1921\n",
      "2599\n",
      "2288\n",
      "3068\n",
      "3531\n",
      "1832\n",
      "2758\n",
      "2958\n",
      "3249\n",
      "1620\n",
      "2904\n",
      "2023\n",
      "1787\n",
      "2936\n",
      "1589\n",
      "1609\n",
      "2490\n",
      "1971\n",
      "1547\n",
      "2194\n",
      "3523\n",
      "2813\n",
      "2368\n",
      "3421\n",
      "1667\n",
      "2439\n",
      "2833\n",
      "1549\n",
      "1962\n",
      "1731\n",
      "1839\n",
      "1859\n",
      "2581\n",
      "2530\n",
      "3460\n",
      "3627\n",
      "1622\n",
      "1854\n",
      "3537\n",
      "3627\n",
      "1667\n",
      "2697\n",
      "2357\n",
      "1501\n",
      "3627\n",
      "3511\n",
      "1691\n",
      "3523\n",
      "1692\n",
      "2910\n",
      "2083\n",
      "2443\n",
      "1769\n",
      "2176\n",
      "1872\n",
      "1617\n",
      "1844\n",
      "2200\n",
      "1970\n",
      "2034\n",
      "2262\n",
      "2662\n",
      "2447\n",
      "2875\n",
      "1836\n",
      "1611\n",
      "1746\n",
      "3627\n",
      "3439\n",
      "2015\n",
      "2073\n",
      "2254\n",
      "1613\n",
      "1993\n",
      "1954\n",
      "2269\n",
      "2745\n",
      "3011\n",
      "1838\n",
      "3273\n",
      "2868\n",
      "2611\n",
      "1730\n",
      "3090\n",
      "3504\n",
      "1793\n",
      "1568\n",
      "1957\n",
      "2485\n",
      "2098\n",
      "2606\n",
      "1858\n",
      "1699\n",
      "1711\n",
      "1881\n",
      "2563\n",
      "1584\n",
      "2269\n",
      "3608\n",
      "3128\n",
      "2439\n",
      "3358\n",
      "2234\n",
      "2889\n",
      "2830\n",
      "1777\n",
      "3181\n",
      "2965\n",
      "1812\n",
      "1870\n",
      "2324\n",
      "2438\n",
      "3051\n",
      "1701\n",
      "1925\n",
      "3394\n",
      "2186\n",
      "2082\n",
      "2327\n",
      "2062\n",
      "1614\n",
      "1856\n",
      "2475\n",
      "1653\n",
      "2186\n",
      "1631\n",
      "2638\n",
      "1529\n",
      "3276\n",
      "2016\n",
      "2720\n",
      "2698\n",
      "1649\n",
      "1801\n",
      "2986\n",
      "2099\n",
      "1621\n",
      "1737\n",
      "1970\n",
      "3412\n",
      "3418\n",
      "2801\n",
      "1890\n",
      "1742\n",
      "2438\n",
      "3208\n",
      "1848\n",
      "2122\n",
      "1561\n",
      "2381\n",
      "1855\n",
      "2565\n",
      "1915\n",
      "1915\n",
      "2252\n",
      "1622\n",
      "1871\n",
      "2969\n",
      "2649\n",
      "2521\n",
      "1581\n",
      "1751\n",
      "3385\n",
      "1901\n",
      "3166\n",
      "2207\n",
      "3562\n",
      "2744\n",
      "1775\n",
      "3164\n",
      "2848\n",
      "2823\n",
      "2300\n",
      "1521\n",
      "1740\n",
      "2024\n",
      "3511\n",
      "3359\n",
      "2520\n",
      "2118\n",
      "2589\n",
      "3489\n",
      "1792\n",
      "2365\n",
      "1758\n",
      "3563\n",
      "2271\n",
      "1811\n",
      "3356\n",
      "3074\n",
      "2767\n",
      "1592\n",
      "3413\n",
      "2481\n",
      "3627\n",
      "1823\n",
      "3400\n",
      "2773\n",
      "3174\n",
      "1950\n",
      "3374\n",
      "2330\n",
      "2500\n",
      "3293\n",
      "2146\n",
      "2198\n",
      "1945\n",
      "2355\n",
      "2192\n",
      "2402\n",
      "1527\n",
      "2717\n",
      "3367\n",
      "2164\n",
      "1538\n",
      "3439\n",
      "2495\n",
      "2000\n",
      "1506\n",
      "2009\n",
      "2994\n",
      "3202\n",
      "2332\n",
      "2407\n",
      "2063\n",
      "3352\n",
      "1853\n",
      "1728\n",
      "1714\n",
      "1980\n",
      "1793\n",
      "3019\n",
      "1963\n",
      "1956\n",
      "1678\n",
      "1598\n",
      "1973\n",
      "1897\n",
      "2683\n",
      "1924\n",
      "1989\n",
      "2747\n",
      "2135\n",
      "1973\n",
      "2710\n",
      "2400\n",
      "1719\n",
      "1573\n",
      "3181\n",
      "2202\n",
      "1927\n",
      "2013\n",
      "2040\n",
      "2533\n",
      "1736\n",
      "2534\n",
      "1757\n",
      "2325\n",
      "2836\n",
      "2859\n",
      "2901\n",
      "2065\n",
      "1937\n",
      "1759\n",
      "1957\n",
      "1903\n",
      "2791\n",
      "1574\n",
      "2318\n",
      "3626\n",
      "2179\n",
      "1760\n",
      "1826\n",
      "1922\n",
      "2344\n",
      "1606\n",
      "3544\n",
      "2263\n",
      "1610\n",
      "3233\n",
      "2451\n",
      "1929\n",
      "3395\n",
      "2464\n",
      "1592\n",
      "2198\n",
      "2206\n",
      "2831\n",
      "3626\n",
      "2578\n",
      "1868\n",
      "2905\n",
      "1772\n",
      "2509\n",
      "2706\n",
      "2485\n",
      "1854\n",
      "1867\n",
      "1580\n",
      "2292\n",
      "3627\n",
      "3137\n",
      "3232\n",
      "1956\n",
      "2598\n",
      "1649\n",
      "1844\n",
      "1797\n",
      "2916\n",
      "1735\n",
      "1552\n",
      "2366\n",
      "3423\n",
      "3179\n",
      "1568\n",
      "1791\n",
      "1757\n",
      "3009\n",
      "2146\n",
      "1929\n",
      "2173\n",
      "3010\n",
      "2503\n",
      "3460\n",
      "2461\n",
      "1579\n",
      "2347\n",
      "2850\n",
      "3544\n",
      "1544\n",
      "1535\n",
      "1699\n",
      "2288\n",
      "2597\n",
      "1917\n",
      "2235\n",
      "2171\n",
      "2406\n",
      "1999\n",
      "1594\n",
      "2259\n",
      "2502\n",
      "2573\n",
      "2579\n",
      "2088\n",
      "2281\n",
      "3324\n",
      "2319\n",
      "1595\n",
      "2427\n",
      "1527\n",
      "2007\n",
      "1964\n",
      "1515\n",
      "1570\n",
      "1542\n",
      "2813\n",
      "3597\n",
      "2125\n",
      "1557\n",
      "1806\n",
      "1749\n",
      "1541\n",
      "2754\n",
      "3627\n",
      "1684\n",
      "1882\n",
      "2745\n",
      "2424\n",
      "1848\n",
      "2190\n",
      "2030\n",
      "1563\n",
      "1594\n",
      "1755\n",
      "1501\n",
      "1931\n",
      "2580\n",
      "1607\n",
      "1616\n",
      "1612\n",
      "1598\n",
      "2934\n",
      "2442\n",
      "2695\n",
      "1778\n",
      "1592\n",
      "3627\n",
      "1779\n",
      "1681\n",
      "2105\n",
      "1671\n",
      "1600\n",
      "3594\n",
      "3333\n",
      "2093\n",
      "1874\n",
      "1608\n",
      "1857\n",
      "1994\n",
      "1765\n",
      "1850\n",
      "2267\n",
      "3627\n",
      "3564\n",
      "1972\n",
      "1912\n",
      "2430\n",
      "1538\n",
      "1960\n",
      "1957\n",
      "3160\n",
      "1541\n",
      "2044\n",
      "1952\n",
      "2169\n",
      "1618\n",
      "1644\n",
      "2897\n",
      "2096\n",
      "3627\n",
      "3312\n",
      "2679\n",
      "2299\n",
      "1938\n",
      "2185\n",
      "1914\n",
      "2849\n",
      "3437\n",
      "2708\n",
      "2825\n",
      "1521\n",
      "3583\n",
      "2694\n",
      "1692\n",
      "1949\n",
      "3057\n",
      "2491\n",
      "2037\n",
      "2103\n",
      "3626\n",
      "1840\n",
      "1899\n",
      "1885\n",
      "1847\n",
      "2093\n",
      "1817\n",
      "3070\n",
      "1735\n",
      "2649\n",
      "3331\n",
      "3231\n",
      "2651\n",
      "2626\n",
      "1568\n",
      "1849\n",
      "1684\n",
      "3231\n",
      "2020\n",
      "2198\n",
      "1664\n",
      "1636\n",
      "1712\n",
      "3219\n",
      "1934\n",
      "2285\n",
      "1749\n",
      "1683\n",
      "1615\n",
      "2028\n",
      "1800\n",
      "1973\n",
      "2325\n",
      "3429\n",
      "1889\n",
      "1823\n",
      "3022\n",
      "1970\n",
      "1667\n",
      "3627\n",
      "3191\n",
      "2392\n",
      "1871\n",
      "2589\n",
      "2470\n",
      "2251\n",
      "1588\n",
      "2466\n",
      "2101\n",
      "3626\n",
      "2344\n",
      "2031\n",
      "2759\n",
      "1519\n",
      "2035\n",
      "3176\n",
      "3187\n",
      "1579\n",
      "3393\n",
      "1930\n",
      "1724\n",
      "1853\n",
      "2146\n",
      "1625\n",
      "2017\n",
      "2692\n",
      "1949\n",
      "1862\n",
      "2506\n",
      "1750\n",
      "1623\n",
      "2140\n",
      "2218\n",
      "2897\n",
      "2406\n",
      "2070\n",
      "1701\n",
      "1882\n",
      "1782\n",
      "2694\n",
      "1614\n",
      "1605\n",
      "1532\n",
      "2174\n",
      "3093\n",
      "1733\n",
      "1776\n",
      "1803\n",
      "1658\n",
      "2349\n",
      "1799\n",
      "3496\n",
      "1897\n",
      "1575\n",
      "2546\n",
      "3069\n",
      "2000\n",
      "2529\n",
      "1681\n",
      "1539\n",
      "1939\n",
      "2095\n",
      "2108\n",
      "1555\n",
      "2073\n",
      "3538\n",
      "2078\n",
      "1834\n",
      "3577\n",
      "1995\n",
      "3509\n",
      "1806\n",
      "1940\n",
      "1669\n",
      "2228\n",
      "3474\n",
      "2046\n",
      "1663\n",
      "3444\n",
      "1691\n",
      "1807\n",
      "1556\n",
      "1944\n",
      "1986\n",
      "1668\n",
      "1771\n",
      "3054\n",
      "3252\n",
      "2050\n",
      "3479\n",
      "1726\n",
      "3602\n",
      "1742\n",
      "1958\n",
      "1829\n",
      "1596\n",
      "2486\n",
      "2815\n",
      "2007\n",
      "2379\n",
      "3102\n",
      "3485\n",
      "3300\n",
      "3367\n",
      "2206\n",
      "1644\n",
      "2100\n",
      "3432\n",
      "3115\n",
      "1893\n",
      "2634\n",
      "2925\n",
      "1793\n",
      "2760\n",
      "1511\n",
      "3277\n",
      "1701\n",
      "1530\n",
      "1508\n",
      "2640\n",
      "2513\n",
      "1971\n",
      "1616\n",
      "2194\n",
      "1881\n",
      "3053\n",
      "1770\n",
      "1713\n",
      "1573\n",
      "1895\n",
      "1598\n",
      "3351\n",
      "3627\n",
      "1826\n",
      "2124\n",
      "1958\n",
      "2016\n",
      "2784\n",
      "1810\n",
      "1534\n",
      "1850\n",
      "2713\n",
      "2709\n",
      "1610\n",
      "2761\n",
      "1825\n",
      "2067\n",
      "2007\n",
      "2567\n",
      "2370\n",
      "2277\n",
      "2036\n",
      "1970\n",
      "1618\n",
      "2180\n",
      "1762\n",
      "1871\n",
      "1787\n",
      "2462\n",
      "1727\n",
      "2500\n",
      "1748\n",
      "1737\n",
      "2598\n",
      "3065\n",
      "3440\n",
      "2088\n",
      "1672\n",
      "2824\n",
      "2478\n",
      "1906\n",
      "1713\n",
      "3113\n",
      "2530\n",
      "1737\n",
      "1679\n",
      "1829\n",
      "2494\n",
      "1551\n",
      "2445\n",
      "3157\n",
      "3014\n",
      "2302\n",
      "1525\n",
      "1850\n",
      "3264\n",
      "3172\n",
      "1707\n",
      "3178\n",
      "3006\n",
      "1746\n",
      "1551\n",
      "2965\n",
      "3001\n",
      "1989\n",
      "2922\n",
      "2322\n",
      "2085\n",
      "3544\n",
      "2714\n",
      "3297\n",
      "1574\n",
      "1696\n",
      "2315\n",
      "1545\n",
      "2561\n",
      "1608\n",
      "2280\n",
      "1906\n",
      "2336\n",
      "1941\n",
      "3227\n",
      "1543\n",
      "1665\n",
      "2341\n",
      "3612\n",
      "2314\n",
      "2414\n",
      "3057\n",
      "1789\n",
      "2715\n",
      "2420\n",
      "1706\n",
      "1971\n",
      "2133\n",
      "2413\n",
      "1518\n",
      "3068\n",
      "1781\n",
      "2326\n",
      "1849\n",
      "1943\n",
      "2684\n",
      "2246\n",
      "3324\n",
      "2788\n",
      "2036\n",
      "1852\n",
      "2532\n",
      "2349\n",
      "3298\n",
      "2437\n",
      "1952\n",
      "3627\n",
      "2029\n",
      "1873\n",
      "1972\n",
      "2903\n",
      "2890\n",
      "2339\n",
      "2230\n",
      "3554\n",
      "3166\n",
      "2758\n",
      "3371\n",
      "2517\n",
      "2553\n",
      "3229\n",
      "2620\n",
      "2354\n",
      "1690\n",
      "1824\n",
      "2600\n",
      "1597\n",
      "1583\n",
      "3627\n",
      "2039\n",
      "2125\n",
      "2036\n",
      "2028\n",
      "1510\n",
      "3229\n",
      "3627\n",
      "1819\n",
      "1857\n",
      "2573\n",
      "3575\n",
      "1712\n",
      "1536\n",
      "1689\n",
      "2762\n",
      "1989\n",
      "2659\n",
      "1982\n",
      "2209\n",
      "2470\n",
      "1863\n",
      "1510\n",
      "2884\n",
      "1735\n",
      "1879\n",
      "2359\n",
      "2284\n",
      "1916\n",
      "1524\n",
      "1540\n",
      "2159\n",
      "3626\n",
      "1772\n",
      "2143\n",
      "2847\n",
      "3312\n",
      "2220\n",
      "3194\n",
      "1795\n",
      "1765\n",
      "1950\n",
      "1694\n",
      "2955\n",
      "2385\n",
      "1866\n",
      "2181\n",
      "1900\n",
      "2422\n",
      "2780\n",
      "1744\n",
      "3399\n",
      "1910\n",
      "1675\n",
      "3361\n",
      "1686\n",
      "2032\n",
      "2687\n",
      "1852\n",
      "1862\n",
      "3248\n",
      "2734\n",
      "3518\n",
      "1519\n",
      "1812\n",
      "3564\n",
      "1548\n",
      "2371\n",
      "1947\n",
      "3225\n",
      "1833\n",
      "2144\n",
      "1690\n",
      "1594\n",
      "1660\n",
      "3555\n",
      "2412\n",
      "1763\n",
      "2290\n",
      "2279\n",
      "2152\n",
      "3253\n",
      "3183\n",
      "3239\n",
      "2414\n",
      "2705\n",
      "1777\n",
      "1876\n",
      "1567\n",
      "1705\n",
      "2322\n",
      "1570\n",
      "1782\n",
      "1746\n",
      "2185\n",
      "2257\n",
      "2098\n",
      "1530\n",
      "1606\n",
      "2253\n",
      "2360\n",
      "1852\n",
      "2689\n",
      "2162\n",
      "2649\n",
      "2058\n",
      "2007\n",
      "2888\n",
      "1760\n",
      "3058\n",
      "1990\n",
      "2657\n",
      "1505\n",
      "1585\n",
      "1854\n",
      "2045\n",
      "1985\n",
      "1874\n",
      "2060\n",
      "1637\n",
      "2658\n",
      "2281\n",
      "2721\n",
      "1608\n",
      "2064\n",
      "3598\n",
      "1618\n",
      "1763\n",
      "1780\n",
      "1963\n",
      "2748\n",
      "3584\n",
      "2197\n",
      "2784\n",
      "2386\n",
      "1644\n",
      "2493\n",
      "2382\n",
      "1971\n",
      "2099\n",
      "2155\n",
      "2103\n",
      "2949\n",
      "2690\n",
      "2689\n",
      "1682\n",
      "1714\n",
      "1566\n",
      "1568\n",
      "1695\n",
      "1614\n",
      "2672\n",
      "2647\n",
      "1665\n",
      "2092\n",
      "2097\n",
      "2825\n",
      "2535\n",
      "3112\n",
      "2783\n",
      "1722\n",
      "2290\n",
      "2746\n",
      "2275\n",
      "1809\n",
      "3055\n",
      "2045\n",
      "2965\n",
      "3226\n",
      "2094\n",
      "1774\n",
      "1616\n",
      "2241\n",
      "2567\n",
      "2924\n",
      "2148\n",
      "2857\n",
      "1955\n",
      "2657\n",
      "2617\n",
      "2769\n",
      "2384\n",
      "2483\n",
      "2182\n",
      "1789\n",
      "2050\n",
      "2329\n",
      "1525\n",
      "2683\n",
      "1998\n",
      "2387\n",
      "2781\n",
      "1515\n",
      "1784\n",
      "1615\n",
      "2287\n",
      "1939\n",
      "1790\n",
      "2620\n",
      "2659\n",
      "1575\n",
      "1583\n",
      "3050\n",
      "2738\n",
      "2630\n",
      "2589\n",
      "1544\n",
      "3627\n",
      "2216\n",
      "2070\n",
      "3092\n",
      "1512\n",
      "3077\n",
      "2607\n",
      "1582\n",
      "2835\n",
      "2087\n",
      "2917\n",
      "3120\n",
      "2667\n",
      "3120\n",
      "1502\n",
      "2189\n",
      "1515\n",
      "2422\n",
      "1879\n",
      "3040\n",
      "2309\n",
      "2385\n",
      "3172\n",
      "2715\n",
      "1967\n",
      "2096\n",
      "1833\n",
      "2841\n",
      "1522\n",
      "1681\n",
      "2665\n",
      "1660\n",
      "1766\n",
      "2045\n",
      "2558\n",
      "1936\n",
      "1580\n",
      "3127\n",
      "3613\n",
      "1937\n",
      "3627\n",
      "2067\n",
      "1785\n",
      "1559\n",
      "1707\n",
      "1648\n",
      "2034\n",
      "2269\n",
      "3281\n",
      "1738\n",
      "2160\n",
      "1933\n",
      "2191\n",
      "3345\n",
      "1774\n",
      "1516\n",
      "1555\n",
      "1973\n",
      "2978\n",
      "2322\n",
      "1632\n",
      "3127\n",
      "1841\n",
      "1597\n",
      "3390\n",
      "2347\n",
      "2230\n",
      "2379\n",
      "1852\n",
      "3184\n",
      "3004\n",
      "2145\n",
      "2029\n",
      "1540\n",
      "2147\n",
      "2161\n",
      "1828\n",
      "2763\n",
      "2324\n",
      "1622\n",
      "1798\n",
      "1709\n",
      "2088\n",
      "1981\n",
      "1631\n",
      "1550\n",
      "1702\n",
      "3168\n",
      "2000\n",
      "2143\n",
      "2542\n",
      "2670\n",
      "1576\n",
      "1785\n",
      "1721\n",
      "1800\n",
      "3097\n",
      "2711\n",
      "2194\n",
      "1747\n",
      "1833\n",
      "2827\n",
      "2023\n",
      "1617\n",
      "1841\n",
      "3189\n",
      "1842\n",
      "2642\n",
      "2510\n",
      "2781\n",
      "2103\n",
      "3473\n",
      "1913\n",
      "2003\n",
      "2080\n",
      "1952\n",
      "2009\n",
      "1672\n",
      "1733\n",
      "1953\n",
      "2569\n",
      "2028\n",
      "2572\n",
      "3228\n",
      "1769\n",
      "1737\n",
      "2184\n",
      "3262\n",
      "2232\n",
      "2934\n",
      "2378\n",
      "1821\n",
      "3509\n",
      "2466\n",
      "1685\n",
      "2102\n",
      "1606\n",
      "1922\n",
      "3150\n",
      "2494\n",
      "2829\n",
      "3027\n",
      "3627\n",
      "2070\n",
      "2256\n",
      "2100\n",
      "2294\n",
      "2586\n",
      "1771\n",
      "1932\n",
      "2565\n",
      "1748\n",
      "1741\n",
      "3627\n",
      "1613\n",
      "3327\n",
      "1911\n",
      "1693\n",
      "2794\n",
      "1845\n",
      "1655\n",
      "2963\n",
      "2586\n",
      "1679\n",
      "3395\n",
      "1817\n",
      "1680\n",
      "3097\n",
      "1879\n",
      "1503\n",
      "1673\n",
      "2308\n",
      "2392\n",
      "2098\n",
      "1548\n",
      "1505\n",
      "1659\n",
      "1854\n",
      "3063\n",
      "1600\n",
      "1761\n",
      "1993\n",
      "2193\n",
      "1885\n",
      "1915\n",
      "2243\n",
      "2859\n",
      "1856\n",
      "3559\n",
      "2200\n",
      "2777\n",
      "1845\n",
      "2629\n",
      "2379\n",
      "1734\n",
      "2327\n",
      "3344\n",
      "2834\n",
      "2638\n",
      "2109\n",
      "1961\n",
      "1600\n",
      "2465\n",
      "2061\n",
      "1983\n",
      "2738\n",
      "1529\n",
      "1601\n",
      "2149\n",
      "3627\n",
      "2782\n",
      "2517\n",
      "2866\n",
      "3330\n",
      "1589\n",
      "2275\n",
      "2300\n",
      "1704\n",
      "1769\n",
      "2239\n",
      "3518\n",
      "2120\n",
      "3126\n",
      "1865\n",
      "1970\n",
      "2110\n",
      "2901\n",
      "1820\n",
      "1776\n",
      "2743\n",
      "2501\n",
      "1731\n",
      "3576\n",
      "2148\n",
      "2859\n",
      "1857\n",
      "1952\n",
      "2000\n",
      "3261\n",
      "2462\n",
      "3035\n",
      "3082\n",
      "2918\n",
      "2365\n",
      "2135\n",
      "2311\n",
      "2394\n",
      "3194\n",
      "3058\n",
      "1714\n",
      "2631\n",
      "3139\n",
      "3094\n",
      "3429\n",
      "3344\n",
      "2427\n",
      "1868\n",
      "1518\n",
      "1695\n",
      "2446\n",
      "3166\n",
      "1612\n",
      "2088\n",
      "1679\n",
      "1717\n",
      "1875\n",
      "2521\n",
      "1575\n",
      "2138\n",
      "2211\n",
      "2544\n",
      "2657\n",
      "3465\n",
      "1506\n",
      "2334\n",
      "2027\n",
      "2074\n",
      "2351\n",
      "2114\n",
      "2054\n",
      "1903\n",
      "1575\n",
      "1721\n",
      "3166\n",
      "2555\n",
      "1672\n",
      "2088\n",
      "2250\n",
      "2442\n",
      "2245\n",
      "3050\n",
      "3259\n",
      "2230\n",
      "2439\n",
      "1552\n",
      "2058\n",
      "2595\n",
      "2486\n",
      "2141\n",
      "1586\n",
      "2741\n",
      "2235\n",
      "3235\n",
      "3037\n",
      "3005\n",
      "2147\n",
      "2213\n",
      "3556\n",
      "3094\n",
      "1860\n",
      "1814\n",
      "3620\n",
      "1609\n",
      "2144\n",
      "1638\n",
      "2123\n",
      "3552\n",
      "2800\n",
      "1797\n",
      "2265\n",
      "3433\n",
      "1743\n",
      "1597\n",
      "1545\n",
      "2470\n",
      "2001\n",
      "1899\n",
      "1576\n",
      "3179\n",
      "2802\n",
      "2581\n",
      "2158\n",
      "1810\n",
      "1646\n",
      "2479\n",
      "2001\n",
      "2972\n",
      "3370\n",
      "2016\n",
      "1568\n",
      "1926\n",
      "2418\n",
      "2806\n",
      "2245\n",
      "3438\n",
      "2397\n",
      "1903\n",
      "1967\n",
      "2471\n",
      "1543\n",
      "2463\n",
      "2497\n",
      "1950\n",
      "1575\n",
      "2684\n",
      "2381\n",
      "2423\n",
      "1777\n",
      "2002\n",
      "2215\n",
      "2033\n",
      "2491\n",
      "1759\n",
      "2301\n",
      "2152\n",
      "2193\n",
      "1593\n",
      "1739\n",
      "2934\n",
      "2416\n",
      "3034\n",
      "2275\n",
      "2684\n",
      "1578\n",
      "1717\n",
      "3281\n",
      "2852\n",
      "3627\n",
      "3627\n",
      "1603\n",
      "2075\n",
      "2078\n",
      "1873\n",
      "1557\n",
      "3484\n",
      "1754\n",
      "1685\n",
      "1881\n",
      "1759\n",
      "1886\n",
      "1601\n",
      "2804\n",
      "1514\n",
      "2318\n",
      "2075\n",
      "2770\n",
      "1574\n",
      "1513\n",
      "3012\n",
      "1775\n",
      "3050\n",
      "1643\n",
      "1853\n",
      "1749\n",
      "1831\n",
      "1566\n",
      "2983\n",
      "1925\n",
      "1850\n",
      "1863\n",
      "1721\n",
      "2186\n",
      "2509\n",
      "2982\n",
      "2126\n",
      "1522\n",
      "1790\n",
      "2103\n",
      "1676\n",
      "1929\n",
      "2256\n",
      "1608\n",
      "3173\n",
      "2814\n",
      "1719\n",
      "1865\n",
      "2876\n",
      "1680\n",
      "1699\n",
      "2049\n",
      "3127\n",
      "3627\n",
      "3404\n",
      "3205\n",
      "2169\n",
      "2995\n",
      "1536\n",
      "1593\n",
      "1716\n",
      "2044\n",
      "1755\n",
      "2555\n",
      "1813\n",
      "3020\n",
      "3361\n",
      "1921\n",
      "2651\n",
      "1610\n",
      "3627\n",
      "1671\n",
      "1770\n",
      "2484\n",
      "1759\n",
      "2769\n",
      "2325\n",
      "3530\n",
      "1696\n",
      "2775\n",
      "2236\n",
      "2850\n",
      "1932\n",
      "1957\n",
      "2226\n",
      "3469\n",
      "1574\n",
      "2413\n",
      "2052\n",
      "3107\n",
      "1642\n",
      "1577\n",
      "2275\n",
      "1661\n",
      "2852\n",
      "2213\n",
      "2363\n",
      "1748\n",
      "2543\n",
      "1799\n",
      "3058\n",
      "2300\n",
      "2314\n",
      "2971\n",
      "2058\n",
      "1841\n",
      "3187\n",
      "2639\n",
      "1772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840\n",
      "1705\n",
      "2170\n",
      "1970\n",
      "1721\n",
      "1667\n",
      "2225\n",
      "3627\n",
      "2528\n",
      "2342\n",
      "2318\n",
      "1543\n",
      "2704\n",
      "2346\n",
      "2395\n",
      "2528\n",
      "1943\n",
      "1719\n",
      "2022\n",
      "1702\n",
      "3332\n",
      "1740\n",
      "2093\n",
      "1690\n",
      "1891\n",
      "1595\n",
      "3448\n",
      "1884\n",
      "2227\n",
      "3164\n",
      "1861\n",
      "1958\n",
      "3314\n",
      "3627\n",
      "3204\n",
      "3378\n",
      "2522\n",
      "3091\n",
      "3073\n",
      "2518\n",
      "2466\n",
      "1754\n",
      "3166\n",
      "2409\n",
      "3326\n",
      "2974\n",
      "2185\n",
      "3031\n",
      "2060\n",
      "1718\n",
      "2318\n",
      "2095\n",
      "3471\n",
      "3476\n",
      "2811\n",
      "2422\n",
      "3627\n",
      "1871\n",
      "1884\n",
      "1870\n",
      "1731\n",
      "2501\n",
      "2081\n",
      "2663\n",
      "1976\n",
      "3225\n",
      "1794\n",
      "2152\n",
      "1904\n",
      "3426\n",
      "2032\n",
      "1665\n",
      "1518\n",
      "1504\n",
      "2994\n",
      "2114\n",
      "2382\n",
      "1883\n",
      "2857\n",
      "3420\n",
      "1658\n",
      "3134\n",
      "2383\n",
      "1849\n",
      "2292\n",
      "1688\n",
      "2196\n",
      "1850\n",
      "2951\n",
      "2623\n",
      "3258\n",
      "1532\n",
      "3087\n",
      "1986\n",
      "1659\n",
      "2636\n",
      "1585\n",
      "1573\n",
      "2709\n",
      "2161\n",
      "2060\n",
      "2821\n",
      "1662\n",
      "2514\n",
      "1556\n",
      "1878\n",
      "2193\n",
      "2689\n",
      "3212\n",
      "2049\n",
      "3093\n",
      "3626\n",
      "1534\n",
      "1535\n",
      "3110\n",
      "2097\n",
      "1766\n",
      "3548\n",
      "2285\n",
      "3295\n",
      "2610\n",
      "1568\n",
      "2315\n",
      "1776\n",
      "3412\n",
      "1626\n",
      "1852\n",
      "3215\n",
      "2099\n",
      "1520\n",
      "1757\n",
      "1725\n",
      "1505\n",
      "1514\n",
      "2027\n",
      "1973\n",
      "3118\n",
      "3627\n",
      "1803\n",
      "1580\n",
      "1593\n",
      "1671\n",
      "2867\n",
      "1952\n",
      "2026\n",
      "1647\n",
      "2005\n",
      "3627\n",
      "1576\n",
      "2530\n",
      "2893\n",
      "1902\n",
      "1688\n",
      "3241\n",
      "2221\n",
      "2474\n",
      "1774\n",
      "1695\n",
      "2479\n",
      "1663\n",
      "1777\n",
      "2688\n",
      "1523\n",
      "1701\n",
      "1930\n",
      "1814\n",
      "2084\n",
      "1867\n",
      "2706\n",
      "2078\n",
      "2280\n",
      "1666\n",
      "2073\n",
      "1847\n",
      "1582\n",
      "1652\n",
      "1654\n",
      "2692\n",
      "1995\n",
      "2190\n",
      "2158\n",
      "1524\n",
      "2282\n",
      "2302\n",
      "2046\n",
      "2444\n",
      "3627\n",
      "1525\n",
      "2223\n",
      "2534\n",
      "2500\n",
      "3252\n",
      "1843\n",
      "3362\n",
      "2059\n",
      "2358\n",
      "1575\n",
      "1830\n",
      "1619\n",
      "2490\n",
      "2456\n",
      "1550\n",
      "3317\n",
      "2450\n",
      "3503\n",
      "1552\n",
      "1717\n",
      "2036\n",
      "1989\n",
      "1840\n",
      "1896\n",
      "1994\n",
      "1859\n",
      "3336\n",
      "1650\n",
      "1610\n",
      "3412\n",
      "1936\n",
      "1557\n",
      "3215\n",
      "3050\n",
      "1762\n",
      "1692\n",
      "2038\n",
      "1927\n",
      "3626\n",
      "3349\n",
      "1665\n",
      "1943\n",
      "2570\n",
      "2478\n",
      "1809\n",
      "2066\n",
      "1591\n",
      "2833\n",
      "1696\n",
      "2342\n",
      "2558\n",
      "2015\n",
      "3442\n",
      "2149\n",
      "2735\n",
      "3085\n",
      "2571\n",
      "3317\n",
      "1694\n",
      "2468\n",
      "2208\n",
      "1549\n",
      "1675\n",
      "1997\n",
      "3241\n",
      "2382\n",
      "2003\n",
      "1683\n",
      "3390\n",
      "3348\n",
      "2849\n",
      "1585\n",
      "1918\n",
      "1903\n",
      "1511\n",
      "2521\n",
      "2504\n",
      "2150\n",
      "1535\n",
      "1516\n",
      "1548\n",
      "1667\n",
      "1669\n",
      "1721\n",
      "1943\n",
      "1855\n",
      "1760\n",
      "2159\n",
      "1992\n",
      "2326\n",
      "2038\n",
      "1893\n",
      "3216\n",
      "2283\n",
      "3217\n",
      "1879\n",
      "3302\n",
      "1644\n",
      "2797\n",
      "1751\n",
      "2030\n",
      "3156\n",
      "2999\n",
      "1536\n",
      "1627\n",
      "1838\n",
      "1645\n",
      "1727\n",
      "2913\n",
      "3627\n",
      "3209\n",
      "3627\n",
      "2114\n",
      "2128\n",
      "2763\n",
      "2805\n",
      "1786\n",
      "3243\n",
      "2692\n",
      "3627\n",
      "2975\n",
      "1519\n",
      "3041\n",
      "2566\n",
      "2483\n",
      "2067\n",
      "1675\n",
      "3449\n",
      "1793\n",
      "1943\n",
      "1503\n",
      "1531\n",
      "1561\n",
      "1652\n",
      "3276\n",
      "3556\n",
      "1618\n",
      "1878\n",
      "1658\n",
      "3568\n",
      "3291\n",
      "2517\n",
      "3627\n",
      "3054\n",
      "2306\n",
      "2430\n",
      "1679\n",
      "3258\n",
      "2773\n",
      "2424\n",
      "1735\n",
      "1761\n",
      "3028\n",
      "2633\n",
      "3230\n",
      "3374\n",
      "3627\n",
      "2288\n",
      "1908\n",
      "2681\n",
      "2776\n",
      "1641\n",
      "1791\n",
      "1657\n",
      "3051\n",
      "1836\n",
      "2221\n",
      "1560\n",
      "2882\n",
      "1555\n",
      "2726\n",
      "2654\n",
      "2856\n",
      "1518\n",
      "1624\n",
      "2307\n",
      "3627\n",
      "2775\n",
      "1661\n",
      "2108\n",
      "2436\n",
      "2608\n",
      "2976\n",
      "1945\n",
      "1593\n",
      "2016\n",
      "1605\n",
      "1997\n",
      "2838\n",
      "2492\n",
      "1806\n",
      "1907\n",
      "2391\n",
      "2335\n",
      "1710\n",
      "1573\n",
      "2635\n",
      "1863\n",
      "2366\n",
      "1616\n",
      "1722\n",
      "2213\n",
      "3627\n",
      "2812\n",
      "2215\n",
      "1706\n",
      "1696\n",
      "1905\n",
      "1624\n",
      "2415\n",
      "1815\n",
      "2574\n",
      "2019\n",
      "1669\n",
      "3549\n",
      "2357\n",
      "2134\n",
      "2438\n",
      "3160\n",
      "2042\n",
      "1921\n",
      "3627\n",
      "3627\n",
      "2036\n",
      "1802\n",
      "1806\n",
      "2670\n",
      "2217\n",
      "2044\n",
      "2783\n",
      "1690\n",
      "1543\n",
      "1520\n",
      "1956\n",
      "2446\n",
      "3048\n",
      "3627\n",
      "1745\n",
      "3627\n",
      "1760\n",
      "1793\n",
      "2653\n",
      "2972\n",
      "2191\n",
      "3533\n",
      "1755\n",
      "3565\n",
      "1970\n",
      "1941\n",
      "1939\n",
      "1552\n",
      "1977\n",
      "2304\n",
      "1567\n",
      "3082\n",
      "1770\n",
      "2158\n",
      "2493\n",
      "1801\n",
      "2818\n",
      "1998\n",
      "1516\n",
      "1765\n",
      "2084\n",
      "2834\n",
      "1772\n",
      "1591\n",
      "2863\n",
      "3341\n",
      "1567\n",
      "1787\n",
      "3102\n",
      "3437\n",
      "1503\n",
      "3171\n",
      "3131\n",
      "1736\n",
      "2799\n",
      "2160\n",
      "2237\n",
      "2434\n",
      "3020\n",
      "2789\n",
      "2348\n",
      "1963\n",
      "1696\n",
      "3223\n",
      "1536\n",
      "2284\n",
      "3134\n",
      "1511\n",
      "1615\n",
      "1518\n",
      "1733\n",
      "2928\n",
      "1676\n",
      "2279\n",
      "2338\n",
      "1742\n",
      "1766\n",
      "1563\n",
      "2013\n",
      "1616\n",
      "2519\n",
      "3497\n",
      "1634\n",
      "2513\n",
      "1615\n",
      "1661\n",
      "1545\n",
      "1798\n",
      "1829\n",
      "1916\n",
      "2958\n",
      "1921\n",
      "1588\n",
      "1786\n",
      "1531\n",
      "2329\n",
      "1663\n",
      "1940\n",
      "1966\n",
      "1565\n",
      "2817\n",
      "2364\n",
      "3386\n",
      "1616\n",
      "1718\n",
      "2687\n",
      "3552\n",
      "1968\n",
      "3562\n",
      "1571\n",
      "1977\n",
      "2687\n",
      "1962\n",
      "1643\n",
      "1753\n",
      "1944\n",
      "3162\n",
      "3332\n",
      "1877\n",
      "3275\n",
      "2661\n",
      "2887\n",
      "1977\n",
      "2041\n",
      "3478\n",
      "3627\n",
      "2591\n",
      "3203\n",
      "1673\n",
      "2034\n",
      "1788\n",
      "3131\n",
      "1889\n",
      "3529\n",
      "3264\n",
      "3296\n",
      "2379\n",
      "1722\n",
      "2109\n",
      "3225\n",
      "1849\n",
      "2885\n",
      "1646\n",
      "2079\n",
      "2030\n",
      "3289\n",
      "1987\n",
      "1827\n",
      "1937\n",
      "2099\n",
      "2196\n",
      "2107\n",
      "3450\n",
      "1674\n",
      "1644\n",
      "3398\n",
      "1574\n",
      "2706\n",
      "1863\n",
      "2857\n",
      "1688\n",
      "1843\n",
      "3588\n",
      "2289\n",
      "3001\n",
      "3403\n",
      "2786\n",
      "1977\n",
      "1939\n",
      "1979\n",
      "1967\n",
      "1723\n",
      "2100\n",
      "2424\n",
      "1603\n",
      "1881\n",
      "1803\n",
      "1553\n",
      "2200\n",
      "1918\n",
      "3449\n",
      "1605\n",
      "2544\n",
      "3359\n",
      "1568\n",
      "2733\n",
      "2324\n",
      "2489\n",
      "1703\n",
      "1592\n",
      "1951\n",
      "3077\n",
      "1803\n",
      "2551\n",
      "1533\n",
      "1630\n",
      "2036\n",
      "1954\n",
      "1883\n",
      "2920\n",
      "1571\n",
      "2997\n",
      "2336\n",
      "1630\n",
      "1743\n",
      "3069\n",
      "1551\n",
      "1719\n",
      "2702\n",
      "2241\n",
      "1515\n",
      "1950\n",
      "1919\n",
      "1738\n",
      "3339\n",
      "1664\n",
      "2221\n",
      "1727\n",
      "2028\n",
      "2260\n",
      "2254\n",
      "1569\n",
      "2361\n",
      "2513\n",
      "1724\n",
      "1511\n",
      "1517\n",
      "2228\n",
      "2237\n",
      "1791\n",
      "2369\n",
      "1754\n",
      "1920\n",
      "2192\n",
      "1571\n",
      "1706\n",
      "1787\n",
      "1575\n",
      "1853\n",
      "2501\n",
      "1734\n",
      "2223\n",
      "1594\n",
      "1802\n",
      "2492\n",
      "1737\n",
      "1774\n",
      "2029\n",
      "1769\n",
      "2687\n",
      "1903\n",
      "1551\n",
      "1627\n",
      "1883\n",
      "2718\n",
      "3466\n",
      "2625\n",
      "1887\n",
      "2868\n",
      "2186\n",
      "2409\n",
      "2749\n",
      "2100\n",
      "2085\n",
      "1513\n",
      "1751\n",
      "2541\n",
      "1698\n",
      "2853\n",
      "1758\n",
      "2914\n",
      "1975\n",
      "2182\n",
      "3088\n",
      "1591\n",
      "2665\n",
      "3478\n",
      "2504\n",
      "1825\n",
      "3521\n",
      "3613\n",
      "2053\n",
      "2335\n",
      "2271\n",
      "3282\n",
      "2349\n",
      "3405\n",
      "3627\n",
      "2606\n",
      "1597\n",
      "3413\n",
      "2124\n",
      "3525\n",
      "3376\n",
      "2002\n",
      "2919\n",
      "1852\n",
      "1960\n",
      "2189\n",
      "1597\n",
      "1665\n",
      "2373\n",
      "1882\n",
      "1957\n",
      "2824\n",
      "1688\n",
      "2824\n",
      "1769\n",
      "1503\n",
      "3325\n",
      "2742\n",
      "1762\n",
      "2774\n",
      "1602\n",
      "3420\n",
      "1594\n",
      "3212\n",
      "2087\n",
      "3426\n",
      "1534\n",
      "2857\n",
      "1980\n",
      "2162\n",
      "3599\n",
      "1615\n",
      "2381\n",
      "1708\n",
      "1956\n",
      "3330\n",
      "1696\n",
      "2491\n",
      "1655\n",
      "2585\n",
      "2893\n",
      "2904\n",
      "1682\n",
      "1509\n",
      "1516\n",
      "1527\n",
      "2115\n",
      "1982\n",
      "1721\n",
      "1523\n",
      "2135\n",
      "1988\n",
      "2774\n",
      "2462\n",
      "1723\n",
      "2003\n",
      "2654\n",
      "2593\n",
      "2546\n",
      "1946\n",
      "1770\n",
      "1532\n",
      "1508\n",
      "2399\n",
      "1849\n",
      "2688\n",
      "1659\n",
      "3525\n",
      "2634\n",
      "2073\n",
      "2673\n",
      "2119\n",
      "1725\n",
      "1937\n",
      "2520\n",
      "3106\n",
      "2575\n",
      "1597\n",
      "3228\n",
      "3279\n",
      "2173\n",
      "3016\n",
      "3585\n",
      "1860\n",
      "1558\n",
      "3207\n",
      "2786\n",
      "1774\n",
      "3271\n",
      "1742\n",
      "2216\n",
      "1504\n",
      "2865\n",
      "2962\n",
      "3052\n",
      "1807\n",
      "1545\n",
      "2004\n",
      "2002\n",
      "3240\n",
      "2248\n",
      "1818\n",
      "3398\n",
      "1803\n",
      "1730\n",
      "3277\n",
      "2561\n",
      "1553\n",
      "2179\n",
      "2883\n",
      "2132\n",
      "2338\n",
      "1679\n",
      "2351\n",
      "2241\n",
      "2485\n",
      "3468\n",
      "3223\n",
      "1913\n",
      "1642\n",
      "3373\n",
      "1630\n",
      "1983\n",
      "2011\n",
      "2883\n",
      "2486\n",
      "2774\n",
      "2535\n",
      "1904\n",
      "1622\n",
      "2703\n",
      "3586\n",
      "3453\n",
      "1684\n",
      "1776\n",
      "2302\n",
      "1794\n",
      "2338\n",
      "2423\n",
      "2898\n",
      "1682\n",
      "1853\n",
      "2337\n",
      "1832\n",
      "1945\n",
      "1574\n",
      "1830\n",
      "3491\n",
      "1535\n",
      "1639\n",
      "2086\n",
      "1647\n",
      "2464\n",
      "2196\n",
      "3627\n",
      "3521\n",
      "1616\n",
      "1852\n",
      "1737\n",
      "2969\n",
      "3376\n",
      "1948\n",
      "2144\n",
      "3627\n",
      "3360\n",
      "1846\n",
      "1641\n",
      "1847\n",
      "1924\n",
      "2293\n",
      "2142\n",
      "2179\n",
      "3435\n",
      "1515\n",
      "1670\n",
      "3049\n",
      "1581\n",
      "2286\n",
      "2860\n",
      "2453\n",
      "2830\n",
      "3393\n",
      "2440\n",
      "3036\n",
      "3088\n",
      "1776\n",
      "2374\n",
      "1609\n",
      "3417\n",
      "1963\n",
      "1615\n",
      "1829\n",
      "2692\n",
      "2465\n",
      "2736\n",
      "1837\n",
      "1747\n",
      "2107\n",
      "1877\n",
      "2571\n",
      "1959\n",
      "3309\n",
      "1976\n",
      "2368\n",
      "2572\n",
      "1898\n",
      "3385\n",
      "1548\n",
      "2454\n",
      "1923\n",
      "2334\n",
      "3185\n",
      "1716\n",
      "1917\n",
      "1750\n",
      "2729\n",
      "2788\n",
      "1793\n",
      "2194\n",
      "1932\n",
      "2541\n",
      "2033\n",
      "1942\n",
      "1828\n",
      "1504\n",
      "1736\n",
      "2154\n",
      "2022\n",
      "1695\n",
      "3627\n",
      "2985\n",
      "1896\n",
      "2621\n",
      "1740\n",
      "3627\n",
      "1879\n",
      "1881\n",
      "3014\n",
      "1690\n",
      "2807\n",
      "1688\n",
      "1941\n",
      "2615\n",
      "2293\n",
      "3066\n",
      "3538\n",
      "1851\n",
      "2777\n",
      "2981\n",
      "3270\n",
      "1625\n",
      "2923\n",
      "2012\n",
      "1780\n",
      "2926\n",
      "1571\n",
      "1606\n",
      "2481\n",
      "1994\n",
      "1540\n",
      "2162\n",
      "3512\n",
      "2797\n",
      "2366\n",
      "3429\n",
      "1639\n",
      "2453\n",
      "2842\n",
      "1542\n",
      "1968\n",
      "1728\n",
      "1808\n",
      "1849\n",
      "2599\n",
      "2529\n",
      "3463\n",
      "3627\n",
      "1640\n",
      "1870\n",
      "3542\n",
      "3627\n",
      "1674\n",
      "2700\n",
      "2354\n",
      "1501\n",
      "3627\n",
      "3493\n",
      "1696\n",
      "3499\n",
      "1709\n",
      "2935\n",
      "2083\n",
      "2453\n",
      "1784\n",
      "2171\n",
      "1846\n",
      "1610\n",
      "1829\n",
      "2224\n",
      "1960\n",
      "2018\n",
      "2261\n",
      "2671\n",
      "2431\n",
      "2871\n",
      "1827\n",
      "1597\n",
      "1734\n",
      "3627\n",
      "3438\n",
      "2001\n",
      "2077\n",
      "2249\n",
      "1614\n",
      "1980\n",
      "1949\n",
      "2286\n",
      "2742\n",
      "3006\n",
      "1839\n",
      "3288\n",
      "2847\n",
      "2608\n",
      "1720\n",
      "3094\n",
      "1505\n",
      "3513\n",
      "1768\n",
      "1564\n",
      "1946\n",
      "2521\n",
      "2104\n",
      "2586\n",
      "1861\n",
      "1699\n",
      "1666\n",
      "1886\n",
      "2559\n",
      "1585\n",
      "2256\n",
      "3611\n",
      "3118\n",
      "2436\n",
      "3357\n",
      "2221\n",
      "2908\n",
      "2850\n",
      "1787\n",
      "3190\n",
      "2970\n",
      "1846\n",
      "1894\n",
      "2357\n",
      "2436\n",
      "3044\n",
      "1695\n",
      "1906\n",
      "3390\n",
      "2209\n",
      "2064\n",
      "2329\n",
      "2042\n",
      "1616\n",
      "1838\n",
      "2472\n",
      "1633\n",
      "2162\n",
      "1615\n",
      "2623\n",
      "1536\n",
      "3254\n",
      "2002\n",
      "2715\n",
      "2697\n",
      "1647\n",
      "1789\n",
      "2967\n",
      "2100\n",
      "1598\n",
      "1758\n",
      "1945\n",
      "3390\n",
      "3405\n",
      "2806\n",
      "1893\n",
      "1715\n",
      "2452\n",
      "3195\n",
      "1858\n",
      "2126\n",
      "1580\n",
      "2398\n",
      "1830\n",
      "2567\n",
      "1917\n",
      "1909\n",
      "2253\n",
      "1607\n",
      "1877\n",
      "2976\n",
      "2649\n",
      "2515\n",
      "1573\n",
      "1757\n",
      "3398\n",
      "1905\n",
      "3161\n",
      "2194\n",
      "3571\n",
      "2724\n",
      "1747\n",
      "3173\n",
      "2869\n",
      "2843\n",
      "2307\n",
      "1528\n",
      "1730\n",
      "2009\n",
      "3504\n",
      "3362\n",
      "2531\n",
      "2110\n",
      "2581\n",
      "3472\n",
      "1818\n",
      "2369\n",
      "1753\n",
      "3561\n",
      "2267\n",
      "1814\n",
      "3344\n",
      "3075\n",
      "2780\n",
      "1596\n",
      "3405\n",
      "2491\n",
      "3627\n",
      "1830\n",
      "3379\n",
      "2776\n",
      "3151\n",
      "1938\n",
      "3362\n",
      "2309\n",
      "2499\n",
      "3300\n",
      "2163\n",
      "2207\n",
      "1931\n",
      "2367\n",
      "2197\n",
      "2403\n",
      "1514\n",
      "2708\n",
      "3375\n",
      "2183\n",
      "1521\n",
      "3461\n",
      "2464\n",
      "1978\n",
      "1508\n",
      "2022\n",
      "2970\n",
      "3201\n",
      "2305\n",
      "2402\n",
      "2064\n",
      "3352\n",
      "1881\n",
      "1722\n",
      "1706\n",
      "1979\n",
      "1762\n",
      "3017\n",
      "1947\n",
      "1956\n",
      "1685\n",
      "1592\n",
      "1969\n",
      "1916\n",
      "2694\n",
      "1903\n",
      "1990\n",
      "2746\n",
      "2131\n",
      "1987\n",
      "2704\n",
      "2409\n",
      "1731\n",
      "1586\n",
      "3169\n",
      "2211\n",
      "1927\n",
      "2016\n",
      "2040\n",
      "2527\n",
      "1722\n",
      "2536\n",
      "1761\n",
      "2321\n",
      "2825\n",
      "2859\n",
      "2895\n",
      "2087\n",
      "1955\n",
      "1768\n",
      "1979\n",
      "1874\n",
      "2804\n",
      "1569\n",
      "2300\n",
      "3626\n",
      "2190\n",
      "1777\n",
      "1832\n",
      "1921\n",
      "2335\n",
      "1614\n",
      "3541\n",
      "2271\n",
      "1614\n",
      "3221\n",
      "2458\n",
      "1951\n",
      "3401\n",
      "2472\n",
      "1591\n",
      "2198\n",
      "2195\n",
      "2836\n",
      "3626\n",
      "2575\n",
      "1894\n",
      "2914\n",
      "1795\n",
      "2505\n",
      "2712\n",
      "2480\n",
      "1827\n",
      "1892\n",
      "1595\n",
      "2299\n",
      "3627\n",
      "3135\n",
      "3257\n",
      "1927\n",
      "2596\n",
      "1684\n",
      "1856\n",
      "1777\n",
      "2912\n",
      "1746\n",
      "1540\n",
      "2391\n",
      "3405\n",
      "3171\n",
      "1553\n",
      "1812\n",
      "1765\n",
      "2997\n",
      "2149\n",
      "1938\n",
      "2182\n",
      "3010\n",
      "2491\n",
      "3449\n",
      "2461\n",
      "1565\n",
      "2316\n",
      "2854\n",
      "3540\n",
      "1538\n",
      "1517\n",
      "1682\n",
      "2249\n",
      "2577\n",
      "1897\n",
      "1503\n",
      "2227\n",
      "2135\n",
      "2423\n",
      "1978\n",
      "1601\n",
      "2281\n",
      "2494\n",
      "2560\n",
      "2606\n",
      "2089\n",
      "2319\n",
      "3336\n",
      "2326\n",
      "1579\n",
      "2426\n",
      "1507\n",
      "1997\n",
      "1968\n",
      "1513\n",
      "1555\n",
      "2189\n",
      "2795\n",
      "3595\n",
      "2139\n",
      "1550\n",
      "1813\n",
      "1737\n",
      "1532\n",
      "2760\n",
      "3604\n",
      "1689\n",
      "1891\n",
      "2734\n",
      "2422\n",
      "1850\n",
      "2197\n",
      "2005\n",
      "1561\n",
      "1584\n",
      "1738\n",
      "1919\n",
      "2612\n",
      "1608\n",
      "1609\n",
      "1629\n",
      "1586\n",
      "2926\n",
      "2470\n",
      "2666\n",
      "1774\n",
      "1587\n",
      "3627\n",
      "1796\n",
      "1700\n",
      "2103\n",
      "1667\n",
      "1615\n",
      "3595\n",
      "3342\n",
      "2104\n",
      "1874\n",
      "1602\n",
      "1879\n",
      "2007\n",
      "1776\n",
      "1842\n",
      "2270\n",
      "3627\n",
      "3578\n",
      "1966\n",
      "1912\n",
      "2441\n",
      "1534\n",
      "1950\n",
      "1970\n",
      "3165\n",
      "1538\n",
      "2057\n",
      "1938\n",
      "2176\n",
      "1626\n",
      "1624\n",
      "2897\n",
      "2121\n",
      "3627\n",
      "3327\n",
      "2670\n",
      "2315\n",
      "1947\n",
      "2172\n",
      "1918\n",
      "2824\n",
      "3445\n",
      "2693\n",
      "2808\n",
      "1535\n",
      "3593\n",
      "2709\n",
      "1687\n",
      "1930\n",
      "3058\n",
      "2490\n",
      "2032\n",
      "2092\n",
      "3626\n",
      "1826\n",
      "1912\n",
      "1871\n",
      "1863\n",
      "2102\n",
      "1841\n",
      "3046\n",
      "1725\n",
      "2648\n",
      "3340\n",
      "3232\n",
      "2638\n",
      "2617\n",
      "1556\n",
      "1829\n",
      "1727\n",
      "3227\n",
      "2024\n",
      "2199\n",
      "1658\n",
      "1658\n",
      "1712\n",
      "3235\n",
      "1934\n",
      "2288\n",
      "1738\n",
      "1681\n",
      "1629\n",
      "2026\n",
      "1780\n",
      "1982\n",
      "2328\n",
      "3443\n",
      "1896\n",
      "1826\n",
      "3013\n",
      "1949\n",
      "1671\n",
      "3627\n",
      "3186\n",
      "2386\n",
      "1881\n",
      "2581\n",
      "2462\n",
      "2251\n",
      "1590\n",
      "2485\n",
      "2095\n",
      "3626\n",
      "2320\n",
      "2012\n",
      "2758\n",
      "1533\n",
      "2073\n",
      "3181\n",
      "3198\n",
      "1574\n",
      "3398\n",
      "1931\n",
      "1730\n",
      "1860\n",
      "2135\n",
      "1601\n",
      "2016\n",
      "2723\n",
      "1939\n",
      "1863\n",
      "2518\n",
      "1755\n",
      "1634\n",
      "2127\n",
      "2223\n",
      "2910\n",
      "1503\n",
      "2395\n",
      "2033\n",
      "1694\n",
      "1876\n",
      "1795\n",
      "2693\n",
      "1612\n",
      "1634\n",
      "1524\n",
      "2130\n",
      "3106\n",
      "1723\n",
      "1785\n",
      "1813\n",
      "1654\n",
      "2340\n",
      "1820\n",
      "3490\n",
      "1868\n",
      "1568\n",
      "2539\n",
      "3074\n",
      "2002\n",
      "2499\n",
      "1683\n",
      "1538\n",
      "1952\n",
      "2111\n",
      "2105\n",
      "1567\n",
      "1505\n",
      "2062\n",
      "3527\n",
      "2075\n",
      "1820\n",
      "3577\n",
      "1986\n",
      "1505\n",
      "3513\n",
      "1825\n",
      "1932\n",
      "1661\n",
      "2253\n",
      "3471\n",
      "2070\n",
      "1669\n",
      "3441\n",
      "1696\n",
      "1798\n",
      "1563\n",
      "1934\n",
      "1984\n",
      "1685\n",
      "1792\n",
      "3087\n",
      "3249\n",
      "2080\n",
      "3493\n",
      "1721\n",
      "3597\n",
      "1747\n",
      "1959\n",
      "1818\n",
      "1619\n",
      "2520\n",
      "2778\n",
      "1984\n",
      "2373\n",
      "3106\n",
      "3499\n",
      "3269\n",
      "3347\n",
      "2242\n",
      "1676\n",
      "2081\n",
      "3420\n",
      "3097\n",
      "1869\n",
      "2627\n",
      "2925\n",
      "1769\n",
      "2784\n",
      "3279\n",
      "1676\n",
      "1539\n",
      "1510\n",
      "2621\n",
      "2504\n",
      "1945\n",
      "1616\n",
      "2198\n",
      "1866\n",
      "3054\n",
      "1787\n",
      "1731\n",
      "1584\n",
      "1873\n",
      "1572\n",
      "3371\n",
      "3627\n",
      "1840\n",
      "2122\n",
      "1501\n",
      "1941\n",
      "2001\n",
      "2804\n",
      "1799\n",
      "1512\n",
      "1833\n",
      "2694\n",
      "2720\n",
      "1612\n",
      "2767\n",
      "1806\n",
      "2054\n",
      "2025\n",
      "2571\n",
      "2378\n",
      "2291\n",
      "2026\n",
      "1965\n",
      "1643\n",
      "2144\n",
      "1753\n",
      "1847\n",
      "1783\n",
      "2475\n",
      "1734\n",
      "2482\n",
      "1747\n",
      "1742\n",
      "2617\n",
      "3087\n",
      "3441\n",
      "2078\n",
      "1678\n",
      "2824\n",
      "2490\n",
      "1920\n",
      "1707\n",
      "3113\n",
      "2508\n",
      "1744\n",
      "1674\n",
      "1849\n",
      "2500\n",
      "1549\n",
      "2416\n",
      "3132\n",
      "3013\n",
      "2298\n",
      "1545\n",
      "1842\n",
      "3262\n",
      "3186\n",
      "1695\n",
      "3167\n",
      "3003\n",
      "1760\n",
      "1540\n",
      "2970\n",
      "3000\n",
      "1976\n",
      "2904\n",
      "2325\n",
      "2078\n",
      "3507\n",
      "2713\n",
      "3269\n",
      "1569\n",
      "1707\n",
      "2313\n",
      "1543\n",
      "2573\n",
      "1621\n",
      "2273\n",
      "1912\n",
      "2305\n",
      "1948\n",
      "3223\n",
      "1535\n",
      "1663\n",
      "2344\n",
      "3607\n",
      "2292\n",
      "2402\n",
      "3055\n",
      "1783\n",
      "2746\n",
      "2410\n",
      "1716\n",
      "1961\n",
      "2135\n",
      "2424\n",
      "1507\n",
      "3053\n",
      "1783\n",
      "2294\n",
      "1862\n",
      "1938\n",
      "2692\n",
      "2263\n",
      "3329\n",
      "2787\n",
      "2048\n",
      "1872\n",
      "2567\n",
      "2352\n",
      "3286\n",
      "2445\n",
      "1952\n",
      "3627\n",
      "2027\n",
      "1878\n"
     ]
    }
   ],
   "source": [
    "for i in X_new:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cf635d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4772\n"
     ]
    }
   ],
   "source": [
    "X_new = []\n",
    "for i in X:\n",
    "    if len(i)>1500:\n",
    "        X_new.append(i)\n",
    "print(len(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "585547ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = specs +specs2\n",
    "waves = waves+waves2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e182919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3821, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined =  np.empty(shape=(3821, 2),dtype='object')\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2bd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8c321c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = np.array(specs)\n",
    "waves = np.array(waves)\n",
    "\n",
    "combined =  []\n",
    "for i in range(specs.shape[0]):\n",
    "    x = np.vstack((waves[i],specs[i])).T\n",
    "    #x = np.transpose((waves[i],specs[i]))\n",
    "    combined.append(x)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33dd3b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13876"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "28d6f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3832, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2fdd3fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.8141689e+03, 5.8308787e+00],\n",
       "        [3.8150483e+03, 5.9771714e+00],\n",
       "        [3.8159260e+03, 6.0892062e+00],\n",
       "        ...,\n",
       "        [9.1875576e+03, 3.7142074e+00],\n",
       "        [9.1896719e+03, 3.7322397e+00],\n",
       "        [9.1917852e+03, 3.7677941e+00]], dtype=float32),\n",
       " array([[3.8141689e+03, 7.2288718e+00],\n",
       "        [3.8150483e+03, 7.0888686e+00],\n",
       "        [3.8159260e+03, 7.1300449e+00],\n",
       "        ...,\n",
       "        [9.2150977e+03, 3.5925965e+00],\n",
       "        [9.2172227e+03, 3.5983169e+00],\n",
       "        [9.2193428e+03, 3.5601919e+00]], dtype=float32),\n",
       " array([[3802.77    ,   18.463863],\n",
       "        [3803.6448  ,   18.5413  ],\n",
       "        [3804.522   ,   18.727428],\n",
       "        ...,\n",
       "        [9210.8545  ,   10.70419 ],\n",
       "        [9212.979   ,   10.705066],\n",
       "        [9215.098   ,   10.669283]], dtype=float32)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2062b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array([])\n",
    "for i in combined:\n",
    "    x = np.append(x,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "20ed9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3da6e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91766\\AppData\\Local\\Temp\\ipykernel_12560\\3740881773.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y = np.asarray(combined)\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "52852dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13876,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9aa7c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9501878596214d558c3b1bc4b3d23597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4772, 3841, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "import numpy as np\n",
    "specs_inter = []\n",
    "temp = specs + specs2\n",
    "temp_new = []\n",
    "for i in temp:\n",
    "    if len(i)>1500:\n",
    "        temp_new.append(i)\n",
    "#specs, specs2 = [], []\n",
    "for i in tqdm(temp_new):\n",
    "    x = np.array(i)\n",
    "    i = 3841\n",
    "    z = i / len(x)\n",
    "    x_int = interpolation.zoom(x,z)\n",
    "    np.expand_dims(x_int, axis=0)\n",
    "    specs_inter.append(x_int)\n",
    "specs_inter = np.array(specs_inter)\n",
    "specs_inter = np.expand_dims(specs_inter, axis=2)\n",
    "print(specs_inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac2e6857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dd5386aea0446d83a4df6d2ff8f3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13972, 3841, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "import numpy as np\n",
    "specs_inter = []\n",
    "temp = specs + specs2\n",
    "\n",
    "for i in tqdm(temp):\n",
    "    x = np.array(i)\n",
    "    i = 3841\n",
    "    z = i / len(x)\n",
    "    x_int = interpolation.zoom(x,z)\n",
    "    np.expand_dims(x_int, axis=0)\n",
    "    specs_inter.append(x_int)\n",
    "specs_inter = np.array(specs_inter)\n",
    "specs_inter = np.expand_dims(specs_inter, axis=2)\n",
    "print(specs_inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa16cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list_Z_emi1 + list_Z_emi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fddb31d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6938)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babf7310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d86790fdbc34452b4bb4b8bb68f7d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13876, 3841)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "import numpy as np\n",
    "waves_inter = []\n",
    "temp = waves+ waves2\n",
    "#waves, waves2 = [], []\n",
    "for i in tqdm(temp):\n",
    "    x = np.array(i)\n",
    "    i = 3841\n",
    "    z = i / len(x)\n",
    "    x_int = interpolation.zoom(x,z)\n",
    "    #np.expand_dims(x_int, axis=0)\n",
    "    waves_inter.append(x_int)\n",
    "#waves_inter = np.array(waves_inter)\n",
    "#specs_inter = np.expand_dims(specs_inter, axis=2)\n",
    "#print(waves_inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0971b1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_vhstack_dispatcher() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaves_inter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecs_inter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:4\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _vhstack_dispatcher() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "stack = np.hstack(waves_inter, specs_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebe46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8111bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13902\n"
     ]
    }
   ],
   "source": [
    "y1 = np.array(list(np.ones(6951))+list(np.zeros(6951)))\n",
    "y2 = np.array(list(np.zeros(6951))+list(np.ones(6951)))\n",
    "y = np.dstack((y1,y2))[0].tolist()\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d4cbb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1.0  0.0\n",
      "0  1.0  0.0\n",
      "1  1.0  0.0\n",
      "2  1.0  0.0\n",
      "3  1.0  0.0\n",
      "4  1.0  0.0\n",
      "(13902, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tqdm\n",
    "lab_head = ['mg2','non']\n",
    "with open('D:\\\\GalMer\\\\labels.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(lab_head)\n",
    "\n",
    "p=0\n",
    "with open('./labels.csv', 'a', newline='') as file:\n",
    "    for i in range(6952):\n",
    "        label = np.zeros(len(lab_head))\n",
    "        label[0], label[1] = 1 , 0 \n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(label)\n",
    "    for i in range(6951):\n",
    "        label = np.zeros(len(lab_head))\n",
    "        label[0], label[1] = 0, 1\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(label)\n",
    "\n",
    "label = pd.read_csv('labels.csv')\n",
    "print(label.head())\n",
    "label = np.array(label)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9251c058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6938.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eeac109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13972,)\n"
     ]
    }
   ],
   "source": [
    "label = np.array(list(np.ones(6986))+list(np.zeros(6986)))\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a9280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab31357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 11177 11177\n",
      "testing data: 2795 2795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(specs_inter, label, random_state=0, train_size = .8)\n",
    "print('training data:', len(X_train), len(y_train))\n",
    "print('testing data:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0c06390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13900, 3841, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e936fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 11100 11100\n",
      "testing data: 2776 2776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined, label, random_state=0, train_size = .8)\n",
    "print('training data:', len(X_train), len(y_train))\n",
    "print('testing data:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4227c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_inter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a2275bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f390bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=0aa0336bf64e7f7eac9067d3a52a14f23251d2cd5f40cbeeee016616a47802d2\n",
      "  Stored in directory: c:\\users\\adars\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3464d8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 3827, 96)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1275, 96)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1271, 256)         123136    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 423, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 423, 256)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 421, 384)          295296    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 419, 384)          442752    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 417, 256)          295168    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 139, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 35584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              36439040  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,647,553\n",
      "Trainable params: 38,647,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=96, kernel_size=15, activation='relu', input_shape=(3841,1)))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=384, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=384, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "feb46f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "559/559 - 264s - loss: 0.0451 - accuracy: 0.9845 - 264s/epoch - 473ms/step\n",
      "Epoch 2/5\n",
      "559/559 - 270s - loss: 0.0551 - accuracy: 0.9814 - 270s/epoch - 483ms/step\n",
      "Epoch 3/5\n",
      "559/559 - 257s - loss: 0.0445 - accuracy: 0.9838 - 257s/epoch - 459ms/step\n",
      "Epoch 4/5\n",
      "559/559 - 261s - loss: 0.0358 - accuracy: 0.9871 - 261s/epoch - 467ms/step\n",
      "Epoch 5/5\n",
      "559/559 - 272s - loss: 0.0484 - accuracy: 0.9836 - 272s/epoch - 487ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164bdf09f70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b63e6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [51,54,56,59,64,58,74,78,80,83, 85,87,89,90,91.75,93.43,94.62,95.87,96.37,96.90, 97.27,97.07,97.49,97.28, 97.79, 98.45,\n",
    "       98.14,98.38,98.71, 98.36]\n",
    "y = np.arange(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fed2051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(y,data)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.savefig('accuracy.png', dpi=1000, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d224530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(x, y_pred, labels=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "808c3be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1244,  188],\n",
       "       [ 256, 1106]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab8a7427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.style.use('seaborn')\n",
    "\n",
    "df_cm = pd.DataFrame(cm, \n",
    "    index = [i for i in range(cm.shape[0])],\n",
    "    columns = [i for i in range(cm.shape[1])])\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "res = sn.heatmap(df_cm, annot=True, fmt='.2f', cmap=cmap)\n",
    "\n",
    "res.invert_yaxis()\n",
    "\n",
    "#plt.yticks([0.5,1.5,2.5], [ '0', '1', '2'],va='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Actual Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "\n",
    "plt.savefig('confusion_matrix_1.png', dpi=1000, bbox_inches='tight' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "765ccf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\IUCAA\\\\mg2'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48a17404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 17s 155ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72b00c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2577\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]<0.5:\n",
    "        y_pred.append(0)\n",
    "    elif pred[i]>= 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d94143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7eec968",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x[2577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "639a231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2794"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2eaf3465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 14s - loss: nan - accuracy: 0.8408 - 14s/epoch - 159ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.8407871127128601]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bebe737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [0.00044581]\n",
      "1.0 [0.998478]\n",
      "0.0 [0.01571688]\n",
      "0.0 [8.142346e-05]\n",
      "1.0 [0.24305384]\n",
      "0.0 [0.02215316]\n",
      "1.0 [3.6117366e-05]\n",
      "0.0 [6.432623e-05]\n",
      "0.0 [0.10428217]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [3.2772373e-06]\n",
      "1.0 [1.]\n",
      "0.0 [1.1652538e-05]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.29513305]\n",
      "1.0 [0.3022333]\n",
      "0.0 [0.0018295]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [7.3106414e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.04915718]\n",
      "0.0 [1.]\n",
      "0.0 [8.39849e-06]\n",
      "1.0 [1.]\n",
      "1.0 [0.98486835]\n",
      "1.0 [1.]\n",
      "0.0 [0.00587118]\n",
      "1.0 [1.]\n",
      "0.0 [6.088726e-05]\n",
      "0.0 [3.2772637e-05]\n",
      "0.0 [0.00030922]\n",
      "1.0 [0.952787]\n",
      "1.0 [1.]\n",
      "0.0 [0.00714278]\n",
      "1.0 [1.]\n",
      "1.0 [0.9748644]\n",
      "0.0 [4.654489e-06]\n",
      "0.0 [0.001059]\n",
      "1.0 [1.]\n",
      "0.0 [1.3857135e-06]\n",
      "0.0 [0.91425806]\n",
      "1.0 [1.]\n",
      "0.0 [8.427203e-06]\n",
      "0.0 [5.7657476e-06]\n",
      "1.0 [1.]\n",
      "1.0 [0.99901694]\n",
      "0.0 [0.9995724]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.9341851]\n",
      "0.0 [0.00052875]\n",
      "0.0 [0.00066052]\n",
      "1.0 [0.9939281]\n",
      "0.0 [2.1418622e-05]\n",
      "1.0 [0.8002697]\n",
      "0.0 [0.00023009]\n",
      "0.0 [0.07264572]\n",
      "1.0 [0.9985556]\n",
      "0.0 [0.01748648]\n",
      "1.0 [0.9899625]\n",
      "1.0 [0.7599398]\n",
      "0.0 [0.01075829]\n",
      "0.0 [0.41585034]\n",
      "1.0 [1.]\n",
      "0.0 [0.02603976]\n",
      "0.0 [1.1412327e-05]\n",
      "1.0 [1.]\n",
      "0.0 [2.9060981e-10]\n",
      "1.0 [1.]\n",
      "0.0 [0.03151606]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999964]\n",
      "1.0 [0.99992484]\n",
      "0.0 [0.00103205]\n",
      "1.0 [1.]\n",
      "1.0 [0.99846625]\n",
      "1.0 [0.29568276]\n",
      "1.0 [1.]\n",
      "0.0 [3.2578726e-05]\n",
      "1.0 [0.999975]\n",
      "0.0 [0.5152928]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [1.6403998e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.9832427]\n",
      "1.0 [0.00415337]\n",
      "1.0 [1.]\n",
      "1.0 [0.9933655]\n",
      "1.0 [0.9462746]\n",
      "1.0 [0.9999996]\n",
      "1.0 [0.00202158]\n",
      "0.0 [5.5781795e-05]\n",
      "0.0 [0.01483983]\n",
      "1.0 [0.05407953]\n",
      "1.0 [1.]\n",
      "0.0 [1.]\n",
      "0.0 [0.80764973]\n",
      "1.0 [1.]\n",
      "1.0 [0.03520128]\n",
      "0.0 [0.01814755]\n",
      "1.0 [0.99999976]\n",
      "0.0 [0.00057094]\n",
      "1.0 [0.98401475]\n",
      "0.0 [0.00128634]\n",
      "0.0 [0.03132229]\n",
      "1.0 [0.30910993]\n",
      "1.0 [1.]\n",
      "0.0 [0.4435675]\n",
      "0.0 [0.7536862]\n",
      "0.0 [0.00039693]\n",
      "1.0 [1.]\n",
      "0.0 [0.00540293]\n",
      "1.0 [0.98548454]\n",
      "1.0 [1.]\n",
      "0.0 [0.00815125]\n",
      "1.0 [1.]\n",
      "0.0 [0.8739275]\n",
      "0.0 [0.00068142]\n",
      "1.0 [0.9997911]\n",
      "0.0 [4.8596792e-08]\n",
      "0.0 [0.07946442]\n",
      "1.0 [2.504414e-06]\n",
      "1.0 [0.9999999]\n",
      "1.0 [1.]\n",
      "1.0 [0.9964372]\n",
      "1.0 [0.15386386]\n",
      "0.0 [1.4028166e-07]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999905]\n",
      "0.0 [0.11338697]\n",
      "1.0 [0.99999565]\n",
      "0.0 [0.2799757]\n",
      "0.0 [0.00284401]\n",
      "0.0 [0.07384251]\n",
      "1.0 [0.00559755]\n",
      "1.0 [1.]\n",
      "0.0 [0.659211]\n",
      "0.0 [0.00010436]\n",
      "1.0 [0.9629033]\n",
      "1.0 [0.99999696]\n",
      "1.0 [0.9264443]\n",
      "1.0 [0.9843551]\n",
      "0.0 [0.0015271]\n",
      "0.0 [9.504597e-06]\n",
      "0.0 [0.00017633]\n",
      "0.0 [0.00025336]\n",
      "1.0 [0.05360207]\n",
      "1.0 [1.1154803e-08]\n",
      "0.0 [0.00833184]\n",
      "1.0 [0.9999962]\n",
      "0.0 [0.44408464]\n",
      "0.0 [0.0049118]\n",
      "1.0 [1.]\n",
      "0.0 [0.00038483]\n",
      "0.0 [0.00124088]\n",
      "1.0 [0.06069701]\n",
      "1.0 [0.9998686]\n",
      "0.0 [5.517871e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.08044727]\n",
      "1.0 [1.]\n",
      "1.0 [0.9996601]\n",
      "1.0 [1.]\n",
      "1.0 [0.95194477]\n",
      "0.0 [0.00774671]\n",
      "0.0 [0.04290169]\n",
      "0.0 [5.310035e-07]\n",
      "1.0 [1.]\n",
      "1.0 [1.5931645e-06]\n",
      "0.0 [0.27864373]\n",
      "1.0 [1.]\n",
      "0.0 [0.23813473]\n",
      "0.0 [0.00015505]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [3.2757576e-05]\n",
      "0.0 [5.68495e-06]\n",
      "0.0 [2.3518443e-07]\n",
      "0.0 [0.02785246]\n",
      "1.0 [0.99942446]\n",
      "0.0 [0.00646605]\n",
      "0.0 [1.0917322e-05]\n",
      "0.0 [0.08387297]\n",
      "0.0 [6.813401e-07]\n",
      "1.0 [0.9996815]\n",
      "1.0 [1.]\n",
      "1.0 [0.9729482]\n",
      "1.0 [1.]\n",
      "1.0 [0.99988717]\n",
      "0.0 [8.1563805e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.001919]\n",
      "1.0 [0.9371263]\n",
      "0.0 [0.00062078]\n",
      "0.0 [0.01228172]\n",
      "1.0 [0.99973243]\n",
      "1.0 [1.5279264e-05]\n",
      "0.0 [1.2125723e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999942]\n",
      "1.0 [0.9929078]\n",
      "0.0 [2.4167908e-05]\n",
      "1.0 [0.9744007]\n",
      "1.0 [0.06299511]\n",
      "1.0 [0.05058277]\n",
      "1.0 [0.4654575]\n",
      "0.0 [2.7865419e-05]\n",
      "0.0 [0.00013792]\n",
      "0.0 [0.03010872]\n",
      "0.0 [1.7266224e-08]\n",
      "1.0 [0.04112422]\n",
      "0.0 [0.01896235]\n",
      "0.0 [0.0211026]\n",
      "0.0 [1.5466578e-07]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999185]\n",
      "0.0 [0.00911343]\n",
      "1.0 [0.99958384]\n",
      "0.0 [2.784539e-05]\n",
      "0.0 [0.00028602]\n",
      "1.0 [0.9579701]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.4798586]\n",
      "1.0 [1.]\n",
      "0.0 [0.13778578]\n",
      "1.0 [0.2917628]\n",
      "1.0 [0.46013486]\n",
      "0.0 [0.01745657]\n",
      "1.0 [1.]\n",
      "0.0 [0.06232157]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9985154]\n",
      "1.0 [0.16286498]\n",
      "1.0 [1.]\n",
      "0.0 [0.00030596]\n",
      "0.0 [0.00104925]\n",
      "1.0 [0.9993733]\n",
      "1.0 [0.8460034]\n",
      "0.0 [2.1432275e-07]\n",
      "0.0 [4.2250545e-07]\n",
      "0.0 [0.0019069]\n",
      "0.0 [0.00030731]\n",
      "0.0 [0.99988025]\n",
      "1.0 [0.9999981]\n",
      "0.0 [2.543694e-05]\n",
      "0.0 [2.9261074e-08]\n",
      "0.0 [0.00026277]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99986047]\n",
      "1.0 [0.05499768]\n",
      "0.0 [1.]\n",
      "0.0 [3.4784392e-08]\n",
      "0.0 [0.00129177]\n",
      "1.0 [0.9999707]\n",
      "0.0 [0.16435461]\n",
      "0.0 [5.046389e-05]\n",
      "0.0 [8.394256e-07]\n",
      "0.0 [0.02949649]\n",
      "1.0 [0.9999966]\n",
      "1.0 [1.]\n",
      "1.0 [0.37054867]\n",
      "1.0 [0.06237551]\n",
      "0.0 [0.00341627]\n",
      "1.0 [0.97419935]\n",
      "0.0 [0.00106585]\n",
      "1.0 [0.998601]\n",
      "0.0 [1.0169299e-06]\n",
      "1.0 [0.99786913]\n",
      "0.0 [0.01058459]\n",
      "0.0 [0.00068664]\n",
      "0.0 [0.99999815]\n",
      "1.0 [0.97792846]\n",
      "1.0 [1.]\n",
      "0.0 [0.0049028]\n",
      "0.0 [1.982144e-08]\n",
      "0.0 [0.00220773]\n",
      "1.0 [0.26849777]\n",
      "1.0 [0.9916894]\n",
      "0.0 [0.00691756]\n",
      "1.0 [1.]\n",
      "0.0 [0.00180817]\n",
      "0.0 [2.2326863e-07]\n",
      "1.0 [1.]\n",
      "0.0 [5.5981272e-06]\n",
      "0.0 [0.02326684]\n",
      "0.0 [0.00961086]\n",
      "1.0 [1.]\n",
      "1.0 [0.84012395]\n",
      "1.0 [0.999749]\n",
      "1.0 [0.9999815]\n",
      "1.0 [1.]\n",
      "0.0 [0.30568254]\n",
      "0.0 [0.00019998]\n",
      "0.0 [0.95490146]\n",
      "1.0 [0.9999719]\n",
      "1.0 [1.]\n",
      "1.0 [0.00046968]\n",
      "1.0 [1.]\n",
      "0.0 [1.6682803e-07]\n",
      "1.0 [0.6987406]\n",
      "1.0 [0.9751444]\n",
      "0.0 [5.8101803e-05]\n",
      "0.0 [0.9983375]\n",
      "0.0 [0.99864006]\n",
      "0.0 [3.988313e-07]\n",
      "0.0 [0.00771827]\n",
      "0.0 [0.00076773]\n",
      "1.0 [1.]\n",
      "0.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00287973]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [5.028139e-06]\n",
      "0.0 [0.00046186]\n",
      "0.0 [8.455603e-05]\n",
      "1.0 [0.9998363]\n",
      "1.0 [0.00457402]\n",
      "1.0 [0.9999965]\n",
      "0.0 [0.00182634]\n",
      "0.0 [0.02134156]\n",
      "0.0 [0.0039357]\n",
      "1.0 [0.9999405]\n",
      "0.0 [0.00780771]\n",
      "0.0 [0.00025886]\n",
      "0.0 [1.4461755e-05]\n",
      "1.0 [0.51648986]\n",
      "0.0 [0.97561234]\n",
      "1.0 [0.34438476]\n",
      "0.0 [0.00196065]\n",
      "0.0 [9.958505e-06]\n",
      "0.0 [2.8916565e-05]\n",
      "0.0 [0.0254035]\n",
      "1.0 [0.00201605]\n",
      "1.0 [0.10769728]\n",
      "1.0 [0.01202656]\n",
      "0.0 [0.00281584]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.9998575]\n",
      "1.0 [0.9999985]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999979]\n",
      "0.0 [2.624132e-05]\n",
      "0.0 [0.01262361]\n",
      "0.0 [0.43048573]\n",
      "0.0 [0.00225736]\n",
      "0.0 [5.608289e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00951183]\n",
      "0.0 [0.21227951]\n",
      "0.0 [0.00172966]\n",
      "1.0 [0.9994802]\n",
      "1.0 [0.99733496]\n",
      "1.0 [0.02797506]\n",
      "1.0 [0.75282913]\n",
      "1.0 [0.9999958]\n",
      "0.0 [0.00126443]\n",
      "0.0 [2.2298486e-06]\n",
      "0.0 [0.0282038]\n",
      "0.0 [0.01651545]\n",
      "0.0 [0.0006664]\n",
      "0.0 [0.10491543]\n",
      "0.0 [0.15046266]\n",
      "0.0 [0.00049608]\n",
      "0.0 [8.807889e-05]\n",
      "0.0 [1.4589128e-07]\n",
      "0.0 [0.22514772]\n",
      "1.0 [0.99990433]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999399]\n",
      "1.0 [0.9999962]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999964]\n",
      "0.0 [0.75863504]\n",
      "0.0 [0.00804447]\n",
      "1.0 [0.8821714]\n",
      "0.0 [0.02142441]\n",
      "1.0 [0.9999998]\n",
      "0.0 [7.049849e-05]\n",
      "0.0 [0.00071067]\n",
      "1.0 [0.9999541]\n",
      "0.0 [0.23542495]\n",
      "1.0 [0.9999966]\n",
      "1.0 [1.5853091e-06]\n",
      "1.0 [0.9976569]\n",
      "1.0 [0.99836123]\n",
      "0.0 [0.00035369]\n",
      "0.0 [7.910295e-05]\n",
      "0.0 [0.98514783]\n",
      "0.0 [5.1447223e-06]\n",
      "0.0 [0.44657668]\n",
      "0.0 [0.03919937]\n",
      "1.0 [0.99999684]\n",
      "0.0 [0.08809275]\n",
      "0.0 [0.01405553]\n",
      "1.0 [0.08521976]\n",
      "1.0 [1.]\n",
      "0.0 [1.]\n",
      "0.0 [0.00020878]\n",
      "0.0 [0.5489548]\n",
      "0.0 [0.03167028]\n",
      "1.0 [0.99391913]\n",
      "0.0 [5.098003e-05]\n",
      "0.0 [0.00079523]\n",
      "1.0 [1.]\n",
      "0.0 [0.12805247]\n",
      "0.0 [0.00073184]\n",
      "0.0 [0.00015552]\n",
      "1.0 [1.]\n",
      "1.0 [0.9839595]\n",
      "1.0 [1.]\n",
      "0.0 [0.98380786]\n",
      "0.0 [0.1940147]\n",
      "1.0 [1.]\n",
      "0.0 [0.4950761]\n",
      "1.0 [0.002186]\n",
      "1.0 [0.00021171]\n",
      "0.0 [2.9517207e-05]\n",
      "1.0 [0.73605186]\n",
      "0.0 [0.00258949]\n",
      "1.0 [0.99999106]\n",
      "0.0 [4.3141505e-08]\n",
      "1.0 [1.]\n",
      "0.0 [0.16938023]\n",
      "0.0 [8.87056e-06]\n",
      "0.0 [0.0003995]\n",
      "1.0 [0.5000755]\n",
      "0.0 [4.9727973e-06]\n",
      "1.0 [1.]\n",
      "0.0 [0.5260646]\n",
      "1.0 [0.99999005]\n",
      "0.0 [0.00112063]\n",
      "0.0 [1.]\n",
      "1.0 [0.99999654]\n",
      "1.0 [1.]\n",
      "0.0 [0.30839154]\n",
      "0.0 [0.00190901]\n",
      "1.0 [0.9939651]\n",
      "1.0 [6.789578e-06]\n",
      "0.0 [1.]\n",
      "1.0 [0.8802422]\n",
      "0.0 [0.00027324]\n",
      "0.0 [0.9999258]\n",
      "0.0 [0.12484024]\n",
      "1.0 [0.99999994]\n",
      "0.0 [0.01298089]\n",
      "0.0 [8.501962e-06]\n",
      "0.0 [0.00460348]\n",
      "1.0 [0.01438896]\n",
      "0.0 [0.13372584]\n",
      "0.0 [0.06102603]\n",
      "1.0 [0.9999825]\n",
      "1.0 [0.00458577]\n",
      "1.0 [0.9997562]\n",
      "1.0 [1.]\n",
      "0.0 [0.00031239]\n",
      "0.0 [0.06986769]\n",
      "0.0 [0.95031697]\n",
      "0.0 [1.]\n",
      "0.0 [0.00021907]\n",
      "1.0 [1.]\n",
      "1.0 [0.9993226]\n",
      "0.0 [0.29087824]\n",
      "1.0 [7.647838e-05]\n",
      "0.0 [2.7146365e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [9.436438e-07]\n",
      "1.0 [0.9999966]\n",
      "1.0 [0.00500552]\n",
      "0.0 [3.3140917e-05]\n",
      "1.0 [0.9999873]\n",
      "0.0 [7.468652e-05]\n",
      "0.0 [2.123819e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.9948718]\n",
      "0.0 [0.96907014]\n",
      "1.0 [0.99997765]\n",
      "0.0 [2.762994e-05]\n",
      "0.0 [0.00024892]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [2.4985238e-05]\n",
      "0.0 [0.00279848]\n",
      "1.0 [1.]\n",
      "0.0 [5.5857057e-05]\n",
      "0.0 [0.15164024]\n",
      "0.0 [0.9843341]\n",
      "1.0 [0.9805912]\n",
      "1.0 [0.98839533]\n",
      "1.0 [1.]\n",
      "0.0 [0.00648873]\n",
      "0.0 [0.01398928]\n",
      "0.0 [1.2731466e-07]\n",
      "0.0 [0.00033221]\n",
      "0.0 [0.00202806]\n",
      "1.0 [1.]\n",
      "0.0 [0.00349992]\n",
      "1.0 [0.9994245]\n",
      "0.0 [0.13954942]\n",
      "1.0 [1.]\n",
      "1.0 [0.9864219]\n",
      "0.0 [0.0001681]\n",
      "0.0 [4.4008175e-07]\n",
      "0.0 [0.009542]\n",
      "1.0 [0.8883122]\n",
      "1.0 [0.00409976]\n",
      "0.0 [6.298006e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [2.7588498e-05]\n",
      "0.0 [0.7009416]\n",
      "0.0 [0.00152815]\n",
      "1.0 [0.9999968]\n",
      "0.0 [0.01240841]\n",
      "1.0 [0.9999991]\n",
      "1.0 [0.99937016]\n",
      "1.0 [0.9999995]\n",
      "1.0 [0.0089031]\n",
      "1.0 [1.]\n",
      "0.0 [0.9942257]\n",
      "1.0 [1.]\n",
      "0.0 [3.581253e-08]\n",
      "0.0 [8.650286e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.03346592]\n",
      "1.0 [0.00801669]\n",
      "1.0 [0.99998844]\n",
      "1.0 [1.]\n",
      "0.0 [5.195816e-07]\n",
      "0.0 [4.5869157e-05]\n",
      "0.0 [6.012537e-10]\n",
      "1.0 [0.837487]\n",
      "1.0 [0.9994747]\n",
      "0.0 [0.14926383]\n",
      "0.0 [1.7209946e-05]\n",
      "0.0 [0.00541486]\n",
      "1.0 [0.99999976]\n",
      "1.0 [0.98708826]\n",
      "0.0 [0.00103928]\n",
      "0.0 [0.00406114]\n",
      "1.0 [1.]\n",
      "0.0 [0.00051298]\n",
      "1.0 [1.]\n",
      "0.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999315]\n",
      "1.0 [0.00310337]\n",
      "1.0 [0.999724]\n",
      "0.0 [0.7972685]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.01117001]\n",
      "1.0 [0.9999972]\n",
      "1.0 [0.9994652]\n",
      "0.0 [0.0001399]\n",
      "0.0 [0.00014585]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9793025]\n",
      "0.0 [0.29903793]\n",
      "0.0 [0.01862158]\n",
      "1.0 [0.970572]\n",
      "1.0 [1.]\n",
      "1.0 [0.9889824]\n",
      "1.0 [1.]\n",
      "1.0 [0.25542948]\n",
      "1.0 [1.]\n",
      "0.0 [0.15286672]\n",
      "1.0 [0.79122716]\n",
      "0.0 [0.02263699]\n",
      "0.0 [5.7553654e-05]\n",
      "0.0 [0.00654956]\n",
      "0.0 [0.00161845]\n",
      "0.0 [0.00017455]\n",
      "0.0 [0.00564713]\n",
      "1.0 [1.]\n",
      "1.0 [0.98973143]\n",
      "1.0 [1.]\n",
      "1.0 [0.11933751]\n",
      "0.0 [0.19852048]\n",
      "0.0 [1.0493155e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00073121]\n",
      "0.0 [0.00282626]\n",
      "1.0 [1.]\n",
      "0.0 [2.316107e-05]\n",
      "1.0 [0.9981718]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [4.1593765e-05]\n",
      "1.0 [0.00022271]\n",
      "0.0 [1.1484912e-05]\n",
      "1.0 [1.]\n",
      "0.0 [4.6781187e-07]\n",
      "0.0 [0.04799758]\n",
      "1.0 [0.95638365]\n",
      "0.0 [0.00010092]\n",
      "0.0 [1.5908605e-05]\n",
      "0.0 [0.0767771]\n",
      "0.0 [0.00015941]\n",
      "0.0 [0.01567848]\n",
      "0.0 [1.9943223e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [4.6988847e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.84784424]\n",
      "1.0 [0.99999213]\n",
      "1.0 [0.9944789]\n",
      "1.0 [6.323412e-07]\n",
      "1.0 [1.]\n",
      "0.0 [0.00749837]\n",
      "1.0 [0.999999]\n",
      "0.0 [0.9999618]\n",
      "1.0 [0.99999934]\n",
      "0.0 [0.00032848]\n",
      "1.0 [0.99999744]\n",
      "0.0 [8.020517e-05]\n",
      "1.0 [1.]\n",
      "0.0 [9.1676004e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.999942]\n",
      "1.0 [0.9521928]\n",
      "0.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.10848165]\n",
      "0.0 [0.00135]\n",
      "0.0 [0.7954386]\n",
      "0.0 [0.00159357]\n",
      "0.0 [5.7798075e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00270233]\n",
      "1.0 [0.99910045]\n",
      "1.0 [0.9999998]\n",
      "0.0 [0.999782]\n",
      "1.0 [1.]\n",
      "0.0 [9.70689e-09]\n",
      "0.0 [0.7667283]\n",
      "0.0 [6.475556e-06]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.09191365]\n",
      "0.0 [0.19151762]\n",
      "0.0 [0.00017355]\n",
      "1.0 [0.4193005]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.16042086]\n",
      "1.0 [1.]\n",
      "1.0 [0.1992944]\n",
      "0.0 [0.0025061]\n",
      "1.0 [1.]\n",
      "0.0 [3.2126212e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [1.5101529e-05]\n",
      "0.0 [1.]\n",
      "1.0 [0.0072236]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999984]\n",
      "0.0 [7.6213524e-05]\n",
      "0.0 [0.00022474]\n",
      "1.0 [1.]\n",
      "0.0 [1.6684806e-11]\n",
      "1.0 [0.99390143]\n",
      "0.0 [0.999999]\n",
      "0.0 [0.83783203]\n",
      "1.0 [0.00050772]\n",
      "0.0 [0.01633117]\n",
      "1.0 [0.99999946]\n",
      "0.0 [0.0007129]\n",
      "0.0 [0.9988535]\n",
      "1.0 [1.5258716e-05]\n",
      "0.0 [0.9998782]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [1.8319223e-07]\n",
      "0.0 [0.21144378]\n",
      "1.0 [0.7096809]\n",
      "0.0 [1.7972494e-05]\n",
      "0.0 [2.3542314e-05]\n",
      "0.0 [0.00533863]\n",
      "1.0 [0.9976248]\n",
      "1.0 [0.92482084]\n",
      "0.0 [1.26063815e-05]\n",
      "0.0 [9.3441633e-07]\n",
      "0.0 [0.05420177]\n",
      "0.0 [2.4632692e-11]\n",
      "0.0 [0.00161475]\n",
      "0.0 [0.00064192]\n",
      "1.0 [0.03256186]\n",
      "1.0 [0.9999989]\n",
      "0.0 [0.00702467]\n",
      "1.0 [1.]\n",
      "0.0 [0.00072543]\n",
      "0.0 [0.00018787]\n",
      "0.0 [0.9896998]\n",
      "0.0 [0.03581167]\n",
      "1.0 [0.31141424]\n",
      "1.0 [1.]\n",
      "1.0 [5.3933286e-06]\n",
      "1.0 [0.9999992]\n",
      "1.0 [0.99994093]\n",
      "1.0 [0.99339414]\n",
      "0.0 [8.95853e-07]\n",
      "1.0 [0.99999946]\n",
      "1.0 [1.]\n",
      "0.0 [1.3841834e-05]\n",
      "0.0 [0.18862161]\n",
      "1.0 [0.96571046]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.06885273]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [4.767489e-07]\n",
      "0.0 [0.32050797]\n",
      "1.0 [1.]\n",
      "0.0 [0.00018844]\n",
      "1.0 [0.99999976]\n",
      "0.0 [0.03238079]\n",
      "1.0 [1.]\n",
      "1.0 [0.9951905]\n",
      "0.0 [2.0907524e-07]\n",
      "0.0 [0.00055469]\n",
      "1.0 [0.00731463]\n",
      "1.0 [1.]\n",
      "0.0 [7.041223e-07]\n",
      "1.0 [1.5152473e-08]\n",
      "0.0 [0.05409183]\n",
      "0.0 [0.00365038]\n",
      "1.0 [1.]\n",
      "0.0 [0.00141277]\n",
      "0.0 [0.98690575]\n",
      "0.0 [0.00983294]\n",
      "1.0 [0.9999931]\n",
      "0.0 [0.00455393]\n",
      "0.0 [9.851028e-05]\n",
      "1.0 [0.99952036]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999946]\n",
      "1.0 [1.]\n",
      "0.0 [1.0116505e-08]\n",
      "1.0 [0.9999972]\n",
      "1.0 [0.00010882]\n",
      "0.0 [0.00021275]\n",
      "1.0 [1.]\n",
      "0.0 [0.00138235]\n",
      "0.0 [1.7304634e-08]\n",
      "1.0 [0.99997133]\n",
      "1.0 [0.04727161]\n",
      "1.0 [0.997556]\n",
      "0.0 [0.00821601]\n",
      "1.0 [0.9992308]\n",
      "0.0 [0.00019606]\n",
      "1.0 [1.]\n",
      "1.0 [0.9997833]\n",
      "1.0 [0.0107446]\n",
      "1.0 [0.9999257]\n",
      "1.0 [0.9978337]\n",
      "1.0 [0.8885713]\n",
      "1.0 [1.]\n",
      "0.0 [0.9980855]\n",
      "1.0 [0.00012201]\n",
      "0.0 [0.24097556]\n",
      "0.0 [4.5289118e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.07890189]\n",
      "1.0 [0.99992424]\n",
      "0.0 [0.00079497]\n",
      "0.0 [1.2711585e-06]\n",
      "0.0 [5.869758e-05]\n",
      "0.0 [0.02302826]\n",
      "1.0 [1.]\n",
      "0.0 [0.0040253]\n",
      "0.0 [0.00721183]\n",
      "0.0 [0.00102061]\n",
      "0.0 [0.05793756]\n",
      "0.0 [0.2681973]\n",
      "1.0 [1.]\n",
      "0.0 [5.945601e-08]\n",
      "0.0 [0.00027566]\n",
      "0.0 [6.509523e-06]\n",
      "1.0 [0.90483695]\n",
      "0.0 [0.00085526]\n",
      "0.0 [3.4706768e-06]\n",
      "1.0 [0.9997274]\n",
      "1.0 [0.02482469]\n",
      "1.0 [0.00802981]\n",
      "0.0 [4.8472783e-05]\n",
      "0.0 [0.00135923]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [6.181319e-05]\n",
      "0.0 [2.08915e-07]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.12239979]\n",
      "0.0 [0.07155037]\n",
      "1.0 [0.99602294]\n",
      "1.0 [1.]\n",
      "1.0 [0.00138566]\n",
      "0.0 [0.01873143]\n",
      "0.0 [3.609244e-05]\n",
      "0.0 [0.0022092]\n",
      "0.0 [4.3276913e-08]\n",
      "0.0 [1.2615914e-08]\n",
      "1.0 [0.99985546]\n",
      "0.0 [5.2787925e-09]\n",
      "0.0 [3.0355599e-05]\n",
      "0.0 [0.00134382]\n",
      "1.0 [0.12536365]\n",
      "0.0 [0.03221441]\n",
      "1.0 [0.99485826]\n",
      "1.0 [1.]\n",
      "1.0 [2.7719725e-05]\n",
      "0.0 [0.04199347]\n",
      "0.0 [0.00029007]\n",
      "0.0 [0.00014988]\n",
      "0.0 [9.700869e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.00963757]\n",
      "1.0 [1.]\n",
      "0.0 [0.32966903]\n",
      "0.0 [0.00017787]\n",
      "0.0 [0.00050564]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999344]\n",
      "1.0 [1.]\n",
      "0.0 [1.]\n",
      "0.0 [0.00073464]\n",
      "1.0 [1.]\n",
      "1.0 [0.970522]\n",
      "1.0 [0.9728782]\n",
      "1.0 [1.]\n",
      "0.0 [0.03879527]\n",
      "0.0 [3.8336773e-05]\n",
      "1.0 [0.01032782]\n",
      "1.0 [1.]\n",
      "0.0 [0.7081997]\n",
      "1.0 [0.6807119]\n",
      "1.0 [0.00120247]\n",
      "1.0 [0.59958136]\n",
      "0.0 [1.2314124e-05]\n",
      "1.0 [0.01868806]\n",
      "0.0 [1.4518247e-06]\n",
      "0.0 [0.00407799]\n",
      "1.0 [1.]\n",
      "1.0 [0.99963844]\n",
      "1.0 [0.9999513]\n",
      "1.0 [0.9999106]\n",
      "0.0 [0.03409006]\n",
      "0.0 [0.0007026]\n",
      "0.0 [0.00195805]\n",
      "0.0 [0.01599574]\n",
      "0.0 [1.1307147e-05]\n",
      "0.0 [0.00055992]\n",
      "1.0 [0.00020725]\n",
      "0.0 [0.00014386]\n",
      "0.0 [0.002372]\n",
      "0.0 [0.00949117]\n",
      "0.0 [0.10277775]\n",
      "0.0 [0.00136157]\n",
      "0.0 [0.00012128]\n",
      "1.0 [1.]\n",
      "0.0 [0.00049217]\n",
      "1.0 [0.9999999]\n",
      "0.0 [1.0983825e-05]\n",
      "0.0 [0.1695631]\n",
      "0.0 [0.00012089]\n",
      "1.0 [0.01882394]\n",
      "0.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.9651031]\n",
      "0.0 [0.45268747]\n",
      "0.0 [0.9956686]\n",
      "0.0 [0.00342488]\n",
      "1.0 [0.96486187]\n",
      "1.0 [0.98661655]\n",
      "0.0 [0.02668695]\n",
      "0.0 [0.03527437]\n",
      "1.0 [0.9495769]\n",
      "0.0 [0.00646807]\n",
      "0.0 [0.00514488]\n",
      "1.0 [1.]\n",
      "0.0 [0.00349976]\n",
      "1.0 [0.99999946]\n",
      "1.0 [0.9959253]\n",
      "1.0 [0.9999775]\n",
      "0.0 [0.00020234]\n",
      "1.0 [0.5743716]\n",
      "1.0 [1.]\n",
      "0.0 [2.489849e-07]\n",
      "1.0 [1.]\n",
      "1.0 [0.00048485]\n",
      "0.0 [0.03558055]\n",
      "1.0 [0.00189401]\n",
      "0.0 [5.5872373e-09]\n",
      "0.0 [0.00018709]\n",
      "1.0 [1.]\n",
      "1.0 [0.00560375]\n",
      "1.0 [1.]\n",
      "1.0 [0.9998108]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999946]\n",
      "0.0 [2.1408619e-07]\n",
      "0.0 [5.1390878e-05]\n",
      "1.0 [0.7855536]\n",
      "0.0 [7.682793e-05]\n",
      "0.0 [9.8068165e-05]\n",
      "0.0 [0.00012708]\n",
      "0.0 [0.928598]\n",
      "0.0 [0.00177963]\n",
      "1.0 [1.]\n",
      "0.0 [0.9954343]\n",
      "1.0 [0.9887125]\n",
      "1.0 [0.99999005]\n",
      "1.0 [0.99999595]\n",
      "1.0 [1.]\n",
      "0.0 [0.00234997]\n",
      "0.0 [0.00036788]\n",
      "0.0 [6.9958257e-09]\n",
      "1.0 [0.9999974]\n",
      "1.0 [1.]\n",
      "0.0 [1.]\n",
      "0.0 [0.00239612]\n",
      "1.0 [1.]\n",
      "0.0 [1.3262631e-06]\n",
      "1.0 [6.433954e-05]\n",
      "0.0 [0.00137123]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.6165756]\n",
      "0.0 [0.00544488]\n",
      "0.0 [0.00095097]\n",
      "1.0 [0.99983484]\n",
      "0.0 [6.740565e-05]\n",
      "0.0 [0.00014571]\n",
      "0.0 [0.97753924]\n",
      "1.0 [0.9998901]\n",
      "1.0 [0.02393111]\n",
      "1.0 [1.]\n",
      "0.0 [0.8931515]\n",
      "1.0 [0.00772418]\n",
      "0.0 [0.9070614]\n",
      "0.0 [5.399937e-06]\n",
      "0.0 [0.00084392]\n",
      "0.0 [6.3901234e-06]\n",
      "1.0 [1.]\n",
      "1.0 [0.7950422]\n",
      "1.0 [0.99903095]\n",
      "0.0 [0.5494129]\n",
      "1.0 [1.]\n",
      "0.0 [0.0078743]\n",
      "0.0 [0.99796784]\n",
      "0.0 [0.00485434]\n",
      "1.0 [0.00242993]\n",
      "0.0 [0.00052577]\n",
      "0.0 [1.2471591e-07]\n",
      "0.0 [1.05402265e-08]\n",
      "0.0 [0.23543578]\n",
      "1.0 [0.00757657]\n",
      "0.0 [0.00013561]\n",
      "0.0 [4.3724736e-05]\n",
      "0.0 [0.00041752]\n",
      "1.0 [1.]\n",
      "1.0 [0.00032342]\n",
      "0.0 [1.]\n",
      "0.0 [0.11052085]\n",
      "1.0 [0.99874735]\n",
      "1.0 [1.]\n",
      "0.0 [0.00016298]\n",
      "1.0 [1.]\n",
      "0.0 [0.0001219]\n",
      "0.0 [0.00317989]\n",
      "1.0 [0.21211876]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.9203343]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00031049]\n",
      "0.0 [0.03063389]\n",
      "1.0 [1.]\n",
      "0.0 [9.58384e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.06701539]\n",
      "1.0 [0.01088926]\n",
      "1.0 [1.]\n",
      "0.0 [9.064815e-06]\n",
      "0.0 [0.05316921]\n",
      "0.0 [0.00111267]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00052837]\n",
      "1.0 [1.]\n",
      "0.0 [0.00845014]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99796396]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999994]\n",
      "0.0 [7.99188e-05]\n",
      "1.0 [0.9999381]\n",
      "1.0 [0.00036343]\n",
      "0.0 [0.00029254]\n",
      "1.0 [0.9996611]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.0029703]\n",
      "1.0 [0.01075089]\n",
      "1.0 [1.]\n",
      "0.0 [0.00318932]\n",
      "0.0 [0.0005094]\n",
      "1.0 [0.99998266]\n",
      "0.0 [0.67956084]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00152029]\n",
      "0.0 [0.00172274]\n",
      "0.0 [0.00022052]\n",
      "1.0 [1.]\n",
      "1.0 [0.0039067]\n",
      "1.0 [0.76481026]\n",
      "1.0 [1.]\n",
      "1.0 [0.26231626]\n",
      "0.0 [5.9055885e-09]\n",
      "0.0 [0.99998695]\n",
      "1.0 [0.03231371]\n",
      "0.0 [0.4306356]\n",
      "1.0 [1.]\n",
      "0.0 [1.1670944e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.21058995]\n",
      "0.0 [0.25285736]\n",
      "0.0 [2.1917594e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00959043]\n",
      "1.0 [0.9999999]\n",
      "1.0 [0.9677447]\n",
      "0.0 [0.00137244]\n",
      "0.0 [0.12738575]\n",
      "0.0 [0.00011227]\n",
      "0.0 [0.00443317]\n",
      "0.0 [3.4235698e-05]\n",
      "0.0 [0.93829334]\n",
      "1.0 [0.984463]\n",
      "0.0 [0.00206898]\n",
      "1.0 [1.]\n",
      "0.0 [0.00042768]\n",
      "0.0 [0.2734535]\n",
      "0.0 [0.00434917]\n",
      "1.0 [1.]\n",
      "0.0 [1.2321256e-06]\n",
      "0.0 [0.9580081]\n",
      "0.0 [0.87545234]\n",
      "0.0 [1.3572467e-05]\n",
      "1.0 [1.]\n",
      "0.0 [2.8365077e-05]\n",
      "1.0 [0.00116978]\n",
      "0.0 [0.05686436]\n",
      "1.0 [1.]\n",
      "0.0 [6.524545e-05]\n",
      "0.0 [0.969754]\n",
      "0.0 [0.11920227]\n",
      "0.0 [0.8368773]\n",
      "0.0 [0.93119866]\n",
      "0.0 [6.139103e-06]\n",
      "1.0 [2.5918048e-06]\n",
      "1.0 [0.9999999]\n",
      "0.0 [3.126152e-07]\n",
      "0.0 [0.00287208]\n",
      "0.0 [0.00015785]\n",
      "1.0 [0.00154862]\n",
      "0.0 [2.4326127e-06]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.98999757]\n",
      "0.0 [0.00166661]\n",
      "1.0 [1.]\n",
      "0.0 [0.11437477]\n",
      "1.0 [0.99877524]\n",
      "0.0 [0.00027449]\n",
      "1.0 [1.]\n",
      "1.0 [0.9452448]\n",
      "0.0 [8.160281e-09]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999946]\n",
      "0.0 [1.]\n",
      "0.0 [0.00010066]\n",
      "1.0 [0.9999984]\n",
      "0.0 [5.0191665e-07]\n",
      "0.0 [0.00085099]\n",
      "0.0 [0.15023118]\n",
      "1.0 [0.00148139]\n",
      "1.0 [0.86452144]\n",
      "0.0 [4.3020857e-05]\n",
      "0.0 [2.4005558e-06]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [1.1116179e-05]\n",
      "1.0 [2.6393513e-05]\n",
      "0.0 [5.354533e-05]\n",
      "0.0 [0.9486346]\n",
      "0.0 [0.00427652]\n",
      "0.0 [0.00325895]\n",
      "1.0 [1.]\n",
      "0.0 [0.00030208]\n",
      "1.0 [1.]\n",
      "0.0 [0.01228275]\n",
      "1.0 [0.9982965]\n",
      "1.0 [1.]\n",
      "0.0 [0.0007427]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.33147493]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.6610907]\n",
      "0.0 [0.03664562]\n",
      "0.0 [1.6120752e-05]\n",
      "1.0 [0.00268536]\n",
      "1.0 [0.9998224]\n",
      "1.0 [0.2982836]\n",
      "0.0 [0.003138]\n",
      "0.0 [0.48077437]\n",
      "0.0 [0.13458073]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999905]\n",
      "0.0 [0.00376743]\n",
      "0.0 [0.5146516]\n",
      "1.0 [0.99979854]\n",
      "0.0 [4.1815725e-05]\n",
      "1.0 [0.02069515]\n",
      "1.0 [0.5109154]\n",
      "0.0 [0.00042193]\n",
      "1.0 [1.]\n",
      "0.0 [0.01938724]\n",
      "1.0 [0.9998096]\n",
      "0.0 [7.819816e-07]\n",
      "1.0 [0.22560929]\n",
      "1.0 [1.]\n",
      "1.0 [0.9834048]\n",
      "0.0 [9.40698e-05]\n",
      "1.0 [0.94879913]\n",
      "0.0 [0.00047201]\n",
      "0.0 [0.00012436]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.11274771]\n",
      "1.0 [1.]\n",
      "1.0 [0.9793544]\n",
      "0.0 [0.10998634]\n",
      "0.0 [5.7652468e-08]\n",
      "0.0 [5.2727147e-09]\n",
      "0.0 [0.00733637]\n",
      "1.0 [0.08573677]\n",
      "0.0 [0.0005528]\n",
      "1.0 [1.]\n",
      "0.0 [0.48389432]\n",
      "0.0 [1.4538463e-06]\n",
      "1.0 [0.9999605]\n",
      "0.0 [0.3674315]\n",
      "0.0 [4.822339e-06]\n",
      "1.0 [0.00040837]\n",
      "0.0 [0.00465592]\n",
      "0.0 [0.00165336]\n",
      "0.0 [0.00132901]\n",
      "0.0 [0.38543704]\n",
      "1.0 [1.]\n",
      "1.0 [0.08674697]\n",
      "1.0 [0.9634803]\n",
      "1.0 [0.99670535]\n",
      "0.0 [0.00048923]\n",
      "1.0 [0.9999988]\n",
      "1.0 [1.]\n",
      "1.0 [0.00013648]\n",
      "1.0 [1.]\n",
      "0.0 [0.00080852]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [7.963351e-05]\n",
      "0.0 [0.06283807]\n",
      "1.0 [0.02749774]\n",
      "0.0 [0.00092669]\n",
      "1.0 [0.9999992]\n",
      "0.0 [0.00831524]\n",
      "1.0 [0.9992154]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.8417265]\n",
      "1.0 [9.5556046e-05]\n",
      "0.0 [1.]\n",
      "0.0 [0.00624741]\n",
      "0.0 [0.2678087]\n",
      "0.0 [5.35123e-05]\n",
      "0.0 [1.]\n",
      "1.0 [0.9999803]\n",
      "1.0 [0.9999902]\n",
      "1.0 [0.0133886]\n",
      "1.0 [0.99649554]\n",
      "1.0 [1.]\n",
      "0.0 [0.00188048]\n",
      "1.0 [0.13249595]\n",
      "1.0 [0.9999998]\n",
      "0.0 [0.9674548]\n",
      "0.0 [0.99999094]\n",
      "0.0 [0.44461212]\n",
      "1.0 [0.9997851]\n",
      "1.0 [1.]\n",
      "1.0 [0.78724843]\n",
      "0.0 [0.02532895]\n",
      "1.0 [3.287374e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00484616]\n",
      "1.0 [0.97618896]\n",
      "0.0 [0.20542891]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999792]\n",
      "1.0 [1.]\n",
      "0.0 [0.17279226]\n",
      "0.0 [0.00152536]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99949074]\n",
      "1.0 [0.9338565]\n",
      "0.0 [0.00290743]\n",
      "1.0 [1.]\n",
      "1.0 [0.9998589]\n",
      "0.0 [6.790818e-05]\n",
      "0.0 [0.0033468]\n",
      "1.0 [1.]\n",
      "0.0 [0.16479088]\n",
      "0.0 [7.9251936e-07]\n",
      "0.0 [0.00037296]\n",
      "1.0 [1.]\n",
      "0.0 [0.0067646]\n",
      "1.0 [1.]\n",
      "1.0 [0.9995572]\n",
      "0.0 [0.8394075]\n",
      "0.0 [0.01695077]\n",
      "0.0 [0.8670087]\n",
      "1.0 [1.]\n",
      "0.0 [0.68722266]\n",
      "1.0 [1.]\n",
      "0.0 [0.04576068]\n",
      "1.0 [0.00067225]\n",
      "0.0 [0.00072006]\n",
      "1.0 [0.9239572]\n",
      "1.0 [0.9999997]\n",
      "0.0 [0.00334907]\n",
      "1.0 [0.9999996]\n",
      "0.0 [0.01718166]\n",
      "1.0 [1.]\n",
      "1.0 [0.01601382]\n",
      "0.0 [0.01343241]\n",
      "1.0 [0.9999996]\n",
      "1.0 [0.99999696]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.07290263]\n",
      "1.0 [1.]\n",
      "0.0 [0.03106509]\n",
      "0.0 [0.06505515]\n",
      "0.0 [0.00026467]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [3.1428455e-05]\n",
      "1.0 [0.9214676]\n",
      "0.0 [0.11177095]\n",
      "1.0 [0.0002255]\n",
      "1.0 [0.18436928]\n",
      "1.0 [0.99998116]\n",
      "1.0 [0.48729664]\n",
      "1.0 [0.9987352]\n",
      "1.0 [0.18280333]\n",
      "0.0 [0.00028368]\n",
      "0.0 [1.]\n",
      "0.0 [0.00471057]\n",
      "0.0 [0.00081781]\n",
      "1.0 [0.9915735]\n",
      "1.0 [1.]\n",
      "0.0 [0.24543561]\n",
      "1.0 [0.15187302]\n",
      "0.0 [6.136682e-05]\n",
      "1.0 [1.]\n",
      "0.0 [3.3171593e-05]\n",
      "0.0 [0.99997205]\n",
      "0.0 [0.9987123]\n",
      "0.0 [0.9344471]\n",
      "0.0 [0.00044542]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.46981955]\n",
      "0.0 [0.52306676]\n",
      "0.0 [0.0001182]\n",
      "1.0 [0.9999996]\n",
      "0.0 [2.4776602e-05]\n",
      "1.0 [0.05877214]\n",
      "1.0 [0.99873114]\n",
      "1.0 [1.]\n",
      "0.0 [0.00361189]\n",
      "1.0 [1.]\n",
      "1.0 [0.96985686]\n",
      "0.0 [1.7624679e-08]\n",
      "0.0 [0.00045511]\n",
      "1.0 [0.99765235]\n",
      "1.0 [0.99999964]\n",
      "0.0 [0.00056554]\n",
      "1.0 [0.9856298]\n",
      "0.0 [0.99413824]\n",
      "0.0 [0.00080772]\n",
      "0.0 [0.00485955]\n",
      "0.0 [0.10725237]\n",
      "0.0 [0.03991776]\n",
      "1.0 [1.]\n",
      "1.0 [0.02786356]\n",
      "0.0 [2.6192914e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00320944]\n",
      "0.0 [0.00874323]\n",
      "0.0 [0.00089003]\n",
      "1.0 [0.99784356]\n",
      "1.0 [0.9999837]\n",
      "1.0 [1.]\n",
      "0.0 [5.8628655e-05]\n",
      "1.0 [0.425122]\n",
      "1.0 [0.9999996]\n",
      "1.0 [1.]\n",
      "0.0 [5.6998942e-05]\n",
      "1.0 [0.9999849]\n",
      "1.0 [0.6429349]\n",
      "0.0 [4.8934395e-05]\n",
      "0.0 [6.332098e-05]\n",
      "0.0 [0.00506717]\n",
      "0.0 [5.9384547e-06]\n",
      "1.0 [1.]\n",
      "1.0 [2.2412492e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [0.01640447]\n",
      "0.0 [0.00014574]\n",
      "0.0 [0.00041662]\n",
      "0.0 [0.9609402]\n",
      "1.0 [0.99957186]\n",
      "1.0 [1.]\n",
      "0.0 [7.3172564e-06]\n",
      "1.0 [0.7733528]\n",
      "1.0 [0.9755544]\n",
      "1.0 [1.]\n",
      "0.0 [6.579812e-08]\n",
      "0.0 [2.1492038e-05]\n",
      "0.0 [0.02637313]\n",
      "0.0 [0.09571425]\n",
      "0.0 [0.00483224]\n",
      "0.0 [1.1224251e-08]\n",
      "0.0 [0.00388606]\n",
      "1.0 [0.8509004]\n",
      "0.0 [0.00127894]\n",
      "1.0 [1.]\n",
      "1.0 [0.9974345]\n",
      "0.0 [4.2734475e-05]\n",
      "0.0 [2.8440212e-05]\n",
      "0.0 [0.99722433]\n",
      "1.0 [1.]\n",
      "0.0 [0.6844305]\n",
      "0.0 [0.99999994]\n",
      "1.0 [0.9999976]\n",
      "1.0 [0.10950411]\n",
      "1.0 [0.99999]\n",
      "0.0 [0.51064366]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00015298]\n",
      "0.0 [0.78589886]\n",
      "0.0 [0.00011382]\n",
      "0.0 [0.99994195]\n",
      "1.0 [0.99999845]\n",
      "1.0 [1.]\n",
      "1.0 [0.99998045]\n",
      "1.0 [0.34494537]\n",
      "1.0 [0.00029043]\n",
      "0.0 [0.00063158]\n",
      "1.0 [0.9999997]\n",
      "1.0 [0.998044]\n",
      "1.0 [0.97063214]\n",
      "0.0 [1.0910679e-06]\n",
      "1.0 [0.03509756]\n",
      "0.0 [0.00426203]\n",
      "1.0 [0.50433195]\n",
      "0.0 [0.99947876]\n",
      "0.0 [6.2194034e-05]\n",
      "0.0 [0.09441692]\n",
      "1.0 [1.]\n",
      "1.0 [0.9992512]\n",
      "0.0 [1.5939867e-07]\n",
      "0.0 [1.]\n",
      "0.0 [0.47216937]\n",
      "1.0 [0.03313076]\n",
      "0.0 [0.00555813]\n",
      "0.0 [0.11490413]\n",
      "1.0 [0.00147334]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999994]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.03117346]\n",
      "0.0 [1.1625134e-05]\n",
      "0.0 [0.52230954]\n",
      "0.0 [0.00016986]\n",
      "1.0 [1.]\n",
      "0.0 [0.14601542]\n",
      "0.0 [0.05061768]\n",
      "1.0 [5.743928e-05]\n",
      "0.0 [1.1171026e-05]\n",
      "0.0 [0.00114689]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00220115]\n",
      "1.0 [0.99991107]\n",
      "1.0 [0.76780385]\n",
      "1.0 [0.04580566]\n",
      "1.0 [0.61326736]\n",
      "1.0 [0.04270775]\n",
      "1.0 [0.7071947]\n",
      "0.0 [0.00071778]\n",
      "0.0 [0.08219451]\n",
      "0.0 [1.3637926e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00161412]\n",
      "1.0 [0.99966663]\n",
      "0.0 [0.0035808]\n",
      "1.0 [1.]\n",
      "0.0 [2.2695158e-08]\n",
      "1.0 [1.]\n",
      "1.0 [0.00023033]\n",
      "0.0 [3.88797e-07]\n",
      "0.0 [0.02242598]\n",
      "0.0 [0.00142458]\n",
      "0.0 [0.00091646]\n",
      "0.0 [0.07224005]\n",
      "1.0 [0.99999833]\n",
      "0.0 [0.07724231]\n",
      "1.0 [0.9748283]\n",
      "1.0 [0.74520665]\n",
      "1.0 [0.9999979]\n",
      "0.0 [0.00024865]\n",
      "0.0 [0.7112073]\n",
      "0.0 [3.599373e-08]\n",
      "0.0 [0.00016293]\n",
      "0.0 [0.00050615]\n",
      "0.0 [0.00060855]\n",
      "1.0 [0.9990333]\n",
      "0.0 [1.528043e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.20840846]\n",
      "1.0 [0.99960476]\n",
      "1.0 [1.]\n",
      "0.0 [3.7284237e-06]\n",
      "0.0 [0.00144569]\n",
      "1.0 [0.9810823]\n",
      "1.0 [0.99997336]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999988]\n",
      "1.0 [1.]\n",
      "1.0 [0.01123618]\n",
      "1.0 [0.9650012]\n",
      "1.0 [1.]\n",
      "1.0 [0.9430683]\n",
      "0.0 [6.9089594e-08]\n",
      "1.0 [0.9976215]\n",
      "1.0 [2.471956e-05]\n",
      "0.0 [0.29265377]\n",
      "0.0 [6.0731047e-05]\n",
      "0.0 [0.00109326]\n",
      "0.0 [0.13037936]\n",
      "0.0 [2.3604901e-08]\n",
      "0.0 [5.137853e-05]\n",
      "1.0 [4.1539777e-05]\n",
      "0.0 [0.00368513]\n",
      "0.0 [0.2350818]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.00302662]\n",
      "0.0 [0.01435307]\n",
      "1.0 [0.999203]\n",
      "0.0 [0.0138154]\n",
      "0.0 [0.00733135]\n",
      "0.0 [0.00101962]\n",
      "1.0 [1.]\n",
      "0.0 [0.00037929]\n",
      "0.0 [0.00058967]\n",
      "1.0 [1.]\n",
      "1.0 [0.9995407]\n",
      "1.0 [1.]\n",
      "0.0 [0.00028732]\n",
      "0.0 [0.00018345]\n",
      "1.0 [0.00774955]\n",
      "1.0 [1.]\n",
      "0.0 [1.5079247e-06]\n",
      "0.0 [0.97755635]\n",
      "0.0 [0.00014522]\n",
      "0.0 [0.33548746]\n",
      "0.0 [0.9999999]\n",
      "0.0 [8.504178e-09]\n",
      "0.0 [0.5169161]\n",
      "1.0 [0.9040939]\n",
      "1.0 [1.]\n",
      "1.0 [0.16261534]\n",
      "0.0 [0.00044142]\n",
      "0.0 [0.03025213]\n",
      "0.0 [1.7918728e-08]\n",
      "1.0 [1.]\n",
      "1.0 [0.02170131]\n",
      "1.0 [0.66213363]\n",
      "1.0 [3.2798212e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.14676644]\n",
      "1.0 [0.9954059]\n",
      "0.0 [0.03055333]\n",
      "1.0 [0.99955136]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9981253]\n",
      "1.0 [1.]\n",
      "0.0 [0.0147119]\n",
      "1.0 [0.87573415]\n",
      "0.0 [0.01122288]\n",
      "0.0 [0.9920741]\n",
      "1.0 [0.04782529]\n",
      "0.0 [0.00102504]\n",
      "0.0 [0.01957451]\n",
      "0.0 [1.088333e-05]\n",
      "1.0 [0.9999995]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999994]\n",
      "1.0 [1.]\n",
      "0.0 [0.01719129]\n",
      "0.0 [0.00130998]\n",
      "1.0 [8.9874885e-07]\n",
      "0.0 [0.00248565]\n",
      "1.0 [1.]\n",
      "0.0 [7.881841e-05]\n",
      "0.0 [0.2507573]\n",
      "0.0 [0.5536214]\n",
      "0.0 [0.00456774]\n",
      "0.0 [0.12693004]\n",
      "1.0 [1.]\n",
      "0.0 [0.00051132]\n",
      "0.0 [0.00051154]\n",
      "0.0 [0.0027339]\n",
      "1.0 [1.]\n",
      "1.0 [0.9979878]\n",
      "0.0 [0.62776375]\n",
      "0.0 [1.]\n",
      "0.0 [0.00085586]\n",
      "0.0 [0.11743347]\n",
      "1.0 [0.8332008]\n",
      "0.0 [0.98555386]\n",
      "1.0 [0.9986086]\n",
      "1.0 [0.07243745]\n",
      "0.0 [0.01748838]\n",
      "0.0 [0.00202975]\n",
      "0.0 [0.9353251]\n",
      "0.0 [2.947478e-07]\n",
      "0.0 [0.00029491]\n",
      "1.0 [0.0967419]\n",
      "1.0 [0.99979883]\n",
      "1.0 [0.8507519]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.3286817]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00370026]\n",
      "0.0 [0.0025732]\n",
      "0.0 [0.06903785]\n",
      "0.0 [0.77941024]\n",
      "0.0 [1.0731822e-05]\n",
      "1.0 [0.99999887]\n",
      "1.0 [0.9999965]\n",
      "0.0 [0.00205065]\n",
      "0.0 [0.0012199]\n",
      "1.0 [0.9988601]\n",
      "0.0 [0.05640239]\n",
      "0.0 [0.00398801]\n",
      "1.0 [1.]\n",
      "1.0 [0.9894457]\n",
      "1.0 [0.01293644]\n",
      "0.0 [0.0017883]\n",
      "1.0 [0.99999964]\n",
      "0.0 [0.22638863]\n",
      "0.0 [0.00261068]\n",
      "1.0 [0.99999523]\n",
      "0.0 [3.1702417e-05]\n",
      "1.0 [0.9999595]\n",
      "1.0 [1.]\n",
      "0.0 [3.9069277e-05]\n",
      "0.0 [0.15845272]\n",
      "1.0 [0.74838954]\n",
      "0.0 [8.093111e-06]\n",
      "0.0 [4.378778e-06]\n",
      "1.0 [0.9633148]\n",
      "1.0 [1.]\n",
      "0.0 [0.00211135]\n",
      "0.0 [0.13268277]\n",
      "0.0 [1.3498864e-07]\n",
      "0.0 [0.82356584]\n",
      "1.0 [0.9998112]\n",
      "1.0 [1.]\n",
      "1.0 [0.01611017]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00118794]\n",
      "1.0 [0.99998844]\n",
      "1.0 [0.999931]\n",
      "1.0 [0.90347904]\n",
      "1.0 [0.9999753]\n",
      "0.0 [0.92595184]\n",
      "1.0 [0.99999833]\n",
      "1.0 [1.]\n",
      "0.0 [0.9642716]\n",
      "0.0 [0.9986037]\n",
      "1.0 [0.99991316]\n",
      "0.0 [3.683524e-05]\n",
      "1.0 [0.9578805]\n",
      "0.0 [0.11835519]\n",
      "1.0 [0.00063616]\n",
      "0.0 [0.01136378]\n",
      "1.0 [1.]\n",
      "0.0 [0.07651635]\n",
      "1.0 [0.7347824]\n",
      "1.0 [0.0010921]\n",
      "0.0 [0.99947864]\n",
      "0.0 [0.00012777]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00098945]\n",
      "0.0 [8.380887e-06]\n",
      "0.0 [0.06764423]\n",
      "1.0 [1.]\n",
      "1.0 [0.10180911]\n",
      "0.0 [0.00027223]\n",
      "0.0 [2.1899031e-07]\n",
      "1.0 [0.99998176]\n",
      "0.0 [0.00177219]\n",
      "1.0 [0.9996639]\n",
      "0.0 [0.78123105]\n",
      "0.0 [0.00135647]\n",
      "1.0 [0.12380849]\n",
      "0.0 [0.00037186]\n",
      "1.0 [1.]\n",
      "1.0 [0.919842]\n",
      "0.0 [9.445001e-05]\n",
      "0.0 [0.00032488]\n",
      "0.0 [0.9994536]\n",
      "0.0 [0.00544857]\n",
      "0.0 [0.91401625]\n",
      "0.0 [8.8066874e-05]\n",
      "1.0 [0.9833491]\n",
      "0.0 [0.00081453]\n",
      "0.0 [1.5175866e-05]\n",
      "0.0 [0.28558257]\n",
      "0.0 [2.834792e-09]\n",
      "0.0 [0.00097442]\n",
      "1.0 [0.38414422]\n",
      "0.0 [0.00160154]\n",
      "1.0 [0.5125776]\n",
      "1.0 [0.67366284]\n",
      "0.0 [0.00103003]\n",
      "1.0 [0.00169876]\n",
      "1.0 [0.8044652]\n",
      "1.0 [0.98409295]\n",
      "0.0 [0.0006017]\n",
      "1.0 [0.9606106]\n",
      "0.0 [0.56228286]\n",
      "0.0 [0.00017668]\n",
      "1.0 [1.]\n",
      "0.0 [2.7608472e-05]\n",
      "0.0 [4.4626148e-08]\n",
      "0.0 [6.789639e-05]\n",
      "0.0 [0.00078124]\n",
      "0.0 [9.104303e-06]\n",
      "0.0 [0.03098302]\n",
      "0.0 [0.99688566]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.02828603]\n",
      "1.0 [1.]\n",
      "1.0 [7.649899e-08]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [2.8285662e-05]\n",
      "1.0 [0.9957484]\n",
      "0.0 [0.99986154]\n",
      "1.0 [1.]\n",
      "0.0 [3.4494323e-07]\n",
      "1.0 [0.99847454]\n",
      "1.0 [0.9896542]\n",
      "0.0 [0.99999857]\n",
      "0.0 [0.07375792]\n",
      "0.0 [0.97563535]\n",
      "1.0 [1.]\n",
      "1.0 [0.9852878]\n",
      "0.0 [0.06517037]\n",
      "0.0 [1.6704277e-06]\n",
      "0.0 [0.00328094]\n",
      "0.0 [0.0616516]\n",
      "0.0 [0.00154021]\n",
      "1.0 [0.99991786]\n",
      "1.0 [0.9998053]\n",
      "1.0 [1.]\n",
      "0.0 [1.1099775e-11]\n",
      "0.0 [0.00547275]\n",
      "0.0 [0.00070943]\n",
      "0.0 [0.00030592]\n",
      "1.0 [0.89854693]\n",
      "1.0 [0.99999815]\n",
      "0.0 [0.00041713]\n",
      "1.0 [0.99999624]\n",
      "1.0 [0.9892338]\n",
      "1.0 [0.03641111]\n",
      "1.0 [1.]\n",
      "1.0 [0.0806452]\n",
      "0.0 [0.9647434]\n",
      "1.0 [0.7577526]\n",
      "1.0 [1.]\n",
      "0.0 [0.4311666]\n",
      "0.0 [0.00534572]\n",
      "0.0 [0.09975712]\n",
      "0.0 [0.00398914]\n",
      "0.0 [0.00013333]\n",
      "0.0 [0.00139923]\n",
      "1.0 [0.9991019]\n",
      "1.0 [1.]\n",
      "0.0 [0.01024601]\n",
      "0.0 [0.00301836]\n",
      "1.0 [0.99134606]\n",
      "1.0 [0.00027495]\n",
      "0.0 [0.00593913]\n",
      "0.0 [0.00107276]\n",
      "1.0 [0.01598447]\n",
      "1.0 [0.99999946]\n",
      "0.0 [0.00060804]\n",
      "0.0 [0.9999636]\n",
      "0.0 [0.00041137]\n",
      "1.0 [1.]\n",
      "1.0 [0.03881056]\n",
      "0.0 [0.36145863]\n",
      "1.0 [1.]\n",
      "0.0 [0.00177825]\n",
      "1.0 [0.99932456]\n",
      "1.0 [1.]\n",
      "0.0 [0.02367026]\n",
      "0.0 [9.373956e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00235281]\n",
      "1.0 [0.15213954]\n",
      "0.0 [0.49515337]\n",
      "0.0 [2.3007475e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.45479035]\n",
      "0.0 [0.00030103]\n",
      "1.0 [1.]\n",
      "0.0 [0.00010714]\n",
      "0.0 [5.3967347e-06]\n",
      "0.0 [0.00114607]\n",
      "0.0 [6.384568e-06]\n",
      "1.0 [1.]\n",
      "0.0 [0.13429241]\n",
      "1.0 [1.]\n",
      "0.0 [0.00146046]\n",
      "0.0 [0.88900423]\n",
      "1.0 [0.99999964]\n",
      "1.0 [0.6335391]\n",
      "1.0 [0.00377744]\n",
      "1.0 [0.9926634]\n",
      "0.0 [0.0002127]\n",
      "0.0 [6.281902e-07]\n",
      "0.0 [0.00161555]\n",
      "1.0 [0.99963075]\n",
      "0.0 [0.01211448]\n",
      "0.0 [3.4108574e-10]\n",
      "0.0 [6.315451e-10]\n",
      "0.0 [0.00537252]\n",
      "0.0 [0.05472027]\n",
      "0.0 [9.878194e-05]\n",
      "0.0 [1.4294539e-05]\n",
      "1.0 [0.78078043]\n",
      "0.0 [7.091309e-05]\n",
      "0.0 [0.54222006]\n",
      "1.0 [1.]\n",
      "1.0 [0.54438335]\n",
      "0.0 [0.00080589]\n",
      "1.0 [0.9999964]\n",
      "1.0 [0.01156824]\n",
      "1.0 [4.1381224e-07]\n",
      "0.0 [1.4947482e-06]\n",
      "0.0 [0.00016035]\n",
      "0.0 [3.517725e-06]\n",
      "1.0 [0.9999971]\n",
      "1.0 [0.13347653]\n",
      "1.0 [0.99872196]\n",
      "0.0 [0.00427411]\n",
      "0.0 [3.8085418e-05]\n",
      "0.0 [0.00011199]\n",
      "1.0 [0.05469888]\n",
      "1.0 [0.99930394]\n",
      "1.0 [1.]\n",
      "1.0 [0.7396013]\n",
      "0.0 [0.00201957]\n",
      "0.0 [0.00094135]\n",
      "1.0 [0.23816206]\n",
      "0.0 [1.3096373e-05]\n",
      "1.0 [0.18820138]\n",
      "0.0 [0.42238623]\n",
      "0.0 [9.670157e-06]\n",
      "1.0 [1.]\n",
      "1.0 [0.05593733]\n",
      "1.0 [0.9902064]\n",
      "0.0 [0.01322292]\n",
      "0.0 [0.1290034]\n",
      "1.0 [1.]\n",
      "1.0 [0.91271794]\n",
      "0.0 [1.2236172e-05]\n",
      "1.0 [0.9999497]\n",
      "0.0 [0.02734986]\n",
      "1.0 [1.]\n",
      "1.0 [0.9832371]\n",
      "0.0 [0.00032731]\n",
      "0.0 [0.00056749]\n",
      "1.0 [0.00946627]\n",
      "0.0 [0.2458646]\n",
      "1.0 [0.34135753]\n",
      "0.0 [0.00044131]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.00066329]\n",
      "1.0 [0.7838529]\n",
      "1.0 [0.95676005]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9305343]\n",
      "1.0 [0.970374]\n",
      "0.0 [0.6594482]\n",
      "0.0 [2.4809745e-07]\n",
      "0.0 [0.00738437]\n",
      "1.0 [0.2659359]\n",
      "1.0 [1.]\n",
      "0.0 [0.00342764]\n",
      "1.0 [0.99978614]\n",
      "0.0 [0.00358737]\n",
      "1.0 [1.]\n",
      "0.0 [0.00315481]\n",
      "0.0 [9.708393e-05]\n",
      "0.0 [0.00027369]\n",
      "0.0 [0.11061605]\n",
      "0.0 [0.0005632]\n",
      "1.0 [0.8755419]\n",
      "1.0 [0.99998325]\n",
      "0.0 [0.00055732]\n",
      "1.0 [1.]\n",
      "0.0 [0.5419435]\n",
      "0.0 [0.00072385]\n",
      "0.0 [5.641365e-10]\n",
      "1.0 [0.06182939]\n",
      "0.0 [0.00257235]\n",
      "0.0 [0.00376177]\n",
      "0.0 [0.00688378]\n",
      "0.0 [4.604135e-05]\n",
      "1.0 [0.89288056]\n",
      "0.0 [0.00228056]\n",
      "1.0 [1.]\n",
      "0.0 [0.02457913]\n",
      "1.0 [0.99998933]\n",
      "0.0 [0.00193862]\n",
      "0.0 [0.10399669]\n",
      "1.0 [0.09022739]\n",
      "0.0 [0.99984145]\n",
      "0.0 [0.0030686]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9998654]\n",
      "0.0 [0.00130159]\n",
      "0.0 [0.02773634]\n",
      "0.0 [0.00071721]\n",
      "0.0 [2.4274712e-08]\n",
      "1.0 [1.]\n",
      "1.0 [0.7180157]\n",
      "0.0 [0.11481951]\n",
      "1.0 [0.03726331]\n",
      "0.0 [0.00893225]\n",
      "0.0 [0.00159625]\n",
      "1.0 [0.87884]\n",
      "1.0 [0.9999353]\n",
      "1.0 [0.9983222]\n",
      "1.0 [0.977772]\n",
      "0.0 [0.00051323]\n",
      "0.0 [0.06289897]\n",
      "0.0 [0.09578831]\n",
      "1.0 [0.06589159]\n",
      "0.0 [0.00161978]\n",
      "1.0 [0.99639034]\n",
      "0.0 [9.249069e-05]\n",
      "0.0 [0.01249939]\n",
      "0.0 [0.00590664]\n",
      "0.0 [0.9881254]\n",
      "1.0 [0.9999911]\n",
      "0.0 [0.00040944]\n",
      "0.0 [0.00160154]\n",
      "1.0 [0.36872962]\n",
      "1.0 [1.]\n",
      "0.0 [2.4153393e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.77849567]\n",
      "0.0 [0.00078274]\n",
      "1.0 [1.]\n",
      "0.0 [0.0056179]\n",
      "0.0 [0.00277199]\n",
      "0.0 [5.20797e-07]\n",
      "1.0 [1.]\n",
      "0.0 [0.00292368]\n",
      "0.0 [0.01783446]\n",
      "1.0 [0.99999267]\n",
      "1.0 [0.7579979]\n",
      "0.0 [0.7838139]\n",
      "1.0 [0.7781643]\n",
      "0.0 [0.0320562]\n",
      "1.0 [0.99987787]\n",
      "0.0 [0.00207321]\n",
      "0.0 [0.01313765]\n",
      "0.0 [3.9760493e-05]\n",
      "1.0 [0.01077645]\n",
      "1.0 [0.9999996]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.997082]\n",
      "1.0 [0.00104892]\n",
      "1.0 [1.]\n",
      "0.0 [0.00010013]\n",
      "0.0 [0.997698]\n",
      "0.0 [6.3719664e-05]\n",
      "0.0 [0.00069981]\n",
      "0.0 [0.471854]\n",
      "1.0 [1.]\n",
      "0.0 [0.00121478]\n",
      "1.0 [0.9957322]\n",
      "1.0 [0.9796173]\n",
      "0.0 [0.09101417]\n",
      "0.0 [0.01003332]\n",
      "0.0 [0.00039481]\n",
      "0.0 [0.01796081]\n",
      "1.0 [1.]\n",
      "0.0 [1.1393113e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.99802464]\n",
      "1.0 [0.94067377]\n",
      "1.0 [1.]\n",
      "0.0 [0.9757964]\n",
      "0.0 [1.8739502e-05]\n",
      "1.0 [0.9912355]\n",
      "0.0 [7.436683e-06]\n",
      "0.0 [2.8240054e-05]\n",
      "1.0 [0.9996525]\n",
      "0.0 [0.00052895]\n",
      "1.0 [0.68529207]\n",
      "0.0 [0.52075255]\n",
      "0.0 [4.6350315e-09]\n",
      "1.0 [0.85410655]\n",
      "1.0 [1.]\n",
      "0.0 [0.09258225]\n",
      "1.0 [0.560329]\n",
      "1.0 [1.]\n",
      "0.0 [0.00069607]\n",
      "0.0 [0.01708015]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999626]\n",
      "0.0 [0.00627844]\n",
      "1.0 [1.]\n",
      "0.0 [0.99356306]\n",
      "0.0 [0.00284864]\n",
      "0.0 [0.00530214]\n",
      "1.0 [0.99953663]\n",
      "0.0 [0.00019924]\n",
      "0.0 [0.00061411]\n",
      "1.0 [0.7448926]\n",
      "1.0 [1.]\n",
      "0.0 [0.6437621]\n",
      "1.0 [1.]\n",
      "0.0 [2.898581e-05]\n",
      "0.0 [0.00676371]\n",
      "0.0 [7.5352873e-06]\n",
      "0.0 [0.0076413]\n",
      "1.0 [0.99931365]\n",
      "1.0 [0.8385098]\n",
      "1.0 [4.067169e-05]\n",
      "0.0 [0.2708641]\n",
      "1.0 [0.36928257]\n",
      "0.0 [0.00053446]\n",
      "0.0 [0.00194295]\n",
      "0.0 [2.4562727e-05]\n",
      "0.0 [0.01270408]\n",
      "1.0 [0.9999998]\n",
      "0.0 [0.7184596]\n",
      "1.0 [1.]\n",
      "0.0 [0.00133159]\n",
      "0.0 [2.1085759e-13]\n",
      "1.0 [0.9999999]\n",
      "1.0 [0.9999973]\n",
      "1.0 [0.8168946]\n",
      "0.0 [1.74092e-06]\n",
      "1.0 [0.9976777]\n",
      "0.0 [2.3572745e-06]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.16388889]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.0001115]\n",
      "0.0 [0.00901316]\n",
      "1.0 [1.]\n",
      "0.0 [0.00083825]\n",
      "0.0 [0.00731354]\n",
      "1.0 [0.00536514]\n",
      "0.0 [0.01387214]\n",
      "0.0 [0.0273271]\n",
      "0.0 [7.745693e-06]\n",
      "0.0 [0.9147452]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00024187]\n",
      "0.0 [0.00012729]\n",
      "1.0 [1.]\n",
      "0.0 [0.00444861]\n",
      "0.0 [0.00302664]\n",
      "1.0 [1.]\n",
      "0.0 [0.74632597]\n",
      "1.0 [0.99999964]\n",
      "0.0 [0.9983642]\n",
      "0.0 [0.06306233]\n",
      "0.0 [0.30351835]\n",
      "0.0 [0.10649016]\n",
      "0.0 [1.0097833e-05]\n",
      "0.0 [0.9918088]\n",
      "0.0 [5.4212956e-05]\n",
      "0.0 [0.00595787]\n",
      "1.0 [1.]\n",
      "1.0 [0.9692242]\n",
      "0.0 [0.00269578]\n",
      "1.0 [1.]\n",
      "1.0 [0.54850227]\n",
      "0.0 [0.00010564]\n",
      "0.0 [0.00889646]\n",
      "0.0 [0.0013052]\n",
      "1.0 [0.02040655]\n",
      "0.0 [2.3144169e-10]\n",
      "1.0 [1.]\n",
      "0.0 [0.6795712]\n",
      "1.0 [0.01630808]\n",
      "1.0 [1.]\n",
      "0.0 [0.00101016]\n",
      "1.0 [1.]\n",
      "1.0 [0.99919754]\n",
      "1.0 [0.99355423]\n",
      "1.0 [1.]\n",
      "0.0 [0.00421665]\n",
      "0.0 [5.8308837e-05]\n",
      "0.0 [8.3303814e-05]\n",
      "0.0 [3.4019447e-06]\n",
      "0.0 [5.929332e-06]\n",
      "0.0 [1.]\n",
      "0.0 [5.957424e-10]\n",
      "1.0 [0.52199095]\n",
      "1.0 [1.]\n",
      "0.0 [4.9772774e-07]\n",
      "1.0 [1.]\n",
      "0.0 [0.9999999]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999993]\n",
      "1.0 [0.5714663]\n",
      "0.0 [2.318284e-09]\n",
      "0.0 [0.0040526]\n",
      "1.0 [0.00446474]\n",
      "0.0 [0.00015785]\n",
      "1.0 [0.99990404]\n",
      "0.0 [0.035511]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.57969064]\n",
      "0.0 [0.00028302]\n",
      "1.0 [1.]\n",
      "0.0 [0.02173197]\n",
      "1.0 [1.]\n",
      "0.0 [0.34805977]\n",
      "0.0 [0.8904166]\n",
      "1.0 [0.9999872]\n",
      "0.0 [0.00529775]\n",
      "1.0 [0.00220928]\n",
      "1.0 [0.99542284]\n",
      "1.0 [0.9999997]\n",
      "1.0 [0.99019927]\n",
      "1.0 [0.99988335]\n",
      "1.0 [3.438028e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.00012859]\n",
      "1.0 [0.4725062]\n",
      "1.0 [1.]\n",
      "1.0 [0.0033292]\n",
      "1.0 [0.99999994]\n",
      "0.0 [0.00872465]\n",
      "0.0 [0.697183]\n",
      "0.0 [0.9574174]\n",
      "1.0 [0.9999905]\n",
      "1.0 [0.99999875]\n",
      "1.0 [0.08283561]\n",
      "0.0 [0.00018775]\n",
      "0.0 [9.96709e-05]\n",
      "1.0 [0.99179757]\n",
      "0.0 [0.08091109]\n",
      "0.0 [0.00012177]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00036325]\n",
      "1.0 [0.996533]\n",
      "1.0 [0.99981153]\n",
      "1.0 [0.2225934]\n",
      "0.0 [1.2105231e-07]\n",
      "1.0 [0.96222895]\n",
      "0.0 [0.02716363]\n",
      "1.0 [0.0036306]\n",
      "0.0 [0.00010828]\n",
      "1.0 [0.00247398]\n",
      "0.0 [0.00042154]\n",
      "0.0 [3.3899526e-06]\n",
      "1.0 [1.]\n",
      "0.0 [0.7878317]\n",
      "0.0 [0.01415221]\n",
      "1.0 [0.6410603]\n",
      "1.0 [0.00406]\n",
      "0.0 [0.04663067]\n",
      "0.0 [0.00073373]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00089976]\n",
      "0.0 [0.0004373]\n",
      "1.0 [0.62577397]\n",
      "1.0 [0.91303957]\n",
      "0.0 [2.2668297e-07]\n",
      "0.0 [8.529988e-05]\n",
      "0.0 [4.829261e-07]\n",
      "0.0 [0.00012781]\n",
      "1.0 [1.]\n",
      "1.0 [0.04097281]\n",
      "1.0 [2.3325783e-05]\n",
      "0.0 [0.00633828]\n",
      "1.0 [0.5739045]\n",
      "0.0 [0.00064128]\n",
      "1.0 [0.1492734]\n",
      "0.0 [0.0012947]\n",
      "1.0 [0.9999981]\n",
      "1.0 [1.]\n",
      "1.0 [0.98431623]\n",
      "0.0 [0.00015766]\n",
      "1.0 [0.8861799]\n",
      "0.0 [4.1652384e-06]\n",
      "0.0 [3.043764e-06]\n",
      "0.0 [0.03353208]\n",
      "1.0 [1.]\n",
      "1.0 [0.04607976]\n",
      "0.0 [0.00560152]\n",
      "1.0 [1.]\n",
      "0.0 [1.8572001e-07]\n",
      "1.0 [1.]\n",
      "1.0 [0.9994318]\n",
      "1.0 [1.]\n",
      "0.0 [0.15011992]\n",
      "0.0 [0.6558217]\n",
      "0.0 [0.00453096]\n",
      "1.0 [0.9999742]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99979055]\n",
      "1.0 [0.99999994]\n",
      "1.0 [1.]\n",
      "0.0 [0.00013153]\n",
      "0.0 [0.00016268]\n",
      "0.0 [0.94298273]\n",
      "0.0 [0.00349889]\n",
      "0.0 [1.1031387e-06]\n",
      "0.0 [0.0039606]\n",
      "1.0 [1.]\n",
      "1.0 [0.99888295]\n",
      "0.0 [0.00060366]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999973]\n",
      "1.0 [0.7052098]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999963]\n",
      "1.0 [1.1394599e-11]\n",
      "0.0 [9.10432e-06]\n",
      "1.0 [0.9998805]\n",
      "1.0 [1.]\n",
      "1.0 [0.99981964]\n",
      "0.0 [1.6288608e-07]\n",
      "1.0 [1.]\n",
      "0.0 [0.00269165]\n",
      "1.0 [1.]\n",
      "0.0 [0.00343463]\n",
      "1.0 [0.99999994]\n",
      "1.0 [0.2186649]\n",
      "1.0 [0.6984969]\n",
      "1.0 [0.51103675]\n",
      "0.0 [0.9211604]\n",
      "1.0 [0.99999464]\n",
      "0.0 [3.2440174e-05]\n",
      "0.0 [2.8071004e-06]\n",
      "0.0 [4.527069e-06]\n",
      "1.0 [0.97959805]\n",
      "0.0 [7.1448644e-06]\n",
      "0.0 [0.00050591]\n",
      "1.0 [0.98650384]\n",
      "1.0 [0.99813527]\n",
      "1.0 [1.]\n",
      "1.0 [0.13131465]\n",
      "1.0 [0.982981]\n",
      "1.0 [1.]\n",
      "1.0 [8.8648315e-09]\n",
      "0.0 [0.00176951]\n",
      "0.0 [0.00253229]\n",
      "0.0 [0.02735601]\n",
      "1.0 [0.99999994]\n",
      "0.0 [0.2301345]\n",
      "0.0 [2.1075952e-05]\n",
      "0.0 [0.00026051]\n",
      "0.0 [0.00030965]\n",
      "0.0 [0.00033198]\n",
      "0.0 [0.04030493]\n",
      "1.0 [1.]\n",
      "1.0 [0.00029044]\n",
      "1.0 [0.99999976]\n",
      "1.0 [0.9564813]\n",
      "1.0 [0.00510473]\n",
      "1.0 [0.8016335]\n",
      "0.0 [7.781039e-06]\n",
      "0.0 [7.469749e-05]\n",
      "0.0 [2.7083968e-06]\n",
      "1.0 [0.01086688]\n",
      "0.0 [3.6715126e-05]\n",
      "0.0 [0.00075646]\n",
      "0.0 [9.9370525e-05]\n",
      "1.0 [1.]\n",
      "1.0 [0.00065561]\n",
      "0.0 [0.00171166]\n",
      "0.0 [0.02065497]\n",
      "0.0 [0.8594625]\n",
      "0.0 [0.00087811]\n",
      "1.0 [7.283843e-05]\n",
      "1.0 [0.9999998]\n",
      "0.0 [3.5002053e-05]\n",
      "0.0 [0.02889322]\n",
      "1.0 [1.]\n",
      "0.0 [0.00318511]\n",
      "1.0 [0.9998445]\n",
      "1.0 [0.9173211]\n",
      "1.0 [1.]\n",
      "1.0 [0.9967507]\n",
      "0.0 [0.0091375]\n",
      "0.0 [0.00021443]\n",
      "0.0 [0.00086214]\n",
      "1.0 [0.9517042]\n",
      "0.0 [0.00017037]\n",
      "0.0 [3.3251936e-06]\n",
      "1.0 [0.99999964]\n",
      "1.0 [0.9999976]\n",
      "0.0 [1.6630397e-06]\n",
      "0.0 [3.716194e-08]\n",
      "1.0 [0.99725217]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.7147945]\n",
      "0.0 [0.07210217]\n",
      "0.0 [0.00249298]\n",
      "1.0 [1.]\n",
      "0.0 [0.37927955]\n",
      "0.0 [2.6742822e-05]\n",
      "0.0 [0.06251506]\n",
      "1.0 [0.9999997]\n",
      "1.0 [1.]\n",
      "0.0 [1.6389582e-05]\n",
      "0.0 [0.13717778]\n",
      "0.0 [0.00397818]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.00449964]\n",
      "1.0 [0.99902606]\n",
      "0.0 [2.101843e-06]\n",
      "1.0 [0.97561896]\n",
      "1.0 [0.9950244]\n",
      "0.0 [0.00279583]\n",
      "1.0 [0.8982171]\n",
      "1.0 [1.]\n",
      "0.0 [0.00030161]\n",
      "1.0 [0.8253429]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999994]\n",
      "0.0 [0.77422386]\n",
      "0.0 [7.804045e-05]\n",
      "0.0 [0.04808313]\n",
      "1.0 [0.99711335]\n",
      "0.0 [0.9872108]\n",
      "0.0 [0.00056195]\n",
      "1.0 [0.999838]\n",
      "0.0 [0.00463273]\n",
      "0.0 [2.927162e-05]\n",
      "0.0 [3.0461939e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.9999999]\n",
      "0.0 [9.6067415e-05]\n",
      "1.0 [0.9999733]\n",
      "0.0 [2.240524e-14]\n",
      "0.0 [0.37624553]\n",
      "1.0 [0.01179405]\n",
      "0.0 [0.0391923]\n",
      "1.0 [0.71513575]\n",
      "0.0 [0.00598859]\n",
      "1.0 [0.99999994]\n",
      "0.0 [0.3215748]\n",
      "0.0 [0.00145935]\n",
      "0.0 [0.01125678]\n",
      "1.0 [0.17944574]\n",
      "1.0 [0.00215014]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [0.00017735]\n",
      "0.0 [0.00398788]\n",
      "1.0 [0.94137454]\n",
      "1.0 [0.9997867]\n",
      "0.0 [0.00014966]\n",
      "1.0 [1.]\n",
      "0.0 [0.00206611]\n",
      "0.0 [0.30241907]\n",
      "0.0 [0.89710003]\n",
      "1.0 [0.5349993]\n",
      "1.0 [1.]\n",
      "1.0 [0.00354572]\n",
      "0.0 [0.00070583]\n",
      "1.0 [0.9998229]\n",
      "0.0 [0.01684123]\n",
      "0.0 [0.09392215]\n",
      "1.0 [1.]\n",
      "0.0 [0.63839597]\n",
      "0.0 [0.00024772]\n",
      "1.0 [0.16537812]\n",
      "1.0 [1.]\n",
      "1.0 [0.8776457]\n",
      "0.0 [0.00838708]\n",
      "0.0 [1.891021e-05]\n",
      "1.0 [0.6758765]\n",
      "1.0 [0.9999433]\n",
      "0.0 [0.03111381]\n",
      "0.0 [0.00014504]\n",
      "0.0 [1.9305378e-06]\n",
      "1.0 [0.99978775]\n",
      "1.0 [1.]\n",
      "0.0 [0.00017448]\n",
      "1.0 [1.]\n",
      "1.0 [0.99856347]\n",
      "0.0 [1.0589308e-09]\n",
      "1.0 [0.6866273]\n",
      "1.0 [0.964057]\n",
      "0.0 [0.00068004]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.01935547]\n",
      "0.0 [0.00028857]\n",
      "0.0 [2.1101996e-05]\n",
      "1.0 [0.9950535]\n",
      "1.0 [0.452653]\n",
      "0.0 [7.5886164e-06]\n",
      "0.0 [0.00353825]\n",
      "0.0 [4.279049e-09]\n",
      "1.0 [0.999573]\n",
      "0.0 [0.00558353]\n",
      "0.0 [0.01034109]\n",
      "1.0 [0.63422257]\n",
      "0.0 [0.00159993]\n",
      "0.0 [1.7790764e-05]\n",
      "1.0 [0.27279457]\n",
      "1.0 [0.9994628]\n",
      "1.0 [1.]\n",
      "1.0 [0.05270845]\n",
      "1.0 [0.99857956]\n",
      "1.0 [0.14924385]\n",
      "1.0 [0.9999869]\n",
      "1.0 [0.00075345]\n",
      "1.0 [0.14759165]\n",
      "0.0 [0.01522988]\n",
      "0.0 [1.]\n",
      "0.0 [0.00686747]\n",
      "1.0 [0.6796149]\n",
      "1.0 [0.00048735]\n",
      "0.0 [3.731536e-08]\n",
      "0.0 [0.5828023]\n",
      "0.0 [0.8500657]\n",
      "1.0 [1.]\n",
      "0.0 [0.00858767]\n",
      "1.0 [0.26447034]\n",
      "0.0 [2.029662e-06]\n",
      "1.0 [0.9999609]\n",
      "0.0 [0.03368312]\n",
      "0.0 [0.5114975]\n",
      "0.0 [0.0134556]\n",
      "1.0 [1.]\n",
      "0.0 [0.42887628]\n",
      "1.0 [0.9999906]\n",
      "0.0 [0.00036383]\n",
      "1.0 [0.9880829]\n",
      "1.0 [0.51093626]\n",
      "0.0 [1.]\n",
      "1.0 [0.9996726]\n",
      "0.0 [5.764164e-06]\n",
      "0.0 [9.117861e-08]\n",
      "0.0 [0.00087568]\n",
      "0.0 [2.8875398e-05]\n",
      "0.0 [0.00182074]\n",
      "0.0 [0.02351153]\n",
      "1.0 [0.99999005]\n",
      "0.0 [0.00011794]\n",
      "0.0 [0.52094054]\n",
      "0.0 [7.5523036e-05]\n",
      "1.0 [0.9831218]\n",
      "1.0 [0.0674627]\n",
      "1.0 [0.95790005]\n",
      "0.0 [0.00480147]\n",
      "0.0 [0.02453111]\n",
      "1.0 [0.00857068]\n",
      "0.0 [0.00069414]\n",
      "1.0 [1.]\n",
      "0.0 [0.09647276]\n",
      "0.0 [0.00016518]\n",
      "1.0 [1.]\n",
      "1.0 [0.9998867]\n",
      "1.0 [0.9999974]\n",
      "0.0 [0.03637414]\n",
      "0.0 [2.8214912e-05]\n",
      "1.0 [0.84077835]\n",
      "1.0 [1.]\n",
      "0.0 [0.48405063]\n",
      "1.0 [0.764267]\n",
      "0.0 [2.2135785e-06]\n",
      "1.0 [1.]\n",
      "0.0 [1.3373639e-06]\n",
      "1.0 [0.9999995]\n",
      "0.0 [0.8959512]\n",
      "1.0 [0.82501894]\n",
      "0.0 [9.476577e-05]\n",
      "1.0 [0.99999565]\n",
      "0.0 [0.00185777]\n",
      "1.0 [1.]\n",
      "1.0 [2.5472928e-09]\n",
      "0.0 [6.3626203e-06]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00026368]\n",
      "1.0 [1.]\n",
      "0.0 [0.05084476]\n",
      "0.0 [0.00024871]\n",
      "0.0 [1.3176565e-10]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.0293771]\n",
      "0.0 [0.0026524]\n",
      "0.0 [0.99999875]\n",
      "1.0 [1.]\n",
      "0.0 [0.02886746]\n",
      "0.0 [0.03249779]\n",
      "0.0 [0.00024547]\n",
      "0.0 [0.81067526]\n",
      "0.0 [0.00163031]\n",
      "0.0 [0.00240616]\n",
      "0.0 [0.00014954]\n",
      "0.0 [0.00242996]\n",
      "1.0 [0.00060069]\n",
      "0.0 [0.00314989]\n",
      "0.0 [0.0203296]\n",
      "0.0 [5.9341405e-06]\n",
      "0.0 [0.99995023]\n",
      "1.0 [1.]\n",
      "0.0 [0.7950307]\n",
      "0.0 [0.14735055]\n",
      "1.0 [0.35202003]\n",
      "0.0 [0.17243473]\n",
      "0.0 [4.313897e-05]\n",
      "1.0 [1.]\n",
      "0.0 [2.6875874e-05]\n",
      "0.0 [0.00037561]\n",
      "0.0 [0.6661754]\n",
      "0.0 [0.43318275]\n",
      "0.0 [0.15927295]\n",
      "1.0 [0.13297382]\n",
      "1.0 [1.]\n",
      "0.0 [0.000156]\n",
      "0.0 [0.00071737]\n",
      "0.0 [1.]\n",
      "1.0 [0.9810841]\n",
      "0.0 [0.00371358]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.0156054]\n",
      "0.0 [1.8542072e-05]\n",
      "1.0 [0.03245022]\n",
      "1.0 [1.]\n",
      "0.0 [0.00145814]\n",
      "1.0 [0.8157588]\n",
      "0.0 [0.00047149]\n",
      "0.0 [3.1264562e-07]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.5953781]\n",
      "1.0 [1.]\n",
      "0.0 [0.00078405]\n",
      "0.0 [0.02562604]\n",
      "0.0 [0.00011793]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.00578777]\n",
      "0.0 [0.10117868]\n",
      "1.0 [1.]\n",
      "1.0 [0.9985373]\n",
      "0.0 [0.00012589]\n",
      "1.0 [0.38967946]\n",
      "0.0 [0.00042903]\n",
      "1.0 [0.9029959]\n",
      "1.0 [1.]\n",
      "1.0 [0.99947244]\n",
      "0.0 [2.5696788e-06]\n",
      "1.0 [0.9999997]\n",
      "0.0 [0.12372972]\n",
      "1.0 [0.9955171]\n",
      "1.0 [nan]\n",
      "0.0 [0.01080276]\n",
      "0.0 [3.838519e-12]\n",
      "0.0 [0.01570757]\n",
      "1.0 [1.]\n",
      "0.0 [0.06622496]\n",
      "0.0 [6.336539e-06]\n",
      "1.0 [0.9396861]\n",
      "1.0 [0.9998271]\n",
      "1.0 [0.99997]\n",
      "0.0 [1.6124376e-06]\n",
      "0.0 [0.0030386]\n",
      "0.0 [0.8678586]\n",
      "0.0 [6.4479085e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.03689677]\n",
      "0.0 [0.0518438]\n",
      "0.0 [0.00032445]\n",
      "1.0 [0.9999993]\n",
      "1.0 [0.82936317]\n",
      "1.0 [0.9999996]\n",
      "1.0 [0.00121937]\n",
      "1.0 [0.20622765]\n",
      "1.0 [0.91342175]\n",
      "1.0 [0.05231186]\n",
      "1.0 [0.9999978]\n",
      "1.0 [0.93312407]\n",
      "0.0 [0.1176805]\n",
      "0.0 [0.00255165]\n",
      "1.0 [1.]\n",
      "1.0 [0.99924153]\n",
      "0.0 [1.1778015e-05]\n",
      "0.0 [1.4918096e-05]\n",
      "0.0 [0.00050912]\n",
      "0.0 [3.4099905e-06]\n",
      "0.0 [0.04781833]\n",
      "0.0 [0.08443694]\n",
      "1.0 [0.9998559]\n",
      "0.0 [5.7744313e-05]\n",
      "0.0 [2.8844986e-05]\n",
      "1.0 [0.17932738]\n",
      "0.0 [0.09361877]\n",
      "1.0 [0.907465]\n",
      "0.0 [0.00083232]\n",
      "1.0 [1.]\n",
      "0.0 [0.00870482]\n",
      "1.0 [0.99995595]\n",
      "0.0 [0.98324543]\n",
      "1.0 [1.]\n",
      "0.0 [0.00090804]\n",
      "0.0 [0.75885594]\n",
      "0.0 [0.05926867]\n",
      "1.0 [0.06112261]\n",
      "1.0 [0.94569504]\n",
      "1.0 [0.92597806]\n",
      "0.0 [0.02275338]\n",
      "0.0 [0.2858527]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.00037244]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.8418145]\n",
      "1.0 [0.9999768]\n",
      "1.0 [0.99999523]\n",
      "0.0 [3.6823621e-06]\n",
      "1.0 [0.997315]\n",
      "0.0 [1.5324893e-05]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00169558]\n",
      "0.0 [0.01230965]\n",
      "1.0 [0.9558987]\n",
      "0.0 [4.061293e-05]\n",
      "0.0 [0.00079232]\n",
      "1.0 [1.]\n",
      "1.0 [0.9986849]\n",
      "0.0 [0.04585048]\n",
      "0.0 [0.00011412]\n",
      "0.0 [8.745812e-05]\n",
      "0.0 [0.02241554]\n",
      "0.0 [0.00098023]\n",
      "0.0 [0.00848818]\n",
      "1.0 [1.]\n",
      "1.0 [0.01819214]\n",
      "0.0 [0.3551363]\n",
      "0.0 [0.00847988]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.00524897]\n",
      "1.0 [1.]\n",
      "0.0 [7.6277365e-07]\n",
      "1.0 [1.]\n",
      "0.0 [0.00423662]\n",
      "1.0 [1.]\n",
      "1.0 [0.00036506]\n",
      "0.0 [0.00084314]\n",
      "1.0 [0.85961896]\n",
      "0.0 [1.7423939e-07]\n",
      "0.0 [0.20504464]\n",
      "0.0 [0.24670434]\n",
      "1.0 [0.00467354]\n",
      "0.0 [0.0199464]\n",
      "1.0 [0.9884544]\n",
      "1.0 [0.99998623]\n",
      "1.0 [1.]\n",
      "1.0 [0.99999994]\n",
      "0.0 [5.2986042e-09]\n",
      "1.0 [0.9990003]\n",
      "1.0 [1.]\n",
      "1.0 [0.00765369]\n",
      "1.0 [0.9999986]\n",
      "0.0 [0.12736134]\n",
      "0.0 [2.1349819e-05]\n",
      "0.0 [0.0726098]\n",
      "0.0 [0.03445713]\n",
      "1.0 [1.]\n",
      "1.0 [0.00120851]\n",
      "0.0 [0.00025963]\n",
      "0.0 [0.01214903]\n",
      "0.0 [0.0265763]\n",
      "0.0 [0.68942255]\n",
      "0.0 [1.0985951e-05]\n",
      "0.0 [0.00021092]\n",
      "1.0 [0.07213797]\n",
      "1.0 [0.23146023]\n",
      "0.0 [0.11865664]\n",
      "1.0 [1.]\n",
      "0.0 [0.00098215]\n",
      "1.0 [1.]\n",
      "0.0 [0.9999999]\n",
      "0.0 [0.03957301]\n",
      "1.0 [0.9999808]\n",
      "0.0 [0.00632695]\n",
      "1.0 [0.03582507]\n",
      "1.0 [1.]\n",
      "0.0 [0.00060736]\n",
      "0.0 [0.0793216]\n",
      "1.0 [0.03047412]\n",
      "0.0 [0.01476295]\n",
      "1.0 [0.9988131]\n",
      "1.0 [0.98718727]\n",
      "1.0 [1.]\n",
      "0.0 [0.6262051]\n",
      "0.0 [0.0152578]\n",
      "1.0 [0.9999999]\n",
      "0.0 [0.91079533]\n",
      "0.0 [0.00099447]\n",
      "1.0 [0.0029637]\n",
      "0.0 [0.00027234]\n",
      "0.0 [0.03752225]\n",
      "0.0 [0.00195189]\n",
      "0.0 [0.00011098]\n",
      "0.0 [4.2284514e-06]\n",
      "0.0 [3.2100115e-06]\n",
      "0.0 [0.06831782]\n",
      "0.0 [4.906335e-06]\n",
      "0.0 [0.00493322]\n",
      "0.0 [0.99966735]\n",
      "1.0 [1.]\n",
      "0.0 [0.99066925]\n",
      "0.0 [1.2637295e-09]\n",
      "0.0 [8.203533e-06]\n",
      "0.0 [0.24133745]\n",
      "0.0 [0.01416237]\n",
      "0.0 [0.01977188]\n",
      "0.0 [0.7741167]\n",
      "1.0 [1.]\n",
      "1.0 [0.0759448]\n",
      "1.0 [1.]\n",
      "0.0 [1.4602879e-05]\n",
      "1.0 [1.]\n",
      "0.0 [0.9263948]\n",
      "0.0 [1.]\n",
      "0.0 [0.08146702]\n",
      "0.0 [0.0057619]\n",
      "0.0 [0.00014532]\n",
      "1.0 [0.18706179]\n",
      "1.0 [0.9556927]\n",
      "0.0 [4.033599e-05]\n",
      "1.0 [0.01768326]\n",
      "0.0 [2.931453e-05]\n",
      "0.0 [0.00290133]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [8.671349e-06]\n",
      "0.0 [0.00119669]\n",
      "0.0 [0.00161997]\n",
      "0.0 [0.00085025]\n",
      "0.0 [0.00039823]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [0.2557041]\n",
      "0.0 [0.0027601]\n",
      "0.0 [0.21651953]\n",
      "1.0 [0.31405923]\n",
      "0.0 [5.382836e-06]\n",
      "1.0 [0.99698734]\n",
      "0.0 [3.433341e-07]\n",
      "1.0 [1.]\n",
      "0.0 [0.00718909]\n",
      "0.0 [9.470298e-05]\n",
      "0.0 [0.6251658]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "0.0 [7.944125e-05]\n",
      "0.0 [0.00279072]\n",
      "0.0 [0.99660397]\n",
      "0.0 [0.25558153]\n",
      "0.0 [0.48911664]\n",
      "0.0 [0.00784047]\n",
      "0.0 [1.4201111e-05]\n",
      "0.0 [0.01565754]\n",
      "1.0 [0.99992186]\n",
      "1.0 [0.99960387]\n",
      "1.0 [1.]\n",
      "1.0 [1.]\n",
      "1.0 [0.59316134]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test[i],pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "919a58e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f1ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 3827, 96)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1275, 96)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1271, 256)         123136    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 423, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 423, 256)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 421, 384)          295296    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 419, 384)          442752    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 417, 256)          295168    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 139, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 35584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              36439040  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,647,553\n",
      "Trainable params: 38,647,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "new_model = tf.keras.models.load_model('saved_model90%/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb3f9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e3b0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 2s - loss: 0.4767 - accuracy: 0.8667 - 2s/epoch - 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4766676425933838, 0.8667381405830383]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test,y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fe3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520e8e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColDefs(\n",
      "    name = 'CORRECTED_NABS_WITH_ALL_QSO'; format = 'D'\n",
      "    name = 'CORRECTED_NABS_WITH_QSO_SN_GR_1'; format = 'D'\n",
      "    name = 'CORRECTED_NABS_WITH_QSO_SN_GR_2'; format = 'D'\n",
      "    name = 'DEC_QSO'; format = 'D'; unit = 'DEG'\n",
      "    name = 'DELTA_V_MGII_2796'; format = 'D'; unit = 'km/s'\n",
      "    name = 'DELTA_V_MGII_2803'; format = 'D'; unit = 'km/s'\n",
      "    name = 'EIGENSPEC_INDEX'; format = 'K'\n",
      "    name = 'ERR_DELTA_V_MGII_2796'; format = 'D'; unit = 'km/s'\n",
      "    name = 'ERR_DELTA_V_MGII_2803'; format = 'D'; unit = 'km/s'\n",
      "    name = 'ERR_FWHM_VDISP_MGII_2796'; format = 'D'; unit = 'km/s'\n",
      "    name = 'ERR_FWHM_VDISP_MGII_2803'; format = 'D'; unit = 'km/s'\n",
      "    name = 'ERR_REST_EW_MGII_2796'; format = 'D'; unit = 'Angstrom'\n",
      "    name = 'ERR_REST_EW_MGII_2803'; format = 'D'; unit = 'Angstrom'\n",
      "    name = 'FIBER_ID'; format = 'K'\n",
      "    name = 'FWHM_VDISP_MGII_2796'; format = 'D'; unit = 'km/s'\n",
      "    name = 'FWHM_VDISP_MGII_2803'; format = 'D'; unit = 'km/s'\n",
      "    name = 'MJD'; format = 'K'\n",
      "    name = 'PARENT_QSO_ID'; format = 'K'\n",
      "    name = 'PLATE'; format = 'K'\n",
      "    name = 'RA_QSO'; format = 'D'; unit = 'DEG'\n",
      "    name = 'REST_EW_MGII_2796'; format = 'D'; unit = 'Angstrom'\n",
      "    name = 'REST_EW_MGII_2803'; format = 'D'; unit = 'Angstrom'\n",
      "    name = 'SNR_2796'; format = 'D'\n",
      "    name = 'SNR_2803'; format = 'D'\n",
      "    name = 'SNR_QSO_MEDIAN'; format = 'D'\n",
      "    name = 'Z_ABS'; format = 'D'\n",
      "    name = 'Z_ABS_ERR'; format = 'D'\n",
      "    name = 'Z_QSO'; format = 'D'\n",
      ")\n",
      "159524\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "hdul1 = fits.open('../SDSS_DR16_QSO_based_MgII_Absorber_Catalog.fits')\n",
    "print(hdul1[1].columns)\n",
    "\n",
    "Plate1 = hdul1[1].data['PLATE']\n",
    "Fiber1 = hdul1[1].data['FIBER_ID']\n",
    "MJD1 = hdul1[1].data['MJD']\n",
    "Zabs = hdul1[1].data['Z_ABS']\n",
    "Nabs = hdul1[1].data['CORRECTED_NABS_WITH_ALL_QSO']\n",
    "Zqso1 = hdul1[1].data['Z_QSO']\n",
    "Rew_2796 = hdul1[1].data['REST_EW_MGII_2796']\n",
    "err_Rew_2796 = hdul1[1].data['ERR_REST_EW_MGII_2796']\n",
    "Rew_2803 = hdul1[1].data['REST_EW_MGII_2803']\n",
    "err_Rew_2803 = hdul1[1].data['ERR_REST_EW_MGII_2803']\n",
    "print(len(MJD1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4f5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "Plate1 = list(Plate1)\n",
    "Fiber1 = list(Fiber1)\n",
    "for i in range(len(MJD1)):\n",
    "    if len(str(Plate1[i]))==3:\n",
    "        Plate1[i] = '0'+str(Plate1[i])\n",
    "    if len(str(Fiber1[i]))==3:\n",
    "        Fiber1[i] = '0'+str(Fiber1[i])\n",
    "    if len(str(Plate1[i]))==2:\n",
    "        Plate1[i] = '00'+str(Plate1[i])\n",
    "    if len(str(Fiber1[i]))==2:\n",
    "        Fiber1[i] = '00'+str(Fiber1[i])\n",
    "    if len(str(Plate1[i]))==1:\n",
    "        Plate1[i] = '000'+str(Plate1[i])\n",
    "    if len(str(Fiber1[i]))==1:\n",
    "        Fiber1[i] = '000'+str(Fiber1[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0308a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\IUCAA\\mg2\n"
     ]
    }
   ],
   "source": [
    "cd D:\\\\IUCAA\\\\mg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93386f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159524\n"
     ]
    }
   ],
   "source": [
    "import glob,os\n",
    "files = os.listdir('../CNN-DR16/Data/non/')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d469f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\IUCAA\\CNN-Dr16\\Data\\non\n"
     ]
    }
   ],
   "source": [
    "cd ../CNN-Dr16/Data/non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50c36e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColDefs(\n",
      "    name = 'flux'; format = 'E'\n",
      "    name = 'loglam'; format = 'E'\n",
      "    name = 'ivar'; format = 'E'\n",
      "    name = 'and_mask'; format = 'J'\n",
      "    name = 'or_mask'; format = 'J'\n",
      "    name = 'wdisp'; format = 'E'\n",
      "    name = 'sky'; format = 'E'\n",
      "    name = 'model'; format = 'E'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "spectra = fits.open(files[1])\n",
    "print(spectra[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d746e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ivar = spectra[1].data['ivar']\n",
    "error = 1.0/np.sqrt(ivar)\n",
    "model = spectra[1].data['model']\n",
    "flux = spectra[1].data['FLUX']\n",
    "wave = 10**spectra[1].data['loglam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80346b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d123d0e8e0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(wave,flux/model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aadbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files= files[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01f01378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a07746623a3401398eabce04ec0459b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "4\n",
      "996\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "discard = []\n",
    "for i in tqdm(range(len(MJD1))):\n",
    "    for j in range(len(files)):\n",
    "        if 'spec-'+str(Plate1[i])+ '-' +str(MJD1[i])+ '-'+str(Fiber1[i])+'.fits' == files[j]:\n",
    "            if Rew_2796[i] < 3*err_Rew_2796[i] and Rew_2803[i] < 3*err_Rew_2803[i]:\n",
    "                name = files[j]\n",
    "                discard.append(name)\n",
    "\n",
    "print(len(files))\n",
    "print(len(discard))\n",
    "ew_checked = list(set(files) - set(discard))\n",
    "print(len(ew_checked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c828089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "ew_checked = list(set(files) - set(discard))\n",
    "print(len(ew_checked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97fd000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_files = ew_checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55312e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1af5fae345941d791ebc5b92e95efcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "list_Z_emi1 = []\n",
    "temp = []\n",
    "for i in tqdm(range(len(MJD1))):\n",
    "    for j in fits_files:\n",
    "        if 'spec-'+str(Plate1[i])+ '-' +str(MJD1[i])+ '-'+str(Fiber1[i])+'.fits' == j :\n",
    "            list_Z_emi1.append(Zqso1[i])\n",
    "            temp.append(j)\n",
    "print(len(list_Z_emi1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f148833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60067,)\n"
     ]
    }
   ],
   "source": [
    "list_z = list_Z_emi1\n",
    "list_z = np.array(list_z)\n",
    "print(list_z.shape)\n",
    "np.save('list_Z_emi_60k', list_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e202f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fits_files[:100]\n",
    "list_Z_emi = list_Z_emi1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cef439d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Z_emi = list_Z_emi1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c6e2756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f7e5a5e5684b3d90d13a0566c57e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48 0\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "specs = []\n",
    "waves = []\n",
    "\n",
    "unchanged = 0\n",
    "\n",
    "for f in tqdm(range(len(temp))):\n",
    "    #spectra = fits.open('../CNN-DR16/Data/non/'+ temp[f] )\n",
    "    spectra = fits.open( temp[f] )\n",
    "    wave = 10**spectra[1].data['loglam']\n",
    "    flux = spectra[1].data['flux']\n",
    "    model = spectra[1].data['model']\n",
    "    if list_Z_emi[f] <=1:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 4250 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "    \n",
    "    elif 1< list_Z_emi[f] <= 1.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 3100 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    elif 1.8< list_Z_emi[f] <= 2.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 2250 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    elif 2.8< list_Z_emi[f] <= 4.8:\n",
    "        X,Y,Z = [],[],[]\n",
    "        for i in range(wave.shape[0]):\n",
    "            if wave[i] > 1500 :\n",
    "                X.append(flux[i])\n",
    "                Y.append(model[i])\n",
    "                Z.append(wave[i])\n",
    "        specs.append(np.array(X)/np.array(Y))\n",
    "        waves.append(Z)\n",
    "        \n",
    "    else:\n",
    "        unchanged = unchanged + 1\n",
    "        specs.append(flux/model)\n",
    "        waves.append(wave)\n",
    "    \n",
    "print(len(specs), len(waves), unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a670620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc58092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1698480ea245c6a3914558d21fdf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 3841, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "import numpy as np\n",
    "specs_inter = []\n",
    "temp = specs\n",
    "#specs, specs2 = [], []\n",
    "for i in tqdm(temp):\n",
    "    x = np.array(i)\n",
    "    i = 3841\n",
    "    z = i / len(x)\n",
    "    x_int = interpolation.zoom(x,z)\n",
    "    np.expand_dims(x_int, axis=0)\n",
    "    specs_inter.append(x_int)\n",
    "specs_inter = np.array(specs_inter)\n",
    "specs_inter = np.expand_dims(specs_inter, axis=2)\n",
    "print(specs_inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e10bb1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 94ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = new_model.predict(specs_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b75cd76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999801]\n",
      "[0.98356307]\n",
      "[0.98356307]\n",
      "[0.9984862]\n",
      "[0.99885464]\n",
      "[0.99999994]\n",
      "[0.00966564]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.46712413]\n",
      "[0.9354524]\n",
      "[0.5293124]\n",
      "[0.94103277]\n",
      "[0.68607014]\n",
      "[0.9998493]\n",
      "[0.9998493]\n",
      "[0.9985929]\n",
      "[0.9857469]\n",
      "[0.08675727]\n",
      "[0.99985343]\n",
      "[0.907784]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.10977903]\n",
      "[0.9991618]\n",
      "[0.9999999]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.99711025]\n",
      "[0.9999953]\n",
      "[1.]\n",
      "[0.92699677]\n",
      "[0.9986575]\n",
      "[0.99999994]\n",
      "[0.99999994]\n",
      "[0.99999994]\n",
      "[0.995929]\n",
      "[0.9994431]\n",
      "[0.00082082]\n",
      "[0.9989848]\n",
      "[0.9989848]\n",
      "[0.9996668]\n",
      "[0.93509203]\n",
      "[0.9993213]\n"
     ]
    }
   ],
   "source": [
    "for i in pred:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f29e9a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 9.6783 - accuracy: 0.1042 - 267ms/epoch - 133ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.67830753326416, 0.1041666641831398]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(specs_inter,np.zeros(48), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab376229",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = []\n",
    "for i in X_train:\n",
    "    i = i.reshape(23,167)\n",
    "    i = np.expand_dims(i, axis=-1)\n",
    "    reshaped.append(i)\n",
    "reshaped = np.array(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eb22faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11097, 23, 167, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1406fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 31s]\n",
      "val_loss: 0.6629297733306885\n",
      "\n",
      "Best val_loss So Far: 0.6629297733306885\n",
      "Total elapsed time: 00h 00m 31s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "resnet            |vanilla           |image_block_1/block_type\n",
      "True              |True              |image_block_1/normalize\n",
      "True              |False             |image_block_1/augment\n",
      "True              |None              |image_block_1/image_augmentation_1/horizontal_flip\n",
      "True              |None              |image_block_1/image_augmentation_1/vertical_flip\n",
      "0                 |None              |image_block_1/image_augmentation_1/contrast_factor\n",
      "0                 |None              |image_block_1/image_augmentation_1/rotation_factor\n",
      "0.1               |None              |image_block_1/image_augmentation_1/translation_factor\n",
      "0                 |None              |image_block_1/image_augmentation_1/zoom_factor\n",
      "False             |None              |image_block_1/res_net_block_1/pretrained\n",
      "resnet50          |None              |image_block_1/res_net_block_1/version\n",
      "True              |None              |image_block_1/res_net_block_1/imagenet_size\n",
      "global_avg        |flatten           |classification_head_1/spatial_reduction_1/reduction_type\n",
      "0                 |0.5               |classification_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 165s 510ms/step - loss: 0.7185 - accuracy: 0.6084 - val_loss: 71.0114 - val_accuracy: 0.5063\n",
      "Epoch 2/10\n",
      "270/295 [==========================>...] - ETA: 12s - loss: 0.5672 - accuracy: 0.7160Not enough memory, reduce batch size to 16.\n",
      "Epoch 1/10\n",
      "590/590 [==============================] - 155s 260ms/step - loss: 0.5504 - accuracy: 0.7302 - val_loss: 0.7996 - val_accuracy: 0.4912\n",
      "Epoch 2/10\n",
      "590/590 [==============================] - 158s 267ms/step - loss: 0.4919 - accuracy: 0.7768 - val_loss: 0.7104 - val_accuracy: 0.5088\n",
      "Epoch 3/10\n",
      "590/590 [==============================] - 157s 266ms/step - loss: 0.4623 - accuracy: 0.7897 - val_loss: 1.0853 - val_accuracy: 0.5069\n",
      "Epoch 4/10\n",
      "590/590 [==============================] - 160s 272ms/step - loss: 0.4462 - accuracy: 0.8012 - val_loss: 0.7322 - val_accuracy: 0.4906\n",
      "Epoch 5/10\n",
      "590/590 [==============================] - 164s 279ms/step - loss: 0.4388 - accuracy: 0.8020 - val_loss: 0.6978 - val_accuracy: 0.4955\n",
      "Epoch 6/10\n",
      "590/590 [==============================] - 159s 270ms/step - loss: 0.4308 - accuracy: 0.8126 - val_loss: 0.7917 - val_accuracy: 0.4931\n",
      "Epoch 7/10\n",
      "590/590 [==============================] - 159s 269ms/step - loss: 0.4204 - accuracy: 0.8124 - val_loss: 0.7906 - val_accuracy: 0.4925\n",
      "Epoch 8/10\n",
      "590/590 [==============================] - 159s 269ms/step - loss: 0.4168 - accuracy: 0.8175 - val_loss: 0.8219 - val_accuracy: 0.4925\n",
      "Epoch 9/10\n",
      " 49/590 [=>............................] - ETA: 2:23 - loss: 0.4192 - accuracy: 0.8227"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=2)\n",
    "clf.fit(\n",
    "    reshaped,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b57f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = []\n",
    "for i in X_test:\n",
    "    i = i.reshape(23,167)\n",
    "    i = np.expand_dims(i, axis=-1)\n",
    "    reshaped.append(i)\n",
    "reshaped = np.array(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fe3063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 7ms/step\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "88/88 [==============================] - 1s 5ms/step - loss: 0.5944 - accuracy: 0.6758\n",
      "[0.5944477319717407, 0.6758202314376831]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(reshaped)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(reshaped, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7b11709",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 1.0\n",
      "[1.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[0.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 0.0\n",
      "[0.] 0.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(predicted_y[i],  y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a269b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6758202567760342\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, predicted_y, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c23218",
   "metadata": {},
   "source": [
    "# Personal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19deeba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=96, kernel_size=15, activation='relu', input_shape=(3841,1)))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=384, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=384, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99db60ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14020, 3842, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "import numpy as np\n",
    "specs_inter = []\n",
    "#temp = #specs + specs2\n",
    "#specs, specs2 = [], []\n",
    "for i in (temp):\n",
    "    x = np.array(i)\n",
    "    i = 3842\n",
    "    z = i / len(x)\n",
    "    x_int = interpolation.zoom(x,z)\n",
    "    np.expand_dims(x_int, axis=0)\n",
    "    specs_inter.append(x_int)\n",
    "specs_inter = np.array(specs_inter)\n",
    "specs_inter = np.expand_dims(specs_inter, axis=2)\n",
    "print(specs_inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d82997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225837fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3841 into shape (1921,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m reshaped \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m specs_inter:\n\u001b[1;32m----> 3\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1921\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#i = np.expand_dims(i, axis=-1)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     reshaped\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 3841 into shape (1921,2)"
     ]
    }
   ],
   "source": [
    "reshaped = []\n",
    "for i in specs_inter:\n",
    "    i = i.reshape(1921,2)\n",
    "    #i = np.expand_dims(i, axis=-1)\n",
    "    reshaped.append(i)\n",
    "reshaped = np.array(reshaped)\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1ca70195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13902, 1921, 2, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ed178984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from classification_models_1D.tfkeras import Classifiers\n",
    "\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "#model = ResNet18(input_shape=(1921, 2), weights='imagenet',include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5da934e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "resnet_model = Sequential()\n",
    "\n",
    "pretrained_model= ResNet18(input_shape=(1921, 2), weights='imagenet',include_top = False)\n",
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "resnet_model.add(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72a1cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 2, 512)            11183752  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,758,665\n",
      "Trainable params: 1,574,913\n",
      "Non-trainable params: 11,183,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(1024, activation='relu'))\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(1, activation='softmax'))\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df58bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0990970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 11216 11216\n",
      "testing data: 2804 2804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reshaped, label, random_state=42, train_size = .8)\n",
    "print('training data:', len(X_train), len(y_train))\n",
    "print('testing data:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "96599ed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 3831, 3830, 3823, 3829, 3835, 3844, 3826, 3182, 3815, 3833, 3840, 3825, 3816, 3827, 3822, 3818, 3836, 3845, 3840, 3818, 3832, 3362, 3358, 3844, 3821, 3812, 3824, 3806, 3850, 3837, 3828, 3842, 3834, 3840, 3836, 3831, 3844, 3815, 3843, 3840, 3839, 3843, 3840, 3842, 3854, 3843, 3813, 3845, 3838, 3843, 3833, 3360, 3827, 3838, 3843, 3834, 3838, 3818, 3826, 3819, 3835, 3832, 3852, 3838, 3849, 3840, 3839, 3843, 3833, 3843, 3831, 3839, 3836, 3826, 3836, 3836, 3844, 3836, 3816, 3816, 3821, 3840, 3837, 3845, 3845, 3828, 3848, 3839, 3834, 3843, 3839, 3831, 3833, 3836, 3834, 3825, 3829, 3840, 3844, 3837, 3362, 3822, 3840, 3826, 3830, 3830, 3811, 3802, 3846, 3811, 3827, 3852, 3353, 3840, 3825, 3847, 3838, 3836, 3824, 3840, 3829, 3850, 3826, 3839, 3821, 3846, 3836, 3840, 3350, 3835, 3843, 3837, 3840, 3823, 3828, 3843, 3821, 3844, 3841, 3826, 3828, 3838, 3840, 3360, 3845, 3838, 3824, 3817, 3840, 3362, 3820, 3832, 3842, 3805, 3835, 3841, 3825, 3810, 3827, 3836, 3841, 3815, 3814, 3826, 3838, 3844, 3836, 3825, 3846, 3809, 3809, 3839, 3815, 3835, 3840, 3833, 3839, 3842, 3842, 3843, 3843, 3831, 3362, 3835, 3800, 3836, 3362, 3822, 3840, 3348, 3836, 3825, 3840, 3808, 3822, 3843, 3827, 3841, 3835, 3836, 3808, 3843, 3848, 3834, 3840, 3824, 3802, 3839, 3840, 3355, 3832, 3838, 3832, 3840, 3836, 3834, 3838, 3845, 3828, 3844, 3827, 3818, 3360, 3849, 3832, 3838, 3362, 3837, 3825, 3840, 3815, 3825, 3844, 3840, 3827, 3843, 3840, 3834, 3822, 3842, 3844, 3842, 3838, 3837, 3841, 3825, 3846, 3832, 3831, 3834, 3851, 3816, 3834, 3836, 3838, 3836, 3837, 3839, 3359, 3834, 3836, 3819, 3835, 3842, 3833, 3846, 3359, 3828, 3828, 3846, 3850, 3848, 3844, 3839, 3850, 3838, 3839, 3782, 3842, 3816, 3832, 3841, 3828, 3829, 3815, 3843, 3833, 3816, 3831, 3842, 3839, 3837, 3362, 3843, 3838, 3844, 3841, 3826, 3838, 3829, 3833, 3842, 3836, 3828, 3833, 3834, 3844, 3846, 3810, 3820, 3848, 3839, 3844, 3833, 3844, 3845, 3835, 3838, 3828, 3833, 3846, 3360, 3844, 3838, 3809, 3823, 3816, 3825, 3828, 3349, 3357, 3841, 3057, 3825, 3830, 3840, 3817, 3356, 3846, 3817, 3820, 3849, 3831, 3837, 3844, 3842, 3839, 3842, 3840, 3846, 3846, 3843, 3834, 3835, 3360, 3844, 3814, 3839, 3837, 3832, 3360, 3833, 3836, 3817, 3830, 3823, 3837, 3828, 3833, 3840, 3838, 3840, 3359, 3362, 3847, 3830, 3353, 3829, 3833, 3843, 3823, 3829, 3350, 3841, 3845, 3838, 3839, 3831, 3820, 3819, 3827, 3360, 3844, 3836, 3831, 3839, 3815, 3808, 3845, 3854, 3821, 3825, 3814, 3836, 3363, 3845, 3812, 3826, 3359, 3812, 3842, 3830, 3352, 3838, 3353, 3843, 3813, 3821, 3356, 3833, 3833, 3836, 3835, 3820, 3817, 3836, 3838, 3351, 3843, 3843, 3836, 3842, 3810, 3847, 3839, 3815, 3840, 3361, 3012, 3828, 3834, 3841, 3353, 3807, 3841, 3823, 3815, 3842, 3834, 3843, 3836, 3836, 3832, 3823, 3846, 3839, 3831, 3836, 3840, 3837, 3840, 3817, 3750, 3829, 3841, 3815, 3828, 3843, 3354, 3843, 3830, 3834, 3825, 3814, 3823, 3842, 3841, 3825, 3842, 3835, 3826, 3356, 3842, 3843, 3838, 3840, 3844, 3836, 3812, 3834, 3832, 3829, 3817, 3820, 3840, 3840, 3850, 3812, 3347, 3843, 3829, 3843, 3794, 3354, 3838, 3843, 3841, 3852, 3847, 3838, 3837, 3836, 3821, 3836, 3833, 3828, 3847, 3845, 3848, 3826, 3828, 3812, 3811, 3825, 3847, 3807, 3811, 3829, 3829, 3841, 3836, 3815, 3354, 3846, 3822, 3837, 3837, 3844, 3836, 3831, 3844, 3826, 3837, 3839, 3842, 3835, 3822, 3834, 3825, 3850, 3837, 3835, 3843, 3830, 3842, 3364, 3821, 3839, 3844, 3820, 3840, 3809, 3845, 3842, 3846, 3827, 3828, 3835, 3807, 3828, 3827, 3844, 3823, 3811, 3834, 3827, 3836, 3844, 3838, 3846, 3817, 3837, 3823, 3847, 3804, 3834, 3838, 3836, 3805, 3844, 3833, 3352, 3830, 3843, 3838, 3841, 3842, 3830, 3828, 3845, 3832, 3806, 3843, 3835, 3841, 3835, 3834, 3836, 3842, 3830, 3827, 3835, 3810, 3815, 3827, 3813, 3829, 3836, 3812, 3819, 3848, 3827, 3824, 3809, 3850, 3836, 3825, 3844, 3847, 3838, 3843, 3825, 3840, 3834, 3832, 3831, 3817, 3844, 3355, 3362, 3356, 3828, 3832, 3831, 3830, 3843, 3843, 3849, 3840, 3848, 3841, 3802, 3823, 3830, 3836, 3809, 3817, 3835, 3823, 3833, 3357, 3847, 3821, 3832, 3836, 3842, 3830, 3845, 3808, 3834, 3848, 3836, 3846, 3842, 3827, 3828, 3840, 3836, 3839, 3827, 3840, 3844, 3843, 3815, 3842, 3836, 3827, 3821, 3827, 3838, 3838, 3846, 3841, 3840, 3846, 3351, 3844, 3853, 3827, 3834, 3837, 3832, 3821, 3838, 3352, 3843, 3846, 3836, 3841, 3838, 3831, 3812, 3824, 3827, 3827, 3850, 3846, 3680, 3851, 3350, 3836, 3803, 3802, 3831, 3844, 3838, 3829, 3812, 3832, 3817, 3832, 3843, 3820, 3841, 3834, 3838, 3825, 3842, 3835, 3846, 3826, 3822, 3832, 3822, 3362, 3845, 3841, 3830, 3836, 3842, 3842, 3842, 3840, 3822, 3845, 3819, 3840, 3824, 3813, 3839, 3843, 3830, 3838, 3839, 3808, 3843, 3837, 3817, 3841, 3842, 3841, 3842, 3839, 3838, 3840, 3828, 3823, 3821, 3830, 3844, 3842, 3843, 3833, 3811, 3842, 3357, 3839, 3839, 3838, 3837, 3848, 3835, 3823, 3838, 3844, 3824, 3802, 3826, 3803, 3839, 3831, 3843, 3844, 3820, 3834, 3810, 3812, 3839, 3844, 3836, 3838, 3843, 3836, 3350, 3833, 3834, 3356, 3821, 3847, 3843, 3830, 3845, 3810, 3829, 3804, 3842, 3841, 3831, 3833, 3825, 3814, 3843, 3836, 3838, 3827, 3828, 3836, 3830, 3842, 3852, 3834, 3841, 3835, 3842, 3832, 3834, 3851, 3839, 3816, 3362, 3834, 3826, 3812, 3810, 3829, 3842, 3835, 3840, 3842, 3841, 3356, 3813, 3362, 3836, 3822, 3842, 3823, 3835, 3839, 3827, 3820, 3834, 3826, 3350, 3826, 3841, 3836, 3825, 3838, 3842, 3838, 3844, 3808, 3843, 3833, 3843, 3843, 3842, 3813, 3355, 3833, 3844, 3829, 3832, 3846, 3841, 3828, 3848, 3809, 3845, 3841, 3824, 3840, 3833, 3838, 3815, 3828, 3832, 3832, 3841, 3838, 3816, 3839, 3833, 3806, 3840, 3818, 3358, 3822, 3841, 3348, 3796, 3836, 3833, 3842, 3842, 3830, 3785, 3806, 3807, 3840, 3844, 3827, 3810, 3816, 3850, 3822, 3828, 3841, 3350, 3837, 3832, 3844, 3830, 3850, 3358, 3845, 3832, 3835, 3838, 3827, 3842, 3362, 3842, 3813, 3829, 3837, 3820, 3828, 3832, 3835, 3839, 3828, 3842, 3844, 3812, 3837, 3822, 3822, 3848, 3843, 3841, 3838, 3364, 3841, 3842, 3814, 3815, 3843, 3835, 3840, 3841, 3842, 3832, 3846, 3827, 3845, 3838, 3834, 3839, 3838, 3361, 3835, 3822, 3833, 3847, 3843, 3830, 3832, 3828, 3814, 3362, 3362, 3817, 3844, 3842, 3840, 3832, 3806, 3353, 3841, 3836, 3840, 3841, 3818, 3848, 3841, 3811, 3835, 3835, 3836, 3356, 3808, 3832, 3833, 3844, 3812, 3840, 3354, 3841, 3825, 3835, 3847, 3850, 3835, 3837, 3844, 3842, 3835, 3814, 3839, 3827, 3816, 3350, 3845, 3844, 3838, 3842, 3817, 3362, 3836, 3833, 3829, 3844, 3844, 3824, 3809, 3841, 3811, 3834, 3846, 3362, 3817, 3849, 3816, 3807, 3825, 3842, 3838, 3832, 3836, 3358, 3840, 3348, 3840, 3822, 3815, 3815, 3827, 3839, 3831, 3851, 3843, 3845, 3833, 3838, 3839, 3817, 3836, 3841, 3836, 3839, 3833, 3831, 3359, 3845, 3845, 3842, 3844, 3832, 3346, 3835, 3820, 3838, 3846, 3823, 3831, 3812, 3839, 3842, 3844, 3819, 3832, 3810, 3818, 3823, 3827, 3810, 3826, 3842, 3843, 3839, 3819, 3832, 3831, 3345, 3842, 3832, 3827, 3843, 3831, 3827, 3832, 3822, 3834, 3834, 3838, 3840, 3822, 3831, 3843, 3839, 3844, 3844, 3833, 3845, 3823, 3835, 3848, 3837, 3845, 3839, 3824, 3842, 3365, 3825, 3820, 3843, 3805, 3817, 3833, 3826, 3353, 3835, 3809, 3839, 3828, 3830, 3834, 3843, 3835, 3805, 3842, 3823, 3839, 3828, 3836, 3824, 3849, 3839, 3819, 3841, 3828, 3840, 3817, 3839, 3844, 3840, 3844, 3362, 3826, 3816, 3821, 3811, 3839, 3815, 3353, 3830, 3840, 3842, 3825, 3837, 3829, 3818, 3843, 3842, 3818, 3808, 3831, 3834, 3829, 3801, 3848, 3845, 3350, 3829, 3355, 3844, 3841, 3830, 3837, 3850, 3839, 3820, 3842, 3844, 3835, 3813, 3843, 3841, 3828, 3824, 3843, 3829, 3362, 3839, 3835, 3828, 3822, 3808, 3842, 3833, 3831, 3832, 3818, 3832, 3845, 3818, 3841, 3839, 3835, 3843, 3826, 3831, 3838, 3840, 3350, 3844, 3802, 3832, 3832, 3847, 3354, 3355, 3831, 3819, 3837, 3840, 3848, 3815, 3847, 3840, 3812, 3828, 3835, 3842, 3843, 3824, 3836, 3839, 3818, 3839, 3828, 3844, 3506, 3842, 3834, 3828, 3839, 3833, 3842, 3845, 3835, 3848, 3847, 3841, 3847, 3840, 3834, 3808, 3822, 3833, 3354, 3803, 3823, 3830, 3820, 3825, 3827, 3838, 3843, 3842, 3838, 3827, 3833, 3843, 3359, 3840, 3840, 3839, 3821, 3833, 3833, 3838, 3818, 3833, 3817, 3845, 3819, 3841, 3820, 3825, 3842, 3477, 3838, 3838, 3842, 3841, 3349, 3837, 3827, 3815, 3847, 3843, 3843, 3823, 3845, 3825, 3844, 3841, 3824, 3839, 3841, 3825, 3839, 3834, 3838, 3831, 3843, 3840, 3843, 3851, 3358, 3827, 3845, 3830, 3842, 3842, 3841, 3806, 3819, 3834, 3841, 3827, 3844, 3835, 3826, 3829, 3844, 3835, 3823, 3814, 3830, 3836, 3835, 3362, 3837, 3822, 3351, 3840, 3836, 3844, 3843, 3358, 3843, 3845, 3844, 3827, 3824, 3815, 3840, 3826, 3848, 3840, 3817, 3842, 3850, 3845, 3845, 3823, 3814, 3362, 3364, 3841, 3835, 3842, 3820, 3826, 3804, 3821, 3818, 3820, 3824, 3833, 3359, 3833, 3833, 3841, 3839, 3816, 3829, 3834, 3831, 3819, 3842, 3847, 3840, 3836, 3809, 3837, 3829, 3833, 3838, 3840, 3486, 3802, 3362, 3844, 3835, 3840, 3840, 3839, 3835, 3814, 3827, 3852, 3829, 3830, 3837, 3844, 3829, 3820, 3838, 3822, 3837, 3841, 3840, 3820, 3809, 3839, 3836, 3844, 3833, 3843, 3806, 3853, 3839, 3840, 3841, 3855, 3838, 3837, 3845, 3827, 3831, 3832, 3838, 3841, 3839, 3823, 3835, 3831, 3832, 3812, 3842, 3839, 3814, 3841, 3828, 3841, 3839, 3818, 3841, 3839, 3837, 3837, 3842, 3774, 3818, 3841, 3843, 3362, 3839, 3813, 3836, 3837, 3831, 3846, 3802, 3841, 3843, 3818, 3842, 3817, 3835, 3842, 3819, 3836, 3841, 3814, 3826, 3833, 3840, 3832, 3817, 3823, 3840, 3848, 3830, 3828, 3842, 3824, 3833, 3833, 3832, 3819, 3836, 3805, 3803, 3844, 3815, 3846, 3846, 3837, 3085, 3822, 3830, 3840, 3823, 3844, 3833, 3827, 3821, 3351, 3841, 3847, 3832, 3836, 3837, 3063, 3833, 3830, 3848, 3827, 3808, 3833, 3825, 3842, 3833, 3840, 3846, 3833, 3362, 3804, 3845, 3836, 3846, 3841, 3831, 3840, 3837, 3823, 3839, 3826, 3821, 3812, 3836, 3830, 3834, 3833, 3804, 3836, 3355, 3838, 3846, 3833, 3841, 3836, 3831, 3837, 3821, 3377, 3820, 3836, 3825, 3839, 3836, 3831, 3825, 3813, 3843, 3844, 3813, 3834, 3838, 3834, 3823, 3353, 3840, 3835, 3829, 3843, 3827, 3827, 3829, 3841, 3819, 3843, 3845, 3827, 3810, 3846, 3840, 3806, 3828, 3819, 3362, 3836, 3840, 3815, 3828, 3837, 3835, 3809, 3829, 3853, 3819, 3830, 3831, 3831, 3511, 3839, 3844, 3840, 3835, 3831, 3843, 3831, 3351, 3819, 3840, 3844, 3845, 3846, 3826, 3828, 3840, 3845, 3834, 3847, 3812, 3832, 3848, 3818, 3352, 3820, 3824, 3843, 3824, 3838, 3842, 3362, 3840, 3355, 3842, 3838, 3845, 3827, 3834, 3839, 3839, 3842, 3844, 3836, 3814, 3845, 3819, 3826, 3840, 3807, 3361, 3837, 3842, 3840, 3841, 3832, 3824, 3818, 3840, 3848, 3813, 3838, 3851, 3842, 3362, 3837, 3838, 3840, 3837, 3842, 3840, 3841, 3839, 3837, 3847, 3832, 3843, 3837, 3835, 3818, 3817, 3843, 3828, 3833, 3828, 3838, 3846, 3834, 3839, 3841, 3833, 3839, 3830, 3822, 3826, 3835, 3838, 3838, 3823, 3840, 3837, 3359, 3810, 3362, 3834, 3828, 3847, 3804, 3838, 3840, 3826, 3820, 3829, 3806, 3841, 3843, 3843, 3819, 3809, 3842, 3829, 3845, 3817, 3815, 3837, 3844, 3842, 3824, 3838, 3843, 3842, 3841, 3824, 3843, 3842, 3826, 3835, 3755, 3840, 3846, 3846, 3837, 3822, 3837, 3831, 3826, 3816, 3819, 3825, 3364, 3833, 3840, 3810, 3814, 3827, 3846, 3819, 3804, 3833, 3841, 3826, 3364, 3839, 3838, 3828, 3839, 3851, 3838, 3830, 3825, 3833, 3843, 3829, 3829, 3811, 3829, 3810, 3353, 3832, 3839, 3839, 3819, 3806, 3831, 3822, 3827, 3831, 3839, 3817, 3845, 3847, 3830, 3831, 3807, 3836, 3835, 3840, 3825, 3831, 3357, 3846, 3826, 3841, 3832, 3830, 3841, 3841, 3849, 3831, 3841, 3820, 3836, 3843, 3841, 3817, 3830, 3839, 3830, 3843, 3815, 3804, 3839, 3841, 3837, 3842, 3827, 3842, 3351, 3844, 3818, 3833, 3837, 3838, 3844, 3838, 3827, 3819, 3833, 3816, 3824, 3841, 3831, 3832, 3821, 3833, 3835, 3811, 3845, 3831, 3825, 3838, 3573, 3830, 3828, 3843, 3834, 3842, 3827, 3839, 3845, 3839, 3845, 3828, 3839, 3839, 3844, 3838, 3822, 3842, 3821, 3839, 3838, 3840, 3841, 3840, 3839, 3837, 3352, 3833, 3842, 3839, 3820, 3843, 3841, 3821, 3841, 3838, 3837, 3834, 3839, 3844, 3824, 3836, 3841, 3807, 3841, 3360, 3800, 3813, 3838, 3835, 3825, 3847, 3830, 3812, 3836, 3839, 3849, 3837, 3844, 3817, 3833, 3842, 3847, 3849, 3820, 3832, 3362, 3845, 3844, 3362, 3829, 3824, 3847, 3837, 3832, 3839, 3834, 3850, 3843, 3843, 3819, 3816, 3833, 3835, 3833, 3838, 3835, 3843, 3829, 3840, 3837, 3829, 3838, 3843, 3837, 3824, 3840, 3844, 3837, 3840, 3810, 3841, 3846, 3831, 3844, 3838, 3820, 3829, 3843, 3825, 3821, 3845, 3819, 3837, 3825, 3837, 3844, 3847, 3840, 3803, 3842, 3836, 3831, 3824, 3828, 3809, 3831, 3839, 3823, 3841, 3847, 3837, 3844, 3836, 3841, 3821, 3842, 3837, 3827, 3842, 3811, 3351, 3820, 3836, 3825, 3814, 3840, 3836, 3841, 3813, 3817, 3827, 3805, 3840, 3842, 3844, 3846, 3844, 3847, 3836, 3850, 3837, 3846, 3843, 3839, 3833, 3842, 3845, 3812, 3827, 3834, 3839, 3824, 3840, 3357, 3824, 3837, 3821, 3830, 3831, 3825, 3823, 3841, 3834, 3845, 3838, 3843, 3837, 3357, 3826, 3815, 3828, 3843, 3840, 3837, 3841, 3847, 3829, 3834, 3830, 3847, 3838, 3803, 3837, 3846, 3841, 3844, 3836, 3843, 3845, 3835, 3826, 3844, 3821, 3841, 3822, 3841, 3819, 3823, 3810, 3843, 3837, 3821, 3830, 3820, 3834, 3816, 3844, 3840, 3834, 3816, 3819, 3836, 3838, 3834, 3836, 3829, 3825, 3812, 3830, 3842, 3835, 3835, 3362, 3804, 3842, 3834, 3841, 3804, 3798, 3842, 3835, 3837, 3845, 3817, 3818, 3844, 3831, 3841, 3839, 3840, 3846, 3807, 3837, 3841, 3841, 3807, 3360, 3845, 3825, 3356, 3835, 3843, 3833, 3842, 3826, 3838, 3836, 3826, 3816, 3832, 3850, 3823, 3838, 3356, 3827, 3361, 3810, 3847, 3842, 3817, 3834, 3840, 3837, 3832, 3803, 3378, 3838, 3837, 3816, 3844, 3839, 3805, 3355, 3844, 3835, 3837, 3835, 3834, 3841, 3348, 3843, 3806, 3814, 3840, 3845, 3835, 3349, 3841, 3820, 3831, 3832, 3804, 3831, 3824, 3833, 3832, 3831, 3843, 3831, 3836, 3842, 3809, 3836, 3838, 3839, 3833, 3124, 3832, 3349, 3824, 3839, 3842, 3814, 3814, 3840, 3827, 3829, 3834, 3841, 3840, 3851, 3845, 3828, 3842, 3834, 3846, 3362, 3840, 3821, 3817, 3828, 2544, 3839, 3842, 3836, 3844, 3851, 3845, 3845, 3837, 3808, 3839, 3836, 3821, 3841, 3815, 3848, 3825, 3840, 3842, 3843, 3838, 3833, 3362, 3843, 3352, 3842, 3834, 3839, 3840, 3805, 3358, 3832, 3835, 3843, 3833, 3845, 3830, 3839, 3825, 3844, 3826, 3831, 3842, 3837, 3351, 3827, 3823, 3841, 3811, 3840, 3841, 3845, 3844, 3830, 3841, 3811, 3841, 3839, 3822, 3836, 3351, 3811, 3349, 3844, 3831, 3841, 3836, 3806, 3841, 3826, 3814, 3827, 3830, 3812, 3845, 3843, 3829, 3813, 3840, 3846, 3834, 3844, 3834, 3833, 3829, 3845, 3802, 3836, 3846, 3831, 3835, 3849, 3827, 3842, 3823, 3842, 3831, 3828, 3827, 3816, 3833, 3841, 3842, 3841, 3836, 3826, 3824, 3359, 3812, 3819, 3835, 3834, 3848, 3846, 3824, 3837, 3842, 3849, 3842, 3847, 3362, 3846, 3842, 3841, 3827, 3824, 3839, 3841, 3853, 3355, 3845, 3835, 3834, 3838, 3838, 3362, 3827, 3823, 3815, 3842, 3836, 3823, 3841, 3839, 3824, 3842, 3832, 3835, 3824, 3833, 3370, 3821, 3818, 3811, 3828, 3839, 3839, 3834, 3806, 3840, 3819, 3840, 3829, 3831, 3820, 3820, 3829, 3350, 3831, 3840, 3841, 3818, 3844, 3846, 3824, 3846, 3847, 3837, 3821, 3833, 3838, 3809, 3834, 3842, 3829, 3840, 3844, 3844, 3816, 3841, 3839, 3844, 3845, 3842, 3804, 3837, 3842, 3827, 3357, 3820, 3845, 3820, 3827, 3818, 3833, 3837, 3835, 3844, 3813, 3841, 3802, 3844, 3844, 3844, 3839, 3835, 3839, 3836, 3827, 3846, 3831, 3836, 3835, 3825, 3825, 3835, 3829, 3806, 3827, 3825, 3844, 3841, 3850, 3839, 3828, 3831, 3350, 3835, 3841, 3756, 3837, 3817, 3837, 3837, 3844, 3830, 3837, 3828, 3842, 3839, 3827, 3818, 3840, 3815, 3812, 3842, 3817, 3838, 3834, 3358, 3838, 3840, 3362, 3833, 3824, 3831, 3821, 3825, 3828, 3825, 3366, 3839, 3841, 3841, 3834, 3844, 3846, 3362, 3833, 3843, 3820, 3841, 3844, 3834, 3836, 3808, 3827, 3841, 3833, 3818, 3840, 3820, 3839, 3839, 3356, 3841, 3840, 3838, 3838, 3844, 3842, 3833, 3840, 3841, 3831, 3839, 3352, 3825, 3818, 3830, 3838, 3840, 3845, 3816, 3839, 3835, 3813, 3837, 3839, 3822, 3835, 3810, 3846, 3821, 3841, 3843, 3834, 3848, 3816, 3832, 3829, 3836, 3819, 3833, 3832, 3812, 3825, 3810, 3841, 3812, 3354, 3826, 3824, 3840, 3831, 3823, 3834, 3847, 3833, 3838, 3844, 3829, 3838, 3816, 3838, 3839, 3824, 3834, 3824, 3806, 3835, 3828, 3812, 3838, 3829, 3811, 3250, 3816, 3832, 3839, 3837, 3837, 3828, 3821, 3832, 3347, 3840, 3813, 3805, 3836, 3832, 3351, 3835, 3803, 3817, 3842, 3833, 3364, 3841, 3830, 3834, 3841, 3820, 3830, 3839, 3813, 3351, 3831, 3843, 3841, 3831, 3836, 3818, 3836, 3829, 3822, 3832, 3840, 3840, 3839, 3827, 3813, 3837, 3841, 3819, 3838, 3837, 3846, 3835, 3836, 3828, 3831, 3835, 3815, 3828, 3731, 3832, 3354, 3822, 3834, 3843, 3811, 3837, 3351, 3364, 3833, 3835, 3844, 3838, 3840, 3841, 3836, 3818, 3811, 3838, 3841, 3350, 3847, 3846, 3839, 3843, 3362, 3817, 3825, 3828, 3829, 3826, 3846, 3843, 3829, 3841, 3838, 3820, 3820, 3821, 3842, 3839, 3838, 3841, 3834, 3824, 3816, 3815, 3842, 3821, 3835, 3834, 3833, 3355, 3827, 3354, 3828, 3832, 3842, 3837, 3829, 3827, 3835, 3835, 3837, 3356, 3845, 3835, 3829, 3824, 3801, 3842, 3850, 3840, 3843, 3819, 3362, 3848, 3843, 3836, 3842, 3823, 3829, 3832, 3832, 3846, 3807, 3839, 3838, 3833, 3824, 3838, 3836, 3837, 3845, 3357, 3347, 3828, 3821, 3844, 3814, 3833, 3840, 3845, 3835, 3838, 3843, 3840, 3848, 3838, 3836, 3853, 3847, 3853, 3815, 3843, 3833, 3838, 3365, 3810, 3835, 3826, 3820, 3831, 3841, 3837, 3840, 3838, 3835, 3832, 3842, 3837, 3832, 3817, 3840, 3845, 3843, 3362, 3841, 3841, 3832, 3838, 3841, 3844, 3356, 3841, 3841, 3839, 3356, 3834, 3808, 3837, 3817, 3818, 3827, 3830, 3833, 2597, 3813, 3801, 3829, 3807, 3831, 3824, 3829, 3842, 3807, 3833, 3841, 3831, 3821, 3806, 3361, 3833, 3840, 3833, 3842, 3847, 3793, 3827, 3821, 3842, 3832, 3841, 3827, 3817, 3829, 3838, 3841, 3846, 3843, 3840, 3833, 3846, 3837, 3836, 3840, 3832, 3807, 3843, 3834, 3830, 3838, 3817, 3843, 3840, 3839, 3846, 3830, 3835, 3836, 3806, 3835, 3357, 3831, 3843, 3840, 3832, 3362, 3840, 3835, 3357, 3820, 3846, 3839, 3841, 3847, 3838, 2918, 3841, 3843, 3832, 3840, 3836, 3848, 3826, 3360, 3816, 3841, 3837, 3844, 3822, 3815, 3835, 3809, 3823, 3815, 3807, 3843, 3818, 3839, 3811, 3842, 3833, 3839, 3828, 3842, 3817, 3843, 3841, 3812, 3841, 3823, 3839, 3837, 3844, 3823, 3845, 3359, 3818, 3832, 3819, 3810, 3844, 3844, 3837, 3843, 3819, 3814, 3843, 3829, 3843, 3819, 3828, 3832, 3812, 3835, 3840, 3842, 3841, 3831, 3823, 3822, 3843, 3356, 3841, 3839, 3841, 3840, 3826, 3840, 3838, 3839, 3840, 3821, 3836, 3838, 3838, 3831, 3839, 3837, 3830, 3835, 3835, 3845, 3821, 3829, 3840, 3841, 3841, 3843, 3812, 3842, 3825, 3847, 3823, 3843, 3807, 3841, 3838, 3362, 3355, 3835, 3815, 3837, 3843, 3819, 3838, 3842, 3810, 3362, 3837, 3840, 3852, 3362, 3824, 3839, 3841, 3831, 3839, 3836, 3850, 3842, 3837, 3831, 3823, 3828, 3843, 3838, 3349, 3825, 3813, 3823, 3827, 3830, 3816, 3843, 3816, 3836, 3839, 3832, 3839, 3850, 3806, 3347, 3350, 3826, 3834, 3837, 3845, 3839, 3838, 3838, 3833, 3837, 3829, 3822, 3359, 3842, 3851, 3836, 3841, 3818, 3831, 3833, 3354, 3835, 3362, 3842, 3348, 3835, 3844, 3830, 3842, 3821, 3833, 3835, 3846, 3815, 3839, 3825, 3845, 3828, 3355, 3841, 3842, 3833, 3840, 3828, 3843, 3831, 3835, 3833, 3828, 3840, 3829, 3845, 3844, 3828, 3827, 3827, 3821, 3840, 3822, 3815, 3841, 3829, 3846, 3845, 3833, 3826, 3841, 3352, 3847, 3362, 3839, 3351, 3848, 3360, 3840, 3825, 3829, 3823, 3823, 3844, 3849, 3827, 3362, 3828, 3842, 3834, 3844, 3357, 3840, 3826, 3825, 3850, 3832, 3845, 3807, 3846, 3836, 3837, 3843, 3843, 3824, 3835, 3836, 3815, 3844, 3844, 3813, 3813, 3824, 3823, 3357, 3355, 3839, 3840, 3846, 3812, 3843, 3808, 3844, 3814, 3845, 3841, 3839, 3843, 3840, 3849, 3807, 3828, 3830, 3362, 3828, 3813, 3843, 3843, 3836, 3845, 3834, 3840, 3838, 3828, 3834, 3812, 3848, 3853, 3835, 3845, 3354, 3818, 3843, 3843, 3836, 3843, 3843, 3355, 3810, 3836, 3837, 3349, 3829, 3837, 3824, 3835, 3818, 3832, 3840, 3830, 3809, 3826, 3362, 3833, 3840, 3847, 3845, 3843, 3839, 3831, 3838, 3819, 3362, 3835, 3835, 3820, 3815, 3833, 3834, 3812, 3808, 3354, 3351, 3832, 3850, 3830, 3827, 3853, 3350, 3844, 3840, 3364, 3827, 3835, 3831, 3844, 3853, 3842, 3828, 3833, 3814, 3846, 3834, 3843, 3818, 3838, 3815, 3813, 3827, 3828, 3826, 3822, 3836, 3842, 3846, 3361, 3811, 3819, 3811, 3830, 3808, 3841, 3348, 3815, 3826, 3835, 3347, 3845, 3836, 3844, 3843, 3851, 3361, 3811, 3362, 3847, 3838, 3820, 3825, 3842, 3818, 3843, 3834, 3828, 3823, 3839, 3350, 3843, 3826, 3847, 3832, 3804, 3827, 3829, 3834, 3825, 3818, 3833, 3841, 3844, 3822, 3831, 3834, 3843, 3813, 3841, 3805, 3847, 3834, 3845, 3839, 3848, 3843, 3836, 3816, 3842, 3844, 3842, 3352, 3834, 3822, 3842, 3827, 3843, 3830, 3835, 3834, 3839, 3811, 3354, 3817, 3825, 3351, 3825, 3817, 3827, 3846, 3841, 3830, 3831, 3815, 3811, 3837, 3814, 3839, 3846, 3805, 3835, 3842, 3807, 3844, 3845, 3846, 3821, 3817, 3841, 3840, 3828, 3816, 3847, 3820, 3356, 3830, 3842, 3839, 3834, 3850, 3826, 3836, 3817, 3848, 3835, 3843, 3844, 3819, 3812, 3829, 3803, 3833, 3832, 3843, 3824, 3832, 3829, 3833, 3827, 3839, 3818, 3832, 3830, 3826, 3837, 3842, 3835, 3804, 3826, 3839, 3839, 3829, 3838, 3836, 3839, 3846, 3839, 3842, 3831, 3843, 3846, 3845, 3828, 3834, 3811, 3844, 3837, 3841, 3845, 3834, 3825, 3836, 3805, 3824, 3361, 3809, 3841, 3840, 3362, 3845, 3844, 3836, 3840, 3844, 3841, 3836, 3845, 3835, 3822, 3823, 3844, 3833, 3844, 3844, 3824, 3818, 3839, 3819, 3843, 3841, 3834, 3815, 3853, 3362, 3829, 3826, 3844, 3844, 3839, 3828, 3844, 3836, 3837, 3841, 3832, 3822, 3843, 3836, 3826, 3846, 3820, 3842, 3837, 3845, 3838, 3830, 3805, 3836, 3844, 3826, 3820, 3839, 3816, 3837, 3348, 3822, 3826, 3807, 3828, 3842, 3827, 3818, 3844, 3843, 3832, 3829, 3838, 3834, 3844, 3842, 3835, 3836, 3847, 3828, 3837, 3838, 3845, 3840, 3835, 3825, 3819, 3829, 3846, 3828, 3841, 3822, 3823, 3845, 3842, 3834, 3843, 3811, 3843, 3839, 3830, 3845, 3843, 3832, 3805, 3845, 3846, 3844, 3820, 3843, 3828, 3839, 3827, 3842, 3828, 3361, 3850, 3830, 3813, 3812, 3845, 3822, 3831, 3837, 3842, 3357, 3820, 3817, 3834, 3836, 3817, 3836, 3828, 3809, 3843, 3847, 3840, 3828, 3845, 3835, 3362, 3842, 3836, 3801, 3830, 3813, 3825, 3828, 3842, 3367, 3845, 3837, 3812, 3801, 3834, 3821, 3824, 3845, 3842, 3840, 3830, 3830, 3817, 3844, 3829, 3818, 3839, 3843, 3837, 3842, 3842, 3841, 3842, 3836, 3829, 3841, 3841, 3840, 3835, 3820, 3845, 3835, 3843, 3845, 3845, 3825, 3840, 3844, 3840, 3844, 3843, 3362, 3836, 3833, 3842, 3350, 3836, 3828, 3835, 3816, 3841, 3859, 3837, 3841, 3821, 3821, 3834, 3840, 3838, 3828, 3826, 3838, 3345, 3844, 3845, 3825, 3848, 3353, 3843, 3563, 3839, 3813, 3840, 3846, 3840, 3816, 3831, 3812, 3818, 3844, 3806, 3834, 3842, 3843, 3804, 3828, 3840, 3837, 3842, 3829, 3811, 3829, 3836, 3820, 3843, 3828, 3825, 3808, 3846, 3361, 3834, 3835, 3362, 3835, 3845, 3839, 3839, 3803, 3829, 3842, 3811, 3810, 3842, 3810, 3837, 3841, 3827, 3351, 3826, 3359, 3837, 3848, 3824, 3833, 3819, 3810, 3839, 3831, 3841, 3833, 3823, 3844, 3835, 3836, 3840, 3833, 3804, 3764, 3840, 3806, 3842, 3827, 3805, 3828, 3843, 3846, 3829, 3843, 3349, 3846, 3817, 3833, 3831, 3827, 3842, 3818, 3830, 3839, 3833, 3835, 3838, 3845, 3840, 3851, 3835, 3835, 3827, 3832, 3852, 3801, 3828, 3845, 3840, 3835, 3823, 3792, 3836, 3816, 3816, 3361, 3821, 3826, 3841, 3844, 3825, 3844, 3832, 3819, 3837, 3833, 3820, 3815, 3834, 3819, 3362, 3838, 3844, 3823, 3822, 3836, 3843, 3844, 3840, 3819, 3834, 3836, 3837, 3840, 3836, 3839, 3840, 3818, 3364, 3835, 3822, 3362, 3837, 3821, 3816, 3846, 3818, 3352, 3813, 3831, 3831, 3807, 3828, 3823, 3815, 3811, 3824, 3830, 3841, 3843, 3844, 3828, 3827, 3842, 3842, 3830, 3351, 3841, 3842, 3824, 3839, 3812, 3841, 3836, 3842, 3840, 3837, 3840, 3826, 3840, 3824, 3840, 3812, 3830, 3827, 3841, 3834, 3844, 3828, 3836, 3848, 3847, 3845, 3844, 3832, 3362, 3827, 3834, 3833, 3842, 3844, 3827, 3841, 3827, 3835, 3841, 3804, 3825, 3821, 3835, 3832, 3830, 3836, 3809, 3829, 3841, 3845, 3834, 3823, 3831, 3845, 3842, 3832, 3835, 3824, 3836, 3849, 3838, 3843, 3841, 3823, 3840, 3848, 3841, 3819, 3842, 3821, 2955, 3834, 3830, 3356, 3840, 3829, 3854, 3362, 3353, 3834, 3846, 3835, 3842, 3851, 3844, 3842, 3352, 3838, 3833, 3841, 3831, 3834, 3843, 3831, 3821, 3840, 3844, 3852, 3352, 3359, 3840, 3818, 3843, 3839, 3835, 3829, 3356, 3837, 3814, 3362, 3807, 3842, 3821, 3842, 3823, 3837, 3841, 3841, 3827, 3829, 3351, 3846, 3842, 3850, 3838, 3845, 3348, 3348, 3817, 3844, 3832, 3825, 3845, 3816, 3837, 3835, 3832, 3821, 3826, 3828, 3817, 3839, 3847, 3840, 3841, 3831, 3830, 3845, 3835, 3813, 3813, 3835, 3832, 3834, 3833, 3839, 3351, 3847, 3835, 3839, 3831, 3574, 3844, 3835, 3815, 3834, 3829, 3808, 3354, 3838, 3848, 3836, 3831, 3831, 3844, 3841, 3817, 3349, 3803, 3842, 3835, 3829, 3827, 3835, 3838, 3362, 3832, 3829, 3835, 3843, 3837, 3843, 3816, 3843, 3841, 3815, 3847, 3822, 3349, 3840, 3841, 3847, 3846, 3814, 3842, 3801, 3362, 3848, 3845, 3834, 3357, 3827, 3840, 3836, 3821, 3828, 3838, 3850, 3832, 3838, 3845, 3823, 3833, 3837, 3846, 3844, 3808, 3831, 3838, 3831, 3831, 3838, 3853, 3833, 3823, 3841, 3830, 3842, 3820, 3829, 3822, 3839, 3842, 3843, 3806, 3837, 3834, 3802, 3820, 3839, 3814, 3845, 3845, 3813, 3841, 3840, 3838, 3839, 3833, 3839, 3843, 3833, 3835, 3847, 3820, 3838, 3843, 3841, 3805, 3836, 3841, 3832, 3831, 3830, 3349, 3802, 3846, 3842, 3351, 3823, 3804, 3815, 3843, 3827, 3824, 3843, 3820, 3810, 3813, 3829, 3823, 3822, 3832, 3843, 3835, 3825, 3816, 3809, 3828, 3826, 3841, 3853, 3827, 3814, 3839, 3834, 3811, 3838, 3840, 3840, 3361, 3838, 3814, 3810, 3830, 3852, 3355, 3839, 3828, 3841, 3845, 3362, 3842, 3819, 3846, 3842, 3840, 3853, 3827, 3831, 3839, 3830, 3840, 3844, 3833, 3841, 3842, 3805, 3831, 3830, 3840, 3812, 3845, 3833, 3848, 3842, 3831, 3833, 3854, 3839, 3844, 3830, 3827, 3837, 3831, 3362, 3811, 3843, 3833, 3845, 3817, 3840, 3834, 3819, 3842, 3838, 3837, 3814, 3824, 3827, 3835, 3836, 3845, 3821, 3843, 3827, 3853, 3826, 3832, 3838, 3832, 3840, 3842, 3839, 3349, 3826, 3833, 3833, 3843, 3358, 3833, 3831, 3827, 3840, 3802, 3841, 3839, 3832, 3836, 3815, 3847, 3847, 3843, 3813, 3840, 3842, 3841, 3849, 3833, 3814, 3840, 3836, 3820, 3842, 3832, 3838, 3836, 3836, 3828, 3813, 3855, 3181, 3839, 3844, 3826, 3829, 3836, 3820, 3839, 3834, 3811, 3831, 3846, 3838, 3837, 3812, 3835, 3837, 3358, 3844, 3825, 3853, 3841, 3831, 3843, 3826, 3834, 3835, 3842, 3354, 3845, 3811, 3829, 3840, 3820, 3827, 3830, 3837, 3837, 3835, 3840, 3834, 3804, 3839, 3841, 3356, 3843, 3844, 3843, 3844, 3819, 3843, 3838, 3842, 3826, 3845, 3844, 3852, 3836, 3813, 3838, 3840, 3816, 3832, 3835, 3829, 3834, 3845, 3834, 3824, 3839, 3362, 3840, 3829, 3847, 3840, 3841, 3360, 3842, 3819, 3843, 3360, 3841, 3362, 3837, 3843, 3845, 3832, 3828, 3844, 3828, 3841, 3819, 3829, 3836, 3833, 3836, 3818, 3355, 3828, 3845, 3838, 3847, 3843, 3849, 3841, 3841, 3831, 3827, 3835, 3837, 3833, 3823, 3812, 3847, 3842, 3821, 3844, 3845, 3841, 3822, 3840, 3845, 3804, 3832, 3812, 3826, 3356, 3804, 3849, 3825, 3821, 3839, 3825, 3843, 3826, 3836, 3361, 3834, 3812, 3841, 3841, 3809, 3824, 3826, 3828, 3835, 3844, 3842, 3844, 3362, 3827, 3826, 3833, 3808, 3825, 3834, 3843, 3838, 3830, 3842, 3830, 3823, 3835, 3837, 3835, 3816, 3841, 3835, 3842, 3837, 3816, 3836, 3828, 3841, 3836, 3840, 3836, 3820, 3837, 3842, 3828, 3843, 3841, 3835, 3851, 3817, 3823, 3354, 3833, 3843, 3362, 3835, 3828, 3839, 3844, 3843, 3824, 3835, 3833, 3843, 3837, 3842, 3847, 3837, 3829, 3838, 3827, 3827, 3831, 3846, 3820, 3846, 3829, 3847, 3834, 3841, 3833, 3813, 3805, 3831, 3843, 3833, 3839, 3817, 3841, 3838, 3845, 3842, 3846, 3838, 3819, 3832, 3847, 3359, 3838, 3818, 3812, 3832, 3845, 3832, 3828, 3811, 3837, 3844, 3811, 3842, 3834, 3827, 3844, 3833, 3841, 3836, 3840, 3844, 3844, 3828, 3810, 3825, 3848, 3838, 3802, 3818, 3829, 3843, 3844, 3349, 3843, 3820, 3823, 3818, 3707, 3362, 3835, 3838, 3814, 3817, 3840, 3844, 3843, 3349, 3822, 3844, 3838, 3845, 3820, 3820, 3839, 3841, 3826, 3821, 3848, 3830, 3840, 3843, 3845, 3840, 3841, 3833, 3838, 3839, 3842, 3841, 3831, 3843, 3809, 3842, 3818, 3840, 3820, 3833, 3819, 3850, 3838, 3805, 3834, 3822, 3809, 3839, 3841, 3843, 3835, 3359, 3807, 3822, 3840, 3829, 3831, 3830, 3844, 3804, 3810, 3840, 3827, 3845, 3845, 3847, 3839, 3362, 3820, 3843, 3822, 3840, 3831, 3841, 3830, 3837, 3842, 3819, 3843, 3352, 3840, 3836, 3842, 3838, 3813, 3850, 3835, 3838, 3850, 3362, 3811, 3350, 3835, 3842, 3841, 3825, 3838, 3824, 3822, 3830, 3830, 3839, 3840, 3820, 3838, 3825, 3820, 3841, 3842, 3836, 3842, 3834, 3826, 3840, 3833, 3832, 3842, 3842, 3836, 3846, 3834, 3830, 3830, 3819, 3828, 3836, 3825, 3839, 3837, 3838, 3848, 3830, 3840, 3844, 3838, 3815, 3845, 3831, 3838, 3821, 3830, 3830, 3844, 3837, 3839, 3844, 3841, 3347, 3839, 3845, 3852, 3842, 3820, 3847, 3838, 3839, 3810, 3841, 3837, 3820, 3818, 3838, 3840, 3815, 3834, 3843, 3811, 3824, 3848, 3840, 3841, 3832, 3843, 3353, 3823, 3841, 3842, 3805, 3828, 3807, 3826, 3820, 3359, 3832, 3820, 3835, 3828, 3837, 3359, 3811, 3833, 3814, 3822, 3833, 3841, 3354, 3830, 3839, 3827, 3840, 3356, 3850, 3820, 3361, 3832, 3833, 3826, 3844, 3846, 3832, 3835, 3841, 3836, 3353, 3834, 3838, 3842, 3835, 3828, 3803, 3832, 3801, 3826, 3831, 3837, 3844, 3845, 3838, 3822, 3843, 3850, 3843, 3837, 3847, 3847, 3834, 3842, 3842, 3825, 3362, 3842, 3843, 3839, 3842, 3823, 3840, 3834, 3839, 3836, 3838, 3840, 3846, 3842, 3844, 3821, 3842, 3848, 3838, 3821, 3353, 3835, 3841, 3845, 3840, 3839, 3844, 3855, 3841, 3821, 3841, 3851, 3843, 3844, 3845, 3353, 3839, 3804, 3831, 3839, 3803, 3351, 3836, 3839, 3837, 3824, 3826, 3832, 3842, 3820, 3846, 3815, 3843, 3347, 3828, 3825, 3837, 3829, 3834, 3837, 3838, 3814, 3834, 3845, 3807, 3842, 3831, 3845, 3832, 3824, 3843, 3838, 3842, 3828, 3840, 3835, 3841, 3851, 3843, 3832, 3838, 3847, 3822, 3821, 3831, 3833, 3836, 3837, 3832, 3831, 3355, 3842, 3821, 3834, 3355, 3837, 3818, 3843, 3818, 3849, 3842, 3850, 3815, 3841, 3356, 3842, 3847, 3845, 3825, 3839, 3354, 3812, 3842, 3807, 3812, 3349, 3818, 3835, 3837, 3832, 3841, 3829, 3838, 3821, 3353, 3841, 3841, 3826, 3844, 3839, 3837, 3835, 3841, 3840, 3837, 3838, 3837, 3840, 3840, 3349, 3832, 3835, 3841, 3830, 3830, 3843, 3838, 3092, 3812, 3842, 3828, 3818, 3838, 3846, 3844, 3821, 3850, 3818, 3356, 3836, 3822, 3819, 3836, 3844, 3843, 3360, 3844, 3846, 3836, 3839, 3840, 3843, 3840, 3811, 3815, 3834, 3832, 3830, 3839, 3826, 3851, 3827, 3815, 3826, 3848, 3844, 3831, 3817, 3361, 3834, 3843, 3838, 3836, 3846, 3838, 3809, 3827, 3842, 3830, 3843, 3846, 3834, 3812, 3832, 3848, 3839, 3361, 3833, 3815, 3838, 3825, 3843, 3829, 3836, 3815, 3839, 3826, 3846, 3847, 3840, 3836, 3840, 3841, 3824, 3844, 3844, 3820, 3843, 3823, 3827, 3351, 3836, 3852, 3815, 3842, 3810, 3829, 3838, 3845, 3813, 3842, 3358, 3837, 3852, 3844, 3847, 3843, 3833, 3828, 3848, 3841, 3353, 3837, 3846, 3838, 3832, 3834, 3851, 3803, 3841, 3834, 3828, 3832, 3826, 3825, 3846, 3817, 3354, 3830, 3839, 3843, 3816, 3829, 3842, 3847, 3825, 3845, 3825, 3845, 3836, 3827, 3533, 3824, 3844, 3834, 3840, 3817, 3815, 3828, 3832, 3844, 3837, 3828, 3828, 3820, 3819, 3803, 3840, 3843, 3839, 3826, 3826, 3845, 3807, 3845, 3842, 3844, 3840, 3839, 3840, 3837, 3832, 3814, 3827, 3359, 3829, 3827, 3833, 3354, 3836, 3840, 3842, 3804, 3820, 3842, 3831, 3836, 3820, 3832, 3838, 3840, 3840, 3837, 3826, 2886, 3841, 3357, 3827, 3822, 3834, 3846, 3843, 3839, 3847, 3842, 3841, 3838, 3848, 3837, 3350, 3828, 3830, 3835, 3809, 3844, 3824, 3376, 3845, 3840, 3827, 3834, 3851, 3839, 3803, 3820, 3828, 3845, 3362, 3820, 3841, 3821, 3844, 3813, 3826, 3851, 3844, 3809, 3817, 3821, 3840, 3839, 3835, 3811, 3817, 3841, 3826, 3844, 3823, 3819, 3816, 3840, 3836, 3814, 3843, 3844, 3837, 3837, 3819, 3817, 3830, 3827, 3841, 3839, 3829, 3836, 3847, 3828, 3851, 3828, 3847, 3827, 3836, 3840, 3845, 3839, 3835, 3804, 3838, 3815, 3832, 3819, 3820, 3831, 3847, 3807, 3849, 3821, 3830, 3845, 3820, 3847, 3827, 3831, 3834, 3818, 3838, 3842, 3836, 3837, 3819, 3842, 3355, 3822, 3816, 3362, 3840, 3834, 3843, 3827, 3817, 3840, 3847, 3364, 3831, 3840, 3830, 3836, 3841, 3806, 3842, 3823, 3834, 3831, 3816, 3827, 3841, 3848, 3842, 3803, 3843, 3848, 3841, 3359, 3836, 3828, 3840, 3840, 3834, 3824, 3836, 3830, 3846, 3809, 3839, 3840, 3850, 3845, 3831, 3815, 3818, 3810, 3840, 3362, 3842, 3840, 3845, 3821, 3825, 3844, 3837, 3830, 3843, 3832, 3839, 3839, 3823, 3349, 3838, 3842, 3842, 3821, 3822, 3813, 3837, 3831, 3831, 3834, 3840, 3838, 3835, 3834, 3348, 3840, 3832, 3842, 3818, 3362, 3841, 3822, 3840, 3832, 3821, 3843, 3832, 3845, 3807, 3832, 3847, 3838, 3825, 3842, 3845, 3823, 3830, 3844, 3821, 3842, 3823, 3821, 3845, 3814, 3840, 3840, 3840, 3825, 3833, 3832, 3841, 3814, 3362, 3811, 3840, 3833, 3841, 3814, 3841, 3843, 3844, 3840, 3832, 3833, 3840, 3846, 3840, 3823, 3357, 3840, 3842, 3829, 3833, 3844, 3826, 3845, 3845, 3825, 3818, 3841, 3837, 3838, 3835, 3355, 3842, 3825, 3362, 3843, 3835, 3822, 3836, 3836, 3837, 3837, 3846, 3846, 3843, 3834, 3841, 3829, 3841, 3835, 3842, 3810, 3828, 3838, 3824, 3836, 3838, 3354, 3844, 3824, 3834, 3842, 3353, 3830, 3844, 3806, 3837, 3839, 3838, 3839, 3828, 3839, 3824, 3832, 3821, 3837, 3810, 3849, 3825, 3828, 3837, 3351, 3833, 3809, 3820, 3844, 3834, 3758, 3362, 3844, 3830, 3834, 3845, 3834, 3822, 3829, 3830, 3825, 3821, 3829, 3361, 3842, 3835, 3829, 3822, 3842, 3845, 3827, 3836, 3838, 3834, 3362, 3813, 3837, 3838, 3844, 3838, 3838, 3358, 3840, 3844, 3840, 3846, 3838, 3837, 3838, 3827, 3824, 3840, 3850, 3836, 3812, 3823, 3820, 3852, 3845, 3841, 3839, 3834, 3813, 3830, 3833, 3829, 3842, 3844, 3351, 3836, 3817, 3360, 3836, 3842, 3819, 3812, 3818, 3839, 3844, 3840, 3829, 3808, 3815, 3853, 3829, 3845, 3835, 3743, 3834, 3813, 3821, 3849, 3357, 3842, 3845, 3848, 3843, 3841, 3816, 3827, 3851, 3828, 3837, 3095, 3831, 3845, 3837, 3843, 3804, 3837, 3803, 3809, 3838, 3816, 3843, 3833, 3805, 3833, 3803, 3845, 3832, 3842, 3830, 3843, 3845, 3840, 3842, 3831, 3845, 3850, 3843, 3841, 3821, 3811, 3841, 3818, 3356, 3825, 3835, 3841, 3834, 3829, 3834, 3836, 3820, 3834, 3817, 3840, 3819, 3834, 3829, 3824, 3820, 3839, 3840, 3842, 3845, 3838, 3839, 3846, 3811, 3833, 3355, 3846, 3843, 3842, 3835, 3839, 3832, 3823, 3845, 3362, 3835, 3846, 3842, 3844, 3810, 3810, 3838, 3814, 3847, 3840, 3356, 3819, 3820, 3808, 3841, 3830, 3826, 3824, 3839, 3808, 3820, 3841, 3823, 3834, 3818, 3351, 3811, 3820, 3833, 3821, 3805, 3839, 3835, 3837, 3818, 3841, 3843, 3819, 3827, 3834, 3832, 3838, 3834, 3833, 3838, 3362, 3830, 3844, 3844, 3844, 3359, 3839, 3840, 3850, 3813, 3831, 3824, 3818, 3825, 3839, 3827, 3821, 3831, 3804, 3349, 3837, 3803, 3845, 3815, 3806, 3836, 3840, 3830, 3837, 3360, 3813, 3813, 3840, 3362, 3825, 3820, 3844, 3839, 3358, 3811, 3812, 3839, 3839, 3843, 3822, 3828, 3842, 3842, 3835, 3825, 3839, 3830, 3803, 3842, 3816, 3830, 3841, 3820, 3824, 3830, 3826, 3838, 3361, 3816, 3838, 3848, 3829, 3838, 3832, 3845, 3834, 3838, 3353, 3830, 3844, 3845, 3845, 3841, 3845, 3804, 3819, 3835, 3827, 3813, 3840, 3836, 3844, 3823, 3847, 3826, 3841, 3810, 3828, 3829, 3843, 3845, 3830, 3844, 3846, 3837, 3835, 3810, 3841, 3841, 3839, 3809, 3842, 3853, 3839, 3356, 3841, 3841, 3839, 3850, 3589, 3833, 3824, 3841, 3844, 3815, 3829, 3839, 3834, 3830, 3823, 3823, 3844, 3831, 3843, 3826, 3349, 3348, 3820, 3827, 3815, 3833, 3837, 3827, 3832, 3822, 3829, 3842, 3834, 3838, 3808, 3352, 3818, 3845, 3833, 3834, 3847, 3844, 3839, 3823, 3834, 3846, 3819, 3839, 3826, 3843, 3843, 3817, 3844, 3845, 3824, 3827, 3827, 3836, 3807, 3840, 3845, 3842, 3823, 3815, 3835, 3842, 3841, 3841, 3849, 3846, 3838, 3837, 3831, 3838, 3835, 3843, 3838, 3827, 3819, 3836, 3821, 3817, 3828, 3815, 3828, 3821, 3826, 3842, 3832, 3817, 3822, 3832, 3838, 3803, 3839, 3831, 3824, 3354, 3726, 3827, 3842, 3834, 3832, 3821, 3822, 3846, 3843, 3348, 3836, 3814, 3842, 3842, 3838, 3807, 3824, 3841, 3824, 3829, 3828, 3837, 3839, 3842, 3831, 3846, 3843, 3841, 3820, 3843, 3842, 3808, 3841, 3834, 3817, 3836, 3835, 3846, 3829, 3832, 3837, 3850, 3815, 3362, 3842, 3807, 3362, 3820, 3820, 3821, 3844, 3843, 3827, 3835, 3810, 3820, 3816, 3819, 3843, 3838, 3835, 3829, 3845, 3830, 3844, 3813, 3826, 3806, 3808, 3817, 3806, 3826, 3840, 3848, 3822, 3845, 3837, 3812, 3841, 3818, 3815, 3837, 3836, 3827, 3806, 3843, 3840, 3819, 3358, 3804, 3816, 3356, 3834, 3839, 3843, 3833, 3816, 3832, 3805, 3835, 3823, 3833, 3355, 3359, 3811, 3841, 3835, 3847, 3349, 3362, 3350, 3821, 3846, 3837, 3824, 3817, 3853, 3838, 3841, 3842, 3806, 3364, 3826, 3837, 3847, 3839, 3357, 3834, 3801, 3830, 3842, 3831, 3818, 3845, 3836, 3837, 3819, 3839, 3844, 3854, 3845, 3843, 3833, 3810, 3820, 3842, 3831, 3824, 3846, 3834, 3479, 3845, 3817, 3839, 3816, 3805, 3835, 3841, 3848, 3821, 3821, 3810, 3827, 3843, 3847, 3835, 3846, 3348, 3836, 3839, 3828, 3829, 3834, 3846, 3819, 3839, 3817, 3832, 3809, 3838, 3827, 3812, 3834, 3837, 3843, 3811, 3837, 3841, 3836, 3351, 3838, 3834, 3363, 3838, 3812, 3843, 3813, 3831, 3823, 3814, 3822, 3827, 3844, 3829, 3841, 3844, 3818, 3835, 3821, 3819, 3842, 3840, 3832, 3845, 3830, 3817, 3811, 3819, 3840, 3840, 3842, 3825, 3843, 3804, 3827, 3841, 3832, 3827, 3354, 3840, 3834, 3834, 3825, 3837, 3837, 3834, 3811, 3829, 3825, 3820, 3823, 3827, 3814, 3847, 3843, 3835, 3818, 3825, 3825, 3353, 3841, 3830, 3349, 3832, 3836, 3840, 3847, 3814, 3836, 3837, 3807, 3804, 3814, 3824, 3361, 3801, 3838, 3853, 3827, 3818, 3839, 3838, 3840, 3814, 3821, 3842, 3846, 3831, 3839, 3821, 3828, 3842, 3846, 3843, 3831, 3831, 3825, 3801, 3820, 3836, 3830, 3842, 3823, 3844, 3825, 3832, 3843, 3849, 3833, 3830, 3843, 3843, 3816, 3821, 3843, 3845, 3838, 3825, 3838, 3833, 3351, 3840, 3820, 3833, 3843, 3814, 3817, 3833, 3819, 3813, 3421, 3841, 3822, 3813, 3354, 3830, 3830, 3840, 3842, 3829, 3830, 3835, 3835, 3819, 3834, 3811, 3818, 3848, 3828, 3819, 3835, 3812, 3840, 3847, 3844, 3816, 3846, 3843, 3351, 3818, 3840, 3821, 3837, 3841, 3820, 3842, 3833, 3838, 3843, 3350, 3845, 3832, 3837, 3830, 3362, 3831, 3841, 3842, 3843, 3800, 3839, 3847, 3832, 3843, 3818, 3354, 3838, 3842, 3810, 3833, 3826, 3842, 3834, 3806, 3837, 3835, 3846, 3835, 3832, 3838, 3820, 3823, 3837, 3841, 3839, 3841, 3359, 3827, 3836, 3827, 3834, 3837, 3819, 3837, 3835, 3813, 3825, 3831, 3838, 3846, 3823, 3837, 3843, 3827, 3814, 3841, 3826, 3802, 3839, 3825, 3828, 3853, 3812, 3358, 3829, 3839, 3843, 3833, 3824, 3357, 3804, 3822, 3833, 3838, 3819, 3814, 3843, 3804, 3839, 3845, 3836, 3828, 3818, 3837, 3843, 3808, 3824, 3811, 3842, 3838, 3837, 3839, 3818, 3818, 3831, 3821, 3827, 3831, 3827, 3842, 3844, 3830, 3825, 3820, 3802, 3844, 3812, 3827, 3843, 3830, 3823, 3845, 3835, 3841, 3818, 3847, 3826, 3817, 3844, 3835, 3810, 3844, 3842, 3838, 3850, 3467, 3843, 3835, 3829, 3839, 3833, 3826, 3362, 3835, 3819, 3848, 3826, 3830, 3841, 3836, 3830, 3823, 3824, 3356, 3843, 3843, 3827, 3839, 3830, 3834, 3838, 3348, 3847, 3824, 3827, 3834, 3842, 3830, 3845, 3841, 3815, 3848, 3817, 3833, 3823, 3820, 3844, 3840, 3833, 3353, 3833, 3833, 3815, 3842, 3843, 3826, 3838, 3840, 3093, 3834, 3805, 3829, 3813, 3839, 3843, 3834, 3829, 3357, 3836, 3826, 3837, 3841, 3844, 3838, 3820, 3847, 3833, 3836, 3844, 3803, 3837, 3815, 3836, 3831, 3836, 3835, 3809, 3832, 3357, 3813, 3831, 3840, 3816, 3840, 3833, 3826, 3813, 3833, 3353, 3843, 3844, 3813, 3832, 3847, 3815, 3844, 3822, 3826, 3836, 3812, 3824, 3844, 3846, 3847, 3840, 3832, 3830, 3834, 3835, 3844, 3842, 3839, 3844, 3847, 3841, 3829, 3839, 3842, 3844, 3834, 3361, 3828, 3834, 3846, 3832, 3831, 3822, 3839, 3355, 3832, 3839, 3847, 3825, 3808, 3834, 3841, 3826, 3813, 3830, 3828, 3822, 3844, 3845, 3824, 3838, 3842, 3829, 3826, 3834, 3832, 3832, 3353, 3821, 3837, 3354, 3837, 3846, 3844, 3821, 3842, 3839, 3839, 3844, 3844, 3844, 3825, 3841, 3842, 3836, 3828, 3830, 3825, 3845, 3835, 3825, 3846, 3843, 3834, 3842, 3817, 3839, 3844, 3835, 3843, 3839, 3361, 3835, 3810, 3826, 3828, 3842, 3810, 3840, 3839, 3834, 3824, 3843, 3838, 3838, 3819, 3843, 3819, 3841, 3841, 3825, 3811, 3828, 3842, 3842, 3846, 3842, 3834, 3838, 3850, 3837, 3362, 3816, 3840, 3841, 3817, 3355, 3840, 3843, 3352, 3839, 3814, 3820, 3849, 3844, 3843, 3844, 3830, 3847, 3847, 3844, 3835, 3853, 3841, 3819, 3845, 3835, 3825, 3844, 3829, 3183, 3843, 3835, 3835, 3823, 3840, 3844, 3833, 3837, 3806, 3840, 3818, 3834, 3352, 3824, 3840, 3808, 3851, 3829, 3843, 3849, 3827, 3838, 3823, 3841, 3835, 3842, 3832, 3807, 3844, 3842, 3842, 3830, 3819, 3827, 3814, 3366, 3823, 3843, 3829, 3840, 3829, 3841, 3357, 3813, 3827, 3833, 3840, 3840, 3361, 3842, 3841, 3826, 3833, 3843, 3844, 3831, 3839, 3844, 3844, 3840, 3818, 3350, 3845, 3839, 3827, 3835, 3825, 3815, 3840, 3833, 3812, 3844, 3843, 3831, 3843, 3840, 3812, 3823, 3843, 3834, 3846, 3841, 3362, 3815, 3830, 3824, 3834, 3823, 3836, 3839, 3845, 3824, 3825, 3844, 3838, 3837, 3834, 3820, 3703, 3829, 3363, 3842, 3843, 3839, 3818, 3831, 3349, 3803, 3840, 3843, 3356, 3832, 3825, 3831, 3822, 3832, 3831, 3845, 3840, 3846, 3814, 3848, 3810, 3843, 3839, 3843, 3829, 3842, 3839, 3845, 3840, 3844, 3840, 3835, 3805, 3837, 3809, 3833, 3845, 3351, 3841, 3352, 3842, 3804, 3841, 3824, 3846, 3840, 3816, 3845, 3351, 3834, 3813, 3825, 3827, 3833, 3836, 3837, 3361, 3816, 3839, 3354, 3822, 3842, 3842, 3831, 3807, 3827, 3359, 3847, 3837, 3825, 3360, 3815, 3361, 3826, 3841, 3842, 3844, 3843, 3821, 3812, 3359, 3841, 3817, 3824, 3813, 3833, 3833, 3821, 3832, 3832, 3843, 3808, 3830, 3844, 3836, 3820, 3837, 3835, 3824, 3822, 3840, 3844, 3847, 3817, 3813, 3809, 3356, 3838, 3827, 3840, 3832, 3357, 3813, 3839, 3829, 3826, 3837, 3844, 3826, 3822, 3839, 3803, 3831, 3841, 3350, 3822, 3839, 3838, 3812, 3836, 3830, 3842, 3829, 3827, 3837, 3821, 3825, 3820, 3832, 3822, 3835, 3839, 3839, 3850, 3839, 3838, 3825, 3835, 3359, 3817, 3827, 3840, 3838, 3847, 3837, 3843, 3828, 3833, 3831, 3835, 3837, 3832, 3352, 3846, 3807, 3847, 3842, 3842, 3818, 3836, 3830, 3845, 3811, 3837, 3813, 3847, 3842, 3840, 3835, 3841, 3844, 3349, 3835, 3842, 3841, 3843, 3845, 3826, 3838, 3820, 3822, 3835, 3839, 3836, 3837, 3828, 3830, 3835, 3356, 3832, 3821, 3840, 3830, 3832, 3840, 3839, 3356, 3838, 3842, 3826, 3825, 3849, 3351, 3834, 3815, 3846, 3831, 3362, 3353, 3832, 3844, 3350, 3837, 3843, 3353, 3833, 3814, 3840, 3843, 3833, 3355, 3826, 3833, 3838, 3830, 3842, 3833, 3832, 3842, 3842, 3832, 3354, 3842, 3842, 3817, 3362, 3832, 3828, 3819, 3835, 3836, 3820, 3819, 3818, 3848, 3824, 3819, 3841, 3833, 3829, 3812, 3824, 3846, 3833, 3849, 3843, 3842, 3829, 3843, 3837, 3820, 3838, 3837, 3827, 3843, 3832, 3827, 3830, 3837, 3825, 3837, 3836, 3843, 3843, 3832, 3839, 3809, 3855, 3841, 3820, 3842, 3836, 3843, 3844, 3823, 3843, 3836, 3802, 3826, 3836, 3841, 3831, 3828, 3815, 3839, 3839, 3359, 3846, 3828, 3844, 3832, 3813, 3840, 3842, 3822, 3843, 3818, 3818, 3353, 3843, 3835, 3820, 3817, 3842, 3819, 3848, 3841, 3844, 3842, 3831, 3838, 3812, 3824, 3830, 3830, 3827, 3837, 3804, 3362, 3837, 3814, 3844, 3832, 3822, 3344, 3823, 3826, 3809, 3847, 3350, 3831, 3837, 3841, 3837, 3819, 3838, 3842, 3842, 3833, 3841, 3827, 3839, 3846, 3838, 3837, 3838, 3349, 3832, 3833, 3831, 3833, 3845, 3813, 3854, 3806, 3843, 3829, 3838, 3838, 3833, 3811, 3845, 3841, 3848, 3845, 3851, 3837, 3831, 3838, 3844, 3839, 3841, 3834, 3836, 3829, 3836, 3835, 3811, 3812, 3844, 3833, 3838, 3840, 3843, 3830, 3362, 3833, 3832, 3347, 3355, 3828, 3813, 3828, 3840, 3841, 3847, 3819, 3835, 3838, 3836, 3833, 3813, 3811, 3353, 3364, 3829, 3828, 3823, 3843, 3845, 3818, 3835, 3842, 3832, 3839, 3834, 3843, 3840, 3845, 3807, 3843, 3821, 3835, 3831, 3352, 3826, 3835, 3821, 3812, 3843, 3831, 3843, 3812, 3834, 3836, 3350, 3828, 3838, 3848, 3840, 3357, 3841, 3832, 3826, 3835, 3815, 3824, 3824, 3351, 3843, 3825, 3362, 3823, 3788, 3844, 3834, 3851, 3834, 3841, 3837, 3836, 3842, 3842, 3820, 3844, 3846, 3843, 3748, 3844, 3840, 3843, 3827, 3831, 3843, 3831, 3824, 3812, 3843, 3844, 3840, 3837, 3362, 3830, 3840, 3826, 3834, 3842, 3836, 3838, 3839, 3839, 3842, 3429, 3822, 3842, 3837, 3835, 3825, 3840, 3825, 3843, 3839, 3839, 3840, 3835, 3834, 3821, 3824, 3846, 3843, 3841, 3839, 3823, 3847, 3838, 3833, 3834, 3835, 3352, 3845, 3803, 3839, 3766, 3827, 3835, 3840, 3840, 3833, 3842, 3815, 3821, 3834, 3846, 3844, 3819, 3841, 3809, 3844, 2918, 3842, 3853, 3818, 3807, 3837, 3843, 3833, 3840, 3813, 3824, 3819, 3844, 3361, 3841, 3832, 3840, 3836, 3829, 3844, 3837, 3832, 3851, 3841, 3811, 3837, 3832, 3843, 3816, 3830, 3848, 3833, 3842, 3837, 3835, 3833, 3811, 3838, 3834, 3813, 3836, 3830, 3842, 3845, 3834, 3844, 3842, 3831, 3840, 3824, 3811, 3825, 3837, 3842, 3812, 3816, 3848, 3826, 3828, 3846, 3842, 3843, 3827, 3824, 3834, 3831, 3838, 3362, 3829, 3836, 3836, 3839, 3830, 3812, 3841, 3818, 3836, 3840, 3827, 3813, 3842, 3806, 3844, 3349, 3836, 3842, 3355, 3814, 3839, 3832, 3842, 3837, 3844, 3837, 3851, 3807, 3833, 3844, 3843, 3832, 3830, 3360, 3829, 3831, 3846, 3835, 3833, 3814, 3833, 3812, 3828, 3833, 3837, 3830, 3838, 3839, 3836, 3832, 3840, 3832, 3834, 3849, 3825, 3832, 3841, 3820, 3825, 3835, 3830, 3842, 3828, 3814, 3825, 3827, 3829, 3831, 3828, 3836, 3840, 3830, 3820, 3351, 3848, 3359, 3818, 3831, 3830, 3834, 3839, 3825, 3845, 3827, 3848, 3810, 3841, 3826, 3846, 3837, 3833, 3841, 3838, 3837, 3846, 3841, 3821, 3828, 3824, 3351, 3843, 3362, 3842, 3837, 3844, 3816, 3823, 3836, 3838, 3829, 3843, 3812, 3836, 3844, 3834, 3834, 3842, 3835, 3844, 3813, 3839, 3838, 3841, 3843, 3840, 3843, 3836, 3825, 3847, 3315, 3851, 3843, 3824, 3841, 3766, 3828, 3839, 3840, 3825, 3838, 3819, 3832, 3837, 3842, 3847, 3551, 3844, 3824, 3810, 3839, 3838, 3816, 3825, 3821, 3821, 3845, 3845, 3362, 3836, 3835, 3839, 3812, 3831, 3839, 3843, 3836, 3823, 3348, 3832, 3828, 3840, 3842, 3362, 3844, 3841, 3838, 3816, 3816, 3841, 3834, 3806, 3835, 3842, 3829, 3840, 3836, 3807, 3358, 3848, 3832, 3841, 3844, 3822, 3828, 3852, 3831, 3842, 3841, 3840, 3814, 3806, 3832, 3844, 3834, 3827, 3843, 3831, 3362, 3821, 3842, 3838, 3802, 3826, 3838, 3830, 3829, 3364, 3829, 3834, 3839, 3852, 3831, 3833, 3351, 3821, 3821, 3834, 3809, 3830, 3847, 3822, 3831, 3833, 3826, 3832, 3847, 3835, 3842, 3843, 3841, 3852, 3830, 3841, 3820, 3840, 3846, 3842, 3844, 3844, 3823, 3834, 3843, 3821, 3819, 3814, 3831, 3356, 3837, 3842, 3827, 3828, 3840, 3842, 3827, 3841, 3821, 3825, 3837, 3831, 3822, 3842, 3843, 3843, 3352, 3805, 3824, 3843, 3841, 3836, 3837, 3820, 3803, 3830, 3831, 3356, 3836, 3821, 3845, 3842, 3841, 3834, 3820, 3824, 3836, 3821, 3844, 3835, 3834, 3841, 3821, 3802, 3835, 3838, 3844, 3820, 3839, 3842, 3841, 3850, 3832, 3830, 3817, 3832, 3844, 3840, 3849, 3845, 3826, 3352, 3811, 3840, 3849, 3351, 3826, 3822, 3845, 3843, 3828, 3846, 3833, 3836, 3836, 3834, 3830, 3832, 3825, 3808, 3832, 3831, 3838, 3821, 3835, 3832, 3805, 3825, 3836, 3830, 3837, 3833, 3844, 3843, 3846, 3834, 3832, 3840, 3842, 3842, 3357, 3837, 3839, 3833, 3362, 3838, 3842, 3834, 3844, 3832, 3844, 3844, 3838, 3836, 3842, 3843, 3832, 3832, 3827, 3814, 3848, 3358, 3842, 3827, 3820, 3359, 3814, 3825, 3348, 3828, 3838, 3837, 3362, 3844, 3833, 3823, 3839, 3814, 3837, 3822, 3357, 3362, 3844, 3825, 3845, 3832, 3814, 3350, 3846, 3844, 3837, 3820, 3822, 3824, 3844, 3842, 3837, 3845, 3833, 3832, 3838, 3832, 3840, 3841, 3841, 3847, 3844, 3843, 3355, 3833, 3843, 3832, 3842, 3836, 3840, 3836, 3839, 3819, 3841, 3829, 3841, 3830, 3820, 3818, 3843, 3848, 3840, 3816, 3844, 3812, 3357, 3805, 3818, 3847, 3830, 3812, 3848, 3355, 3820, 3837, 3826, 3833, 3843, 3847, 3841, 3816, 3834, 3807, 3856, 3804, 3837, 3843, 3832, 3824, 3831, 3843, 3826, 3362, 3838, 3827, 3841, 3840, 3826, 3822, 3839, 3843, 3843, 3828, 3824, 3813, 3839, 3362, 3831, 3835, 3807, 3842, 3824, 3806, 3835, 3846, 3826, 3846, 3353, 3834, 3844, 3844, 3840, 3812, 3835, 3836, 3839, 3837, 3817, 3847, 3833, 3844, 3838, 3834, 3827, 3826, 3841, 3846, 3836, 3825, 3357, 3839, 3816, 3841, 3839, 3814, 3829, 3835, 3826, 3830, 3843, 3804, 3831, 3354, 3817, 3838, 3837, 3830, 3844, 3820, 3834, 3842, 3816, 3832, 3357, 3846, 3831, 3823, 3823, 3842, 3822, 3806, 3843, 3834, 3356, 3829, 3818, 3835, 3823, 3840, 3837, 3834, 3841, 3815, 3825, 3834, 3832, 3845, 3817, 3821, 3817, 3838, 3832, 3837, 3832, 3839, 3821, 3836, 3824, 3838, 3839, 3841, 3814, 3841, 3844, 3831, 3820, 3817, 3839, 3843, 3839, 3842, 3364, 3843, 3839, 3809, 3837, 3841, 3836, 3842, 3819, 3831, 3832, 3844, 3836, 3353, 3826, 3389, 3838, 3829, 3843, 3843, 3820, 3843, 3817, 3826, 3796, 3360, 3827, 3812, 3829, 3839, 3810, 3840, 3837, 3810, 3834, 3832, 3846, 3835, 3837, 3839, 3842, 3830, 3362, 3830, 3840, 3815, 3810, 3812, 3837, 3835, 3811, 3847, 3841, 3846, 3835, 3827, 3820, 3845, 3824, 3834, 3349, 3841, 3835, 3843, 3837, 3817, 3846, 3815, 3841, 3351, 3845, 3844, 3841, 3839, 3838, 3830, 3839, 3844, 3830, 3822, 3839, 3815, 3844, 3838, 3830, 3840, 3848, 3357, 3831, 3843, 3840, 3843, 3842, 3833, 3844, 3838, 3842, 3839, 3816, 3831, 3838, 3810, 3822, 3814, 3812, 3825, 3848, 3356, 3840, 3842, 3841, 3848, 3815, 3835, 3846, 3824, 3838, 3847, 3840, 3842, 3829, 3827, 3842, 3354, 3830, 3817, 3459, 3820, 3844, 3839, 3841, 3848, 3845, 3832, 3819, 3826, 3846, 3839, 3833, 3829, 3842, 3833, 3835, 3834, 3836, 3835, 3824, 3848, 3840, 3812, 3811, 3843, 3812, 3826, 3804, 3834, 3829, 3830, 3843, 3831, 3398, 3843, 3819, 3827, 3845, 3827, 3840, 3818, 3362, 3817, 3672, 3842, 3841, 3840, 3842, 3835, 3829, 3844, 3836, 3841, 3835, 3839, 3805, 3846, 3839, 3359, 3834, 3834, 3833, 3845, 3837, 3844, 3840, 3842, 3840, 3843, 3838, 3359, 3827, 3843, 3804, 3834, 3836, 3356, 3808, 3839, 3842, 3800, 3839, 3844, 3349, 3831, 3844, 3813, 3842, 3819, 3837, 3354, 3847, 3838, 3816, 3841, 3842, 3354, 3362, 3817, 3830, 3839, 3844, 3834, 3825, 3814, 3803, 3838, 3841, 3828, 3824, 3825, 3846, 3826, 3820, 3830, 3821, 3816, 3836, 3843, 3800, 2918, 3834, 3807, 3835, 3843, 3838, 3844, 3843, 3840, 3844, 3841, 3841, 3828, 3840, 3846, 3837, 3842, 3806, 3842, 3823, 3844, 3839, 3812, 3842, 3830, 3808, 3828, 3844, 3836, 3838, 3840, 3841, 3838, 3833, 3829, 3821, 3849, 3836, 3838, 3835, 3848, 3836, 3840, 3837, 3835, 3831, 3348, 3847, 3817, 3830, 3844, 3843, 3844, 3839, 3841, 3842, 3818, 3801, 3829, 3821, 3835, 3838, 3839, 3838, 3827, 3831, 3809, 3841, 3833, 3850, 3830, 3845, 3845, 3824, 3832, 3324, 3842, 3840, 3827, 3841, 3835, 3839, 3833, 3835, 3840, 3804, 3352, 3821, 3807, 3828, 3838, 3847, 3825, 3837, 3355, 3356, 3817, 3841, 3354, 3842, 3844, 3824, 3840, 3836, 3847, 3834, 3828, 3838, 3817, 3845, 3833, 3835, 3843, 3843, 3842, 3823, 3818, 3837, 3843, 3840, 3823, 3359, 3842, 3364, 3844, 3843, 3833, 3827, 3843, 3823, 3797, 3842, 3803, 3819, 3353, 3844, 3840, 3831, 3843, 3844, 3839, 3831, 3840, 3348, 3840, 3826, 3810, 3837, 3821, 3820, 3836, 3818, 3837, 3839, 3837, 3840, 3831, 3828, 3807, 3811, 3850, 3844, 3836, 3833, 3834, 3841, 3848, 3362, 3834, 3829, 3835, 3841, 3840, 3838, 3849, 3349, 3827, 3809, 3838, 3846, 3814, 3826, 3821, 3831, 3833, 3847, 3810, 3842, 3830, 3357, 3829, 3814, 3829, 3835, 3819, 3839, 3355, 3831, 3844, 3834, 3825, 3841, 3821, 3838, 3838, 3845, 3845, 3830, 3833, 3839, 3848, 3837, 3846, 3362, 3844, 3836, 3348, 3827, 3838, 3813, 3806, 3825, 3815, 3362, 3815, 3838, 3822, 3816, 3833, 3832, 3852, 3827, 3841, 3836, 3844, 3835, 3825, 3837, 3851, 3842, 3815, 3828, 3833, 3843, 3841, 3834, 3833, 3828, 3828, 3839, 3848, 3845, 3810, 3848, 3835, 3827, 3359, 3828, 3822, 3841, 3809, 3821, 3837, 3833, 3805, 3811, 3826, 3843, 3834, 3830, 3835, 3815, 3835, 3839, 3837, 3835, 3842, 3834, 3803, 3840, 3825, 3838, 3832, 3833, 3846, 3854, 3847, 3830, 3842, 3850, 3840, 3840, 3821, 3809, 3840, 3825, 3845, 3827, 3351, 3840, 3835, 3843, 3832, 3821, 3833, 3833, 3844, 3852, 3823, 3849, 3843, 3842, 3843, 3837, 3817, 3841, 3839, 3841, 3846, 3809, 3825, 3844, 3824, 3844, 3838, 3846, 3828, 3350, 3843, 3839, 3842, 3823, 3841, 3820, 3745, 3832, 3351, 3845, 3838, 3817, 3353, 3816, 3836, 3846, 3843, 3842, 3816, 3353, 3843, 3815, 3832, 3836, 3853, 3846, 3843, 3816, 3841, 3837, 3808, 3832, 3833, 3839, 3844, 3841, 3810, 3819, 3821, 3829, 3845, 3812, 3834, 3847, 3851, 3837, 3354, 3840, 3830, 3821, 3834, 3834, 3350, 3833, 3839, 3821, 3837, 3810, 3840, 3814, 3839, 3841, 3828, 3362, 3842, 3845, 3821, 3843, 3497, 3815, 3839, 3845, 3836, 3828, 3841, 3833, 3848, 3840, 3815, 3826, 3842, 3844, 3841, 3843, 3825, 3842, 3854, 3841, 3835, 3834, 3824, 3819, 3829, 3821, 3847, 3835, 3831, 3845, 3835, 3836, 3842, 3824, 3835, 3831, 3840, 3845, 3850, 3833, 3843, 3837, 3842, 3840, 3819, 3829, 3825, 3799, 3833, 3836, 3351, 3842, 3845, 3828, 3362, 3840, 3835, 3821, 3836, 3820, 3837, 3842, 3829, 3827, 3836, 3820, 3362, 3843, 3804, 3836, 3839, 3815, 3833, 3817, 3843, 3348, 3843, 3823, 3809, 3842, 3837, 3842, 3826, 3846, 3835, 3832, 3816, 3829, 3842, 3830, 3842, 3815, 3813, 3841, 3839, 3827, 3818, 3362, 3356, 3845, 3354, 3342, 3846, 3837, 3767, 3826, 3840, 3842, 3823, 3840, 3815, 3841, 3842, 3824, 3802, 3845, 3829, 3853, 3831, 3803, 3832, 3834, 3828, 3813, 3843, 3841, 3356, 3813, 3351, 3845, 3841, 3831, 3833, 3825, 3835, 3834, 3816, 3832, 3835, 3828, 3842, 3828, 3352, 3837, 3828, 3357, 3805, 3835, 3813, 3807, 3357, 3836, 3833, 3814, 3833, 3824, 3819, 3841, 3810, 3839, 3831, 3819, 3842, 3840, 3834, 3836, 3829, 3829, 3826, 3821, 3823, 3817, 3807, 3836, 3840, 3838, 3843, 3836, 3835, 3825, 3817, 3830, 3837, 3820, 3812, 3838, 3843, 3843, 3835, 3848, 3843, 3836, 3843, 3825, 3843, 3804, 3818, 3361, 3815, 3842, 3828, 3833, 3841, 3834, 3815, 3846, 3823, 3827, 3842, 3811, 3844, 3358, 3351, 3836, 3837, 3848, 3831, 3830, 3362, 3829, 3825, 3823, 3847, 3843, 3841, 3831, 3838, 3843, 3822, 3822, 3842, 3838, 3849, 3834, 3840, 3817, 3814, 3849, 3825, 3842, 3357, 3838, 3825, 3831, 3822, 3840, 3823, 3362, 3841, 3837, 3843, 3825, 3823, 3835, 3844, 3799, 3356, 3843, 3827, 3846, 3844, 3349, 3500, 3842, 3842, 3812, 3847, 3845, 3352, 3843, 3838, 3843, 3828, 3843, 3353, 3834, 3825, 3836, 3842, 3847, 3832, 3817, 3845, 3811, 3837, 3820, 3831, 3833, 3829, 3841, 3836, 3834, 3817, 3842, 3806, 3802, 3845, 3802, 3847, 3842, 3835, 3839, 3853, 3841, 3833, 3836, 3822, 3834, 3818, 3842, 3838, 3843, 3835, 3807, 3840, 3816, 3837, 3843, 3839, 3851, 3847, 3842, 3833, 3843, 3831, 3842, 3370, 3821, 3842, 3851, 3807, 3818, 3838, 3849, 3809, 3845, 3362, 3844, 3840, 3841, 3358, 3844, 3841, 3837, 3843, 3843, 3351, 3836, 3817, 3845, 3822, 3837, 3834, 3834, 3350, 3353, 3838, 3834, 3845, 3842, 3836, 3843, 3840, 3825, 3840, 3811, 3831, 3842, 3834, 3857, 3819, 3829, 3846, 3817, 3836, 3843, 3845, 3845, 3834, 3830, 3844, 3841, 3838, 3840, 3816, 3843, 3843, 3839, 3829, 3845, 3828, 3838, 3835, 3825, 3837, 3845, 3827, 3825, 3846, 3841, 3811, 3827, 3829, 3844, 3822, 3833, 3839, 3816, 3842, 3836, 3824, 3354, 3846, 3798, 3834, 3810, 3811, 3830, 3833, 3845, 3821, 3825, 3840, 3816, 3832, 3840, 3836, 3829, 3845, 3840, 3813, 3347, 3839, 3808, 3364, 3839, 3816, 3362, 3808, 3814, 3826, 3838, 3822, 3588, 3842, 3850, 3829, 3841, 3839, 3830, 3841, 3840, 3844, 3821, 3833, 3836, 3353, 3839, 3836, 3836, 3820, 3822, 3836, 3813, 3839, 3843, 3842, 3846, 3362, 3746, 3821, 3811, 3830, 3841, 3815, 3352, 3825, 3816, 3832, 3841, 3828, 3839, 3833, 3845, 3823, 3821, 3836, 3814, 3822, 3839, 3362, 3831, 3843, 3840, 3817, 3844, 3812, 3823, 3834, 3833, 3832, 3828, 3843, 3838, 3831, 3814, 3842, 3813, 3838, 3824, 3834, 3831, 3844, 3845, 3838, 3837, 3823, 3842, 3835, 3822, 3825, 3840, 3836, 3850, 3829, 3842, 3814, 3823, 3829, 3833, 3845, 3820, 3824, 3776, 3836, 3846, 3832, 3830, 3826, 3824, 3836, 3840, 3818, 3828, 3825, 3840, 3839, 3840, 3353, 3830, 3846, 3829, 3360, 3850, 3840, 3842, 3814, 3820, 3832, 3835, 3835, 3842, 3826, 3437, 3827, 3833, 3820, 3817, 3835, 3845, 3820, 3848, 3843, 3849, 3842, 3840, 3804, 3847, 3844, 3624, 3842, 3826, 3827, 3841, 3844, 3804, 3811, 3837, 3844, 3839, 3820, 3826, 3821, 3807, 3835, 3838, 3834, 3835, 3825, 3804, 3847, 3818, 3844, 3831, 3828, 3826, 3830, 3836, 3837, 3820, 3841, 3835, 3839, 3839, 3820, 3831, 3841, 3819, 3851, 3841, 3830, 3836, 3832, 3805, 3814, 3838, 3826, 3840, 3820, 3840, 3842, 3835, 3842, 3840, 3829, 3832, 3837, 3843, 3843, 3828, 3840, 3362, 3834, 3833, 3829, 3844, 3818, 3351, 3835, 3812, 3837, 3842, 3847, 3843, 3845, 3822, 3348, 3838, 3832, 3836, 3833, 3833, 3846, 3836, 3835, 3842, 3837, 3844, 3831, 3822, 3835, 3811, 3835, 3824, 3351, 3819, 3835, 3836, 3818, 3829, 3816, 3840, 3840, 3845, 3844, 3837, 3835, 3833, 3827, 3842, 3818, 3832, 3808, 3835, 3834, 3840, 3818, 3837, 3846, 3820, 3842, 3840, 3840, 3843, 3839, 3816, 3839, 3828, 3835, 3617, 3812, 3832, 3840, 3362, 3838, 3350, 3842, 3821, 3842, 3836, 3839, 3837, 3840, 3841, 3842, 3802, 3838, 3842, 3844, 3835, 3831, 3817, 3839, 3836, 3840, 3822, 3818, 3828, 3837, 3844, 3842, 3811, 3833, 3807, 3801, 2916, 3846, 3807, 3828, 3842, 3836, 3357, 3841, 3362, 2917, 3848, 3818, 3834, 3845, 3839, 3838, 3845, 3371, 3828, 3843, 3824, 3840, 3812, 3847, 3814, 3833, 3814, 3831, 3825, 3843, 3821, 3811, 3832, 3830, 3843, 3817, 3844, 3825, 3826, 3843, 3841, 3326, 3847, 3834, 3835, 3816, 3837, 3829, 3839, 3831, 3838, 3841, 3836, 3844, 3838, 3841, 3615, 3840, 3843, 3830, 3805, 3779, 3842, 3816, 3837, 3820, 3839, 3832, 3827, 3818, 3832, 3845, 3816, 3834, 3844, 3839, 3838, 3835, 3842, 3846, 3833, 3833, 3826, 3817, 3843, 3813, 3841, 3831, 3831, 3844, 3833, 3819, 3818, 3842, 3819, 3839, 3834, 3816, 3844, 3843, 3835, 3851, 3841, 3831, 3838, 3833, 3831, 3840, 3834, 3843, 3840, 3830, 3801, 3840, 3844, 3834, 3832, 3810, 3841, 3836, 3830, 3847, 3843, 3824, 3843, 3819, 3841, 3846, 3846, 3841, 3831, 3845, 3840, 3838, 3838, 3844, 3360, 3845, 3829, 3846, 3834, 3831, 3821, 3814, 3843, 3843, 3838, 3817, 3814, 3828, 3835, 3362, 3835, 3091, 3844, 3832, 3840, 3828, 3845, 3838, 3819, 3836, 3846, 3815, 3362, 3838, 3815, 3829, 3362, 3827, 3351, 3840, 3830, 3845, 3835, 3844, 3828, 3813, 3800, 3847, 3833, 3830, 3833, 3841, 3833, 3841, 3848, 3362, 3840, 3823, 3827, 3843, 3838, 3834, 3814, 3842, 3822, 3825, 3827, 3350, 3842, 3814, 3841, 3840, 3827, 3823, 3838, 3826, 3833, 3836, 3357, 3347, 3852, 3838, 3832, 3834, 3845, 3841, 3823, 3844, 3830, 3829, 3842, 3352, 3836, 3812, 3837, 3805, 3828, 3810, 3824, 3844, 3846, 3362, 3826, 3818, 3822, 3832, 3845, 3811, 3362, 3358, 3842, 3831, 3834, 3848, 3843, 3841, 3828, 3828, 3829, 3834, 3839, 3829, 3810, 3839, 3833, 3359, 3835, 3842, 3356, 3828, 3830, 3824, 3812, 3837, 3821, 3811, 3839, 3355, 3836, 3822, 3804, 3820, 3821, 3848, 3838, 3843, 3837, 3844, 3826, 3825, 3821, 3831, 3830, 3362, 3840, 3831, 3843, 3825, 3842, 3837, 3830, 3813, 3842, 3826, 3843, 3828, 3843, 3841, 3825, 3805, 3842, 3846, 3843, 3824, 3838, 3823, 3362, 3831, 3837, 3842, 3814, 3836, 3835, 3843, 3827, 3834, 3837, 3357, 3820, 3839, 3847, 3839, 3830, 3843, 3828, 3841, 3818, 3840, 3842, 3841, 3834, 3787, 3841, 3828, 3843, 3843, 3832, 3831, 3838, 3844, 3839, 3821, 3842, 3808, 3844, 3837, 3837, 3833, 3843, 3837, 3825, 3834, 3823, 3841, 3838, 3842, 3845, 3843, 3820, 3811, 3822, 3832, 3843, 3842, 3830, 3843, 3848, 3833, 3841, 3844, 3835, 3357, 3840, 3844, 3840, 3826, 3834, 3813, 3832, 3838, 3844, 3831, 3364, 3835, 3836, 3835, 3358, 3841, 3842, 3835, 3352, 3845, 3359, 3820, 3846, 3837, 3817, 3358, 3840, 3842, 3830, 3840, 3845, 3850, 3842, 3818, 3832, 3814, 3843, 3832, 3816, 3361, 3843, 3814, 3845, 3809, 3816, 3845, 3830, 3835, 3852, 3842, 3845, 3831, 3830, 3362, 3842, 3846, 3836, 3831, 3843, 3839, 3830, 3359, 3838, 3820, 3831, 3846, 3831, 3830, 3838, 3842, 3765, 3825, 3804, 3839, 3833, 3843, 3825, 3837, 3837, 3837, 3835, 3844, 3822, 3827, 3844, 3808, 3828, 3368, 3355, 3819, 3348, 3848, 3832, 3828, 3815, 3800, 3832, 3828, 3843, 3813, 3838, 3844, 3840, 3821, 3844, 3832, 3841, 3803, 3803, 3846, 3819, 3828, 3838, 3838, 3831, 3803, 3359, 3845, 3830, 3823, 3830, 3843, 3845, 3846, 3842, 3815, 3842, 3842, 3843, 3833, 3814, 3831, 3846, 3845, 3845, 3830, 3809, 3808, 3846, 3831, 3839, 3842, 3841, 3843, 3843, 3800, 3848, 3816, 3828, 3840, 3844, 3836, 3830, 3836, 3851, 3840, 3824, 3831, 3831, 3841, 3841, 3843, 3826, 3843, 3814, 3843, 3833, 3840, 3844, 3818, 3830, 3845, 3838, 3840, 3810, 3843, 3826, 3843, 3818, 3841, 3841, 3836, 3812, 3353, 3836, 3817, 3837, 3833, 3831, 3850, 3842, 3823, 3834, 3839, 3839, 3822, 3832, 3843, 3843, 3845, 3844, 3837, 3824, 3841, 3835, 3838, 3834, 3811, 3844, 3830, 3817, 3843, 3842, 3831, 3816, 3846, 3811, 3836, 3840, 3836, 3842, 3841, 3833, 3843, 3839, 3812, 3840, 3818, 3840, 3835, 3833, 3844, 3844, 3843, 3813, 3846, 3838, 3839, 3846, 3833, 3842, 3829, 3843, 3362, 3835, 3819, 3844, 3809, 3367, 3346, 3845, 3845, 3844, 3824, 3829, 3828, 3847, 3843, 3831, 3833, 3823, 3829, 3840, 3840, 3836, 3841, 3808, 3830, 3839, 3847, 3841, 3813, 3362, 3828, 3836, 3824, 3816, 3845, 3830, 3810, 3823, 3751, 3845, 3826, 3819, 3828, 3815, 3830, 3813, 3843, 3814, 3847, 3845, 3842, 3842, 3843, 3843, 3845, 3808, 3841, 3354, 3369, 3838, 3839, 3804, 3813, 3847, 3827, 3840, 3811, 3831, 3836, 3843, 3841, 3822, 3813, 3833, 3849, 3835, 3826, 3842, 3836, 3843, 3816, 3841, 3829, 3840, 3829, 3358, 3817, 3823, 3802, 3843, 3836, 3843, 3844, 3843, 3828, 3841, 3833, 3838, 3805, 3818, 3825, 3842, 3836, 3823, 3829, 3847, 3843, 3824, 3844, 3353, 3829, 3809, 3844, 3833, 3828, 3824, 3819, 3836, 3843, 3816, 3841, 3844, 3843, 3833, 3841, 3838, 3836, 3830, 3832, 3830, 3844, 3831, 3362, 3845, 3358, 3828, 3370, 3845, 3834, 3826, 3819, 3848, 3839, 3837, 3814, 3836, 3841, 3842, 3847, 3839, 3820, 3807, 3843, 3806, 3361, 3837, 3828, 3820, 3845, 3352, 3349, 3824, 3833, 3833, 3837, 3806, 3839, 3615, 3817, 3813, 3805, 3840, 3842, 3805, 3833, 3846, 3835, 3841, 3844, 3841, 3840, 3807, 3807, 3842, 3830, 3834, 3838, 3778, 3838, 3804, 3833, 3355, 3834, 3837, 3839, 3843, 3846, 3841, 3833, 3823, 3819, 3837, 3822, 3811, 3810, 3821, 3816, 3814, 3846, 3839, 3843, 3358, 3815, 3804, 3839, 3831, 3816, 3812, 3821, 3846, 3828, 3839, 3842, 3840, 3829, 3361, 3835, 3826, 3819, 3830, 3827, 3831, 3840, 3836, 3846, 3826, 3511, 3842, 3841, 3831, 3842, 3823, 3818, 3829, 3838, 3844, 3816, 3827, 3846, 3842, 3841, 3828, 3840, 3838, 3831, 3847, 3841, 3826, 3843, 3838, 3826, 3843, 3840, 3810, 3828, 3820, 3840, 3835, 3838, 3841, 3844, 3825, 3819, 3834, 3834, 3838, 3833, 3839, 3362, 3843, 3832, 3817, 3845, 3841, 3831, 3814, 3842, 3818, 3815, 3358, 3843, 3837, 3832, 3358, 3814, 3837, 3356, 3839, 3830, 3846, 3811, 3851, 3351, 3842, 3833, 3825, 3815, 3834, 3810, 3835, 3838, 3826, 3835, 3835, 3831, 3845, 3814, 3829, 3841, 3834, 3806, 3834, 3360, 3806, 3848, 3817, 3827, 3803, 3831, 3834, 3845, 3847, 3822, 3845, 3843, 3836, 3835, 3818, 3840, 3833, 3817, 3849, 3841, 3847, 3828, 3803, 3813, 3841, 3826, 3357, 3824, 3836, 3843, 3841, 3845, 3837, 3814, 3822, 3851, 3821, 3832, 3355, 3829, 3823, 3842, 3837, 3844, 3823, 3842, 3821, 3819, 3598, 3838, 3818, 3825, 3839, 3830, 3812, 3826, 3831, 3844, 3841, 3822, 3835, 3836, 3827, 3830, 3822, 3359, 3847, 3827, 3831, 3834, 3842, 3818, 3347, 3846, 3835, 3844, 3827, 3830, 3829, 3845, 3807, 3835, 3842, 3833, 3844, 3841, 3838, 3833, 3840, 3842, 3844, 3822, 3810, 3818, 3807, 3839, 3822, 3846, 3843, 3833, 3838, 3836, 3844, 3822, 3822, 3842, 3845, 3840, 3830, 3836, 3817, 3839, 3839, 3837, 3843, 3834, 3849, 3834, 3853, 3838, 3803, 3843, 3841, 3842, 3839, 3831, 3820, 3829, 3841, 3842, 3846, 3836, 3843, 3840, 3836, 3839, 3357, 3807, 3833, 3846, 3845, 3836, 3820, 3817, 3841, 3840, 3843, 3844, 3825, 3830, 3831, 3836, 3841, 3840, 3841, 3837, 3818, 3814, 3842, 3835, 3845, 3827, 3348, 3843, 3803, 3842, 3839, 3807, 3839, 3810, 3855, 3843, 3821, 3849, 3835, 3819, 3832, 3822, 3838, 3836, 3836, 3842, 3814, 3830, 3823, 3838, 3832, 3826, 3351, 3824, 3849, 3843, 3842, 3842, 3827, 3832, 3836, 3833, 3830, 3841, 3841, 3833, 3822, 3821, 3845, 3832, 3838, 3840, 3354, 3845, 3823, 3842, 3844, 3839, 3838, 3841, 3815, 3815, 3846, 3837, 3823, 3802, 3842, 3847, 3836, 3845, 3843, 3819, 3841, 3821, 3840, 3830, 3819, 3845, 3838, 3819, 3826, 3818, 3840, 3840, 3833, 3826, 3830, 3830, 3845, 3847, 3824, 3838, 3822, 3841, 3838, 3842, 3836, 3838, 3835, 3837, 3819, 3847, 3827, 3834, 3814, 2919, 3840, 3840, 3840, 3846, 3834, 3827, 3838, 3820, 3843, 3823, 3842, 3832, 3843, 3795, 3846, 3841, 3832, 3835, 3823, 3825, 3838, 3840, 3353, 3819, 3843, 3824, 3823, 3837, 3840, 3831, 3358, 3838, 3837, 3816, 3814, 3830, 3816, 3828, 3836, 3845, 3840, 3838, 3843, 3845, 3831, 3843, 3810, 3848, 3830, 3825, 3819, 3825, 3840, 3804, 3841, 3834, 3828, 3841, 3844, 3826, 3831, 3840, 3838, 3842, 3842, 3818, 3844, 3831, 3807, 3840, 3834, 3835, 3825, 3839, 3826, 3823, 3803, 3826, 3822, 3824, 3838, 3841, 3824, 3846, 3837, 3842, 3837, 3349, 3819, 3846, 3833, 3822, 3829, 3841, 3840, 3349, 3834, 3812, 3840, 3841, 3842, 3842, 3846, 3835, 3810, 3847, 3831, 3837, 3841, 3813, 3816, 3834, 3351, 3843, 3832, 3844, 3849, 3841, 3841, 3839, 3838, 3840, 3819, 3838, 3351, 3817, 3838, 3803, 3824, 3809, 3830, 3808, 3804, 3810, 3843, 3848, 3836, 3843, 3821, 3843, 3839, 3836, 3852, 3837, 3829, 3829, 3818, 3838, 3849, 3351, 3814, 3824, 3833, 3350, 3840, 3842, 3831, 3362, 3839, 3819, 3818, 3828, 3834, 3838, 3842, 3849, 3846, 3846, 3843, 3846, 3838, 3809, 3814, 3840, 3838, 3352, 3841, 3843, 3805, 3843, 3834, 3829, 3822, 3828, 3811, 3838, 3845, 3837, 3845, 3826, 3850, 3827, 3840, 3826, 3840, 3822, 3844, 3353, 3813, 3829, 3837, 3835, 3349, 3834, 3837, 3825, 3371, 3830, 3838, 3844, 3840, 3834, 3843, 3838, 3841, 3833, 3836, 3842, 3834, 3836, 3820, 3826, 3813, 3819, 3840, 3846, 3832, 3825, 3842, 3838, 3830, 3844, 3830, 3837, 3847, 3837, 3825, 3350, 3837, 3842, 3827, 3842, 3835, 3840, 3843, 3844, 3846, 3845, 3826, 3841, 3839, 3829, 3840, 3836, 3836, 3844, 3838, 3359, 3817, 3844, 3824, 3832, 3815, 3819, 3853, 3839, 3841, 3835, 3835, 3842, 3821, 3837, 3826, 3841, 3814, 3823, 3827, 3808, 3828, 3837, 3841, 3845, 3833, 3823, 3822, 3841, 3811, 3841, 3840, 3844, 3825, 3835, 3362, 3825, 3843, 3844, 3829, 3843, 3825, 3831, 3823, 3836, 3839, 3842, 3845, 3835, 3833, 3839, 3834, 3819, 3838, 3841, 3843, 3838, 3820, 3358, 3834, 3836, 3355, 3844, 3827, 3839, 3818, 3831, 3826, 3820, 3816, 3843, 3834, 3829, 3348, 3818, 3832, 3844, 3827, 3830, 3352, 3351, 3841, 3842, 3827, 3840, 3803, 3815, 3817, 3823, 3827, 3838, 3830, 3844, 3842, 3830, 3838, 3354, 3835, 3831, 3846, 3841, 3844, 3839, 3840, 3830, 3843, 3349, 3842, 3844, 3815, 3802, 3842, 3840, 3829, 3827, 3838, 3830, 3833, 3836, 3828, 3815, 3846, 3835, 3819, 3827, 3362, 3818, 3840, 3844, 3832, 3840, 3844, 3841, 3831, 3830, 3837, 3845, 3841, 3830, 3840, 3842, 3836, 3842, 3818, 3766, 3831, 3836, 3806, 3840, 3829, 3824, 3841, 3847, 3822, 3831, 3842, 3842, 3839, 3845, 3830, 3842, 3843, 3837, 3835, 3824, 3834, 3848, 3849, 3828, 3838, 3815, 3839, 3838, 3815, 3838, 3843, 3809, 3835, 3822, 3835, 3834, 3845, 3818, 3842, 3827, 3841, 3846, 3827, 3841, 3839, 3831, 3845, 3836, 3808, 3838, 3829, 3361, 3844, 3841, 3828, 3829, 3371, 3842, 3824, 3834, 3803, 3828, 3845, 3845, 3807, 3361, 3843, 3843, 3840, 3853, 3815, 3829, 3841, 3813, 3835, 3818, 3826, 3836, 3804, 3845, 3813, 3811, 3841, 3830, 3827, 3843, 3840, 3841, 3845, 3845, 3825, 3839, 3845, 3829, 3827, 3831, 3841, 3805, 3840, 3842, 3349, 3843, 3850, 3819, 3812, 3842, 3818, 3836, 3832, 3823, 3830, 3828, 3810, 3841, 3397, 3829, 3839, 3840, 3815, 3820, 3854, 3822, 3834, 3842, 3846, 3845, 3840, 3825, 3354, 3842, 3841, 3846, 3268, 3838, 3852, 3837, 3808, 3844, 3837, 3816, 3838, 3829, 3810, 3842, 3841, 3829, 3825, 3845, 3842, 3840, 3362, 3362, 3838, 3816, 3839, 3826, 3838, 3828, 3844, 3820, 3364, 3844, 3837, 3830, 3822, 3842, 3836, 3845, 3840, 3839, 3352, 3362, 3803, 3846, 3816, 3817, 3833, 3845, 3841, 3822, 3357, 3840, 3844, 3823, 3840, 3841, 3839, 3834, 3843, 3813, 3811, 3814, 3823, 3838, 3844, 3840, 3345, 3352, 3836, 3818, 3804, 3846, 3839, 3817, 3822, 3847, 3827, 3828, 3841, 3490\n  y sizes: 11100\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1655\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1651\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1652\u001b[0m       label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1653\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)))\n\u001b[0;32m   1654\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1655\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3831, 3830, 3823, 3829, 3835, 3844, 3826, 3182, 3815, 3833, 3840, 3825, 3816, 3827, 3822, 3818, 3836, 3845, 3840, 3818, 3832, 3362, 3358, 3844, 3821, 3812, 3824, 3806, 3850, 3837, 3828, 3842, 3834, 3840, 3836, 3831, 3844, 3815, 3843, 3840, 3839, 3843, 3840, 3842, 3854, 3843, 3813, 3845, 3838, 3843, 3833, 3360, 3827, 3838, 3843, 3834, 3838, 3818, 3826, 3819, 3835, 3832, 3852, 3838, 3849, 3840, 3839, 3843, 3833, 3843, 3831, 3839, 3836, 3826, 3836, 3836, 3844, 3836, 3816, 3816, 3821, 3840, 3837, 3845, 3845, 3828, 3848, 3839, 3834, 3843, 3839, 3831, 3833, 3836, 3834, 3825, 3829, 3840, 3844, 3837, 3362, 3822, 3840, 3826, 3830, 3830, 3811, 3802, 3846, 3811, 3827, 3852, 3353, 3840, 3825, 3847, 3838, 3836, 3824, 3840, 3829, 3850, 3826, 3839, 3821, 3846, 3836, 3840, 3350, 3835, 3843, 3837, 3840, 3823, 3828, 3843, 3821, 3844, 3841, 3826, 3828, 3838, 3840, 3360, 3845, 3838, 3824, 3817, 3840, 3362, 3820, 3832, 3842, 3805, 3835, 3841, 3825, 3810, 3827, 3836, 3841, 3815, 3814, 3826, 3838, 3844, 3836, 3825, 3846, 3809, 3809, 3839, 3815, 3835, 3840, 3833, 3839, 3842, 3842, 3843, 3843, 3831, 3362, 3835, 3800, 3836, 3362, 3822, 3840, 3348, 3836, 3825, 3840, 3808, 3822, 3843, 3827, 3841, 3835, 3836, 3808, 3843, 3848, 3834, 3840, 3824, 3802, 3839, 3840, 3355, 3832, 3838, 3832, 3840, 3836, 3834, 3838, 3845, 3828, 3844, 3827, 3818, 3360, 3849, 3832, 3838, 3362, 3837, 3825, 3840, 3815, 3825, 3844, 3840, 3827, 3843, 3840, 3834, 3822, 3842, 3844, 3842, 3838, 3837, 3841, 3825, 3846, 3832, 3831, 3834, 3851, 3816, 3834, 3836, 3838, 3836, 3837, 3839, 3359, 3834, 3836, 3819, 3835, 3842, 3833, 3846, 3359, 3828, 3828, 3846, 3850, 3848, 3844, 3839, 3850, 3838, 3839, 3782, 3842, 3816, 3832, 3841, 3828, 3829, 3815, 3843, 3833, 3816, 3831, 3842, 3839, 3837, 3362, 3843, 3838, 3844, 3841, 3826, 3838, 3829, 3833, 3842, 3836, 3828, 3833, 3834, 3844, 3846, 3810, 3820, 3848, 3839, 3844, 3833, 3844, 3845, 3835, 3838, 3828, 3833, 3846, 3360, 3844, 3838, 3809, 3823, 3816, 3825, 3828, 3349, 3357, 3841, 3057, 3825, 3830, 3840, 3817, 3356, 3846, 3817, 3820, 3849, 3831, 3837, 3844, 3842, 3839, 3842, 3840, 3846, 3846, 3843, 3834, 3835, 3360, 3844, 3814, 3839, 3837, 3832, 3360, 3833, 3836, 3817, 3830, 3823, 3837, 3828, 3833, 3840, 3838, 3840, 3359, 3362, 3847, 3830, 3353, 3829, 3833, 3843, 3823, 3829, 3350, 3841, 3845, 3838, 3839, 3831, 3820, 3819, 3827, 3360, 3844, 3836, 3831, 3839, 3815, 3808, 3845, 3854, 3821, 3825, 3814, 3836, 3363, 3845, 3812, 3826, 3359, 3812, 3842, 3830, 3352, 3838, 3353, 3843, 3813, 3821, 3356, 3833, 3833, 3836, 3835, 3820, 3817, 3836, 3838, 3351, 3843, 3843, 3836, 3842, 3810, 3847, 3839, 3815, 3840, 3361, 3012, 3828, 3834, 3841, 3353, 3807, 3841, 3823, 3815, 3842, 3834, 3843, 3836, 3836, 3832, 3823, 3846, 3839, 3831, 3836, 3840, 3837, 3840, 3817, 3750, 3829, 3841, 3815, 3828, 3843, 3354, 3843, 3830, 3834, 3825, 3814, 3823, 3842, 3841, 3825, 3842, 3835, 3826, 3356, 3842, 3843, 3838, 3840, 3844, 3836, 3812, 3834, 3832, 3829, 3817, 3820, 3840, 3840, 3850, 3812, 3347, 3843, 3829, 3843, 3794, 3354, 3838, 3843, 3841, 3852, 3847, 3838, 3837, 3836, 3821, 3836, 3833, 3828, 3847, 3845, 3848, 3826, 3828, 3812, 3811, 3825, 3847, 3807, 3811, 3829, 3829, 3841, 3836, 3815, 3354, 3846, 3822, 3837, 3837, 3844, 3836, 3831, 3844, 3826, 3837, 3839, 3842, 3835, 3822, 3834, 3825, 3850, 3837, 3835, 3843, 3830, 3842, 3364, 3821, 3839, 3844, 3820, 3840, 3809, 3845, 3842, 3846, 3827, 3828, 3835, 3807, 3828, 3827, 3844, 3823, 3811, 3834, 3827, 3836, 3844, 3838, 3846, 3817, 3837, 3823, 3847, 3804, 3834, 3838, 3836, 3805, 3844, 3833, 3352, 3830, 3843, 3838, 3841, 3842, 3830, 3828, 3845, 3832, 3806, 3843, 3835, 3841, 3835, 3834, 3836, 3842, 3830, 3827, 3835, 3810, 3815, 3827, 3813, 3829, 3836, 3812, 3819, 3848, 3827, 3824, 3809, 3850, 3836, 3825, 3844, 3847, 3838, 3843, 3825, 3840, 3834, 3832, 3831, 3817, 3844, 3355, 3362, 3356, 3828, 3832, 3831, 3830, 3843, 3843, 3849, 3840, 3848, 3841, 3802, 3823, 3830, 3836, 3809, 3817, 3835, 3823, 3833, 3357, 3847, 3821, 3832, 3836, 3842, 3830, 3845, 3808, 3834, 3848, 3836, 3846, 3842, 3827, 3828, 3840, 3836, 3839, 3827, 3840, 3844, 3843, 3815, 3842, 3836, 3827, 3821, 3827, 3838, 3838, 3846, 3841, 3840, 3846, 3351, 3844, 3853, 3827, 3834, 3837, 3832, 3821, 3838, 3352, 3843, 3846, 3836, 3841, 3838, 3831, 3812, 3824, 3827, 3827, 3850, 3846, 3680, 3851, 3350, 3836, 3803, 3802, 3831, 3844, 3838, 3829, 3812, 3832, 3817, 3832, 3843, 3820, 3841, 3834, 3838, 3825, 3842, 3835, 3846, 3826, 3822, 3832, 3822, 3362, 3845, 3841, 3830, 3836, 3842, 3842, 3842, 3840, 3822, 3845, 3819, 3840, 3824, 3813, 3839, 3843, 3830, 3838, 3839, 3808, 3843, 3837, 3817, 3841, 3842, 3841, 3842, 3839, 3838, 3840, 3828, 3823, 3821, 3830, 3844, 3842, 3843, 3833, 3811, 3842, 3357, 3839, 3839, 3838, 3837, 3848, 3835, 3823, 3838, 3844, 3824, 3802, 3826, 3803, 3839, 3831, 3843, 3844, 3820, 3834, 3810, 3812, 3839, 3844, 3836, 3838, 3843, 3836, 3350, 3833, 3834, 3356, 3821, 3847, 3843, 3830, 3845, 3810, 3829, 3804, 3842, 3841, 3831, 3833, 3825, 3814, 3843, 3836, 3838, 3827, 3828, 3836, 3830, 3842, 3852, 3834, 3841, 3835, 3842, 3832, 3834, 3851, 3839, 3816, 3362, 3834, 3826, 3812, 3810, 3829, 3842, 3835, 3840, 3842, 3841, 3356, 3813, 3362, 3836, 3822, 3842, 3823, 3835, 3839, 3827, 3820, 3834, 3826, 3350, 3826, 3841, 3836, 3825, 3838, 3842, 3838, 3844, 3808, 3843, 3833, 3843, 3843, 3842, 3813, 3355, 3833, 3844, 3829, 3832, 3846, 3841, 3828, 3848, 3809, 3845, 3841, 3824, 3840, 3833, 3838, 3815, 3828, 3832, 3832, 3841, 3838, 3816, 3839, 3833, 3806, 3840, 3818, 3358, 3822, 3841, 3348, 3796, 3836, 3833, 3842, 3842, 3830, 3785, 3806, 3807, 3840, 3844, 3827, 3810, 3816, 3850, 3822, 3828, 3841, 3350, 3837, 3832, 3844, 3830, 3850, 3358, 3845, 3832, 3835, 3838, 3827, 3842, 3362, 3842, 3813, 3829, 3837, 3820, 3828, 3832, 3835, 3839, 3828, 3842, 3844, 3812, 3837, 3822, 3822, 3848, 3843, 3841, 3838, 3364, 3841, 3842, 3814, 3815, 3843, 3835, 3840, 3841, 3842, 3832, 3846, 3827, 3845, 3838, 3834, 3839, 3838, 3361, 3835, 3822, 3833, 3847, 3843, 3830, 3832, 3828, 3814, 3362, 3362, 3817, 3844, 3842, 3840, 3832, 3806, 3353, 3841, 3836, 3840, 3841, 3818, 3848, 3841, 3811, 3835, 3835, 3836, 3356, 3808, 3832, 3833, 3844, 3812, 3840, 3354, 3841, 3825, 3835, 3847, 3850, 3835, 3837, 3844, 3842, 3835, 3814, 3839, 3827, 3816, 3350, 3845, 3844, 3838, 3842, 3817, 3362, 3836, 3833, 3829, 3844, 3844, 3824, 3809, 3841, 3811, 3834, 3846, 3362, 3817, 3849, 3816, 3807, 3825, 3842, 3838, 3832, 3836, 3358, 3840, 3348, 3840, 3822, 3815, 3815, 3827, 3839, 3831, 3851, 3843, 3845, 3833, 3838, 3839, 3817, 3836, 3841, 3836, 3839, 3833, 3831, 3359, 3845, 3845, 3842, 3844, 3832, 3346, 3835, 3820, 3838, 3846, 3823, 3831, 3812, 3839, 3842, 3844, 3819, 3832, 3810, 3818, 3823, 3827, 3810, 3826, 3842, 3843, 3839, 3819, 3832, 3831, 3345, 3842, 3832, 3827, 3843, 3831, 3827, 3832, 3822, 3834, 3834, 3838, 3840, 3822, 3831, 3843, 3839, 3844, 3844, 3833, 3845, 3823, 3835, 3848, 3837, 3845, 3839, 3824, 3842, 3365, 3825, 3820, 3843, 3805, 3817, 3833, 3826, 3353, 3835, 3809, 3839, 3828, 3830, 3834, 3843, 3835, 3805, 3842, 3823, 3839, 3828, 3836, 3824, 3849, 3839, 3819, 3841, 3828, 3840, 3817, 3839, 3844, 3840, 3844, 3362, 3826, 3816, 3821, 3811, 3839, 3815, 3353, 3830, 3840, 3842, 3825, 3837, 3829, 3818, 3843, 3842, 3818, 3808, 3831, 3834, 3829, 3801, 3848, 3845, 3350, 3829, 3355, 3844, 3841, 3830, 3837, 3850, 3839, 3820, 3842, 3844, 3835, 3813, 3843, 3841, 3828, 3824, 3843, 3829, 3362, 3839, 3835, 3828, 3822, 3808, 3842, 3833, 3831, 3832, 3818, 3832, 3845, 3818, 3841, 3839, 3835, 3843, 3826, 3831, 3838, 3840, 3350, 3844, 3802, 3832, 3832, 3847, 3354, 3355, 3831, 3819, 3837, 3840, 3848, 3815, 3847, 3840, 3812, 3828, 3835, 3842, 3843, 3824, 3836, 3839, 3818, 3839, 3828, 3844, 3506, 3842, 3834, 3828, 3839, 3833, 3842, 3845, 3835, 3848, 3847, 3841, 3847, 3840, 3834, 3808, 3822, 3833, 3354, 3803, 3823, 3830, 3820, 3825, 3827, 3838, 3843, 3842, 3838, 3827, 3833, 3843, 3359, 3840, 3840, 3839, 3821, 3833, 3833, 3838, 3818, 3833, 3817, 3845, 3819, 3841, 3820, 3825, 3842, 3477, 3838, 3838, 3842, 3841, 3349, 3837, 3827, 3815, 3847, 3843, 3843, 3823, 3845, 3825, 3844, 3841, 3824, 3839, 3841, 3825, 3839, 3834, 3838, 3831, 3843, 3840, 3843, 3851, 3358, 3827, 3845, 3830, 3842, 3842, 3841, 3806, 3819, 3834, 3841, 3827, 3844, 3835, 3826, 3829, 3844, 3835, 3823, 3814, 3830, 3836, 3835, 3362, 3837, 3822, 3351, 3840, 3836, 3844, 3843, 3358, 3843, 3845, 3844, 3827, 3824, 3815, 3840, 3826, 3848, 3840, 3817, 3842, 3850, 3845, 3845, 3823, 3814, 3362, 3364, 3841, 3835, 3842, 3820, 3826, 3804, 3821, 3818, 3820, 3824, 3833, 3359, 3833, 3833, 3841, 3839, 3816, 3829, 3834, 3831, 3819, 3842, 3847, 3840, 3836, 3809, 3837, 3829, 3833, 3838, 3840, 3486, 3802, 3362, 3844, 3835, 3840, 3840, 3839, 3835, 3814, 3827, 3852, 3829, 3830, 3837, 3844, 3829, 3820, 3838, 3822, 3837, 3841, 3840, 3820, 3809, 3839, 3836, 3844, 3833, 3843, 3806, 3853, 3839, 3840, 3841, 3855, 3838, 3837, 3845, 3827, 3831, 3832, 3838, 3841, 3839, 3823, 3835, 3831, 3832, 3812, 3842, 3839, 3814, 3841, 3828, 3841, 3839, 3818, 3841, 3839, 3837, 3837, 3842, 3774, 3818, 3841, 3843, 3362, 3839, 3813, 3836, 3837, 3831, 3846, 3802, 3841, 3843, 3818, 3842, 3817, 3835, 3842, 3819, 3836, 3841, 3814, 3826, 3833, 3840, 3832, 3817, 3823, 3840, 3848, 3830, 3828, 3842, 3824, 3833, 3833, 3832, 3819, 3836, 3805, 3803, 3844, 3815, 3846, 3846, 3837, 3085, 3822, 3830, 3840, 3823, 3844, 3833, 3827, 3821, 3351, 3841, 3847, 3832, 3836, 3837, 3063, 3833, 3830, 3848, 3827, 3808, 3833, 3825, 3842, 3833, 3840, 3846, 3833, 3362, 3804, 3845, 3836, 3846, 3841, 3831, 3840, 3837, 3823, 3839, 3826, 3821, 3812, 3836, 3830, 3834, 3833, 3804, 3836, 3355, 3838, 3846, 3833, 3841, 3836, 3831, 3837, 3821, 3377, 3820, 3836, 3825, 3839, 3836, 3831, 3825, 3813, 3843, 3844, 3813, 3834, 3838, 3834, 3823, 3353, 3840, 3835, 3829, 3843, 3827, 3827, 3829, 3841, 3819, 3843, 3845, 3827, 3810, 3846, 3840, 3806, 3828, 3819, 3362, 3836, 3840, 3815, 3828, 3837, 3835, 3809, 3829, 3853, 3819, 3830, 3831, 3831, 3511, 3839, 3844, 3840, 3835, 3831, 3843, 3831, 3351, 3819, 3840, 3844, 3845, 3846, 3826, 3828, 3840, 3845, 3834, 3847, 3812, 3832, 3848, 3818, 3352, 3820, 3824, 3843, 3824, 3838, 3842, 3362, 3840, 3355, 3842, 3838, 3845, 3827, 3834, 3839, 3839, 3842, 3844, 3836, 3814, 3845, 3819, 3826, 3840, 3807, 3361, 3837, 3842, 3840, 3841, 3832, 3824, 3818, 3840, 3848, 3813, 3838, 3851, 3842, 3362, 3837, 3838, 3840, 3837, 3842, 3840, 3841, 3839, 3837, 3847, 3832, 3843, 3837, 3835, 3818, 3817, 3843, 3828, 3833, 3828, 3838, 3846, 3834, 3839, 3841, 3833, 3839, 3830, 3822, 3826, 3835, 3838, 3838, 3823, 3840, 3837, 3359, 3810, 3362, 3834, 3828, 3847, 3804, 3838, 3840, 3826, 3820, 3829, 3806, 3841, 3843, 3843, 3819, 3809, 3842, 3829, 3845, 3817, 3815, 3837, 3844, 3842, 3824, 3838, 3843, 3842, 3841, 3824, 3843, 3842, 3826, 3835, 3755, 3840, 3846, 3846, 3837, 3822, 3837, 3831, 3826, 3816, 3819, 3825, 3364, 3833, 3840, 3810, 3814, 3827, 3846, 3819, 3804, 3833, 3841, 3826, 3364, 3839, 3838, 3828, 3839, 3851, 3838, 3830, 3825, 3833, 3843, 3829, 3829, 3811, 3829, 3810, 3353, 3832, 3839, 3839, 3819, 3806, 3831, 3822, 3827, 3831, 3839, 3817, 3845, 3847, 3830, 3831, 3807, 3836, 3835, 3840, 3825, 3831, 3357, 3846, 3826, 3841, 3832, 3830, 3841, 3841, 3849, 3831, 3841, 3820, 3836, 3843, 3841, 3817, 3830, 3839, 3830, 3843, 3815, 3804, 3839, 3841, 3837, 3842, 3827, 3842, 3351, 3844, 3818, 3833, 3837, 3838, 3844, 3838, 3827, 3819, 3833, 3816, 3824, 3841, 3831, 3832, 3821, 3833, 3835, 3811, 3845, 3831, 3825, 3838, 3573, 3830, 3828, 3843, 3834, 3842, 3827, 3839, 3845, 3839, 3845, 3828, 3839, 3839, 3844, 3838, 3822, 3842, 3821, 3839, 3838, 3840, 3841, 3840, 3839, 3837, 3352, 3833, 3842, 3839, 3820, 3843, 3841, 3821, 3841, 3838, 3837, 3834, 3839, 3844, 3824, 3836, 3841, 3807, 3841, 3360, 3800, 3813, 3838, 3835, 3825, 3847, 3830, 3812, 3836, 3839, 3849, 3837, 3844, 3817, 3833, 3842, 3847, 3849, 3820, 3832, 3362, 3845, 3844, 3362, 3829, 3824, 3847, 3837, 3832, 3839, 3834, 3850, 3843, 3843, 3819, 3816, 3833, 3835, 3833, 3838, 3835, 3843, 3829, 3840, 3837, 3829, 3838, 3843, 3837, 3824, 3840, 3844, 3837, 3840, 3810, 3841, 3846, 3831, 3844, 3838, 3820, 3829, 3843, 3825, 3821, 3845, 3819, 3837, 3825, 3837, 3844, 3847, 3840, 3803, 3842, 3836, 3831, 3824, 3828, 3809, 3831, 3839, 3823, 3841, 3847, 3837, 3844, 3836, 3841, 3821, 3842, 3837, 3827, 3842, 3811, 3351, 3820, 3836, 3825, 3814, 3840, 3836, 3841, 3813, 3817, 3827, 3805, 3840, 3842, 3844, 3846, 3844, 3847, 3836, 3850, 3837, 3846, 3843, 3839, 3833, 3842, 3845, 3812, 3827, 3834, 3839, 3824, 3840, 3357, 3824, 3837, 3821, 3830, 3831, 3825, 3823, 3841, 3834, 3845, 3838, 3843, 3837, 3357, 3826, 3815, 3828, 3843, 3840, 3837, 3841, 3847, 3829, 3834, 3830, 3847, 3838, 3803, 3837, 3846, 3841, 3844, 3836, 3843, 3845, 3835, 3826, 3844, 3821, 3841, 3822, 3841, 3819, 3823, 3810, 3843, 3837, 3821, 3830, 3820, 3834, 3816, 3844, 3840, 3834, 3816, 3819, 3836, 3838, 3834, 3836, 3829, 3825, 3812, 3830, 3842, 3835, 3835, 3362, 3804, 3842, 3834, 3841, 3804, 3798, 3842, 3835, 3837, 3845, 3817, 3818, 3844, 3831, 3841, 3839, 3840, 3846, 3807, 3837, 3841, 3841, 3807, 3360, 3845, 3825, 3356, 3835, 3843, 3833, 3842, 3826, 3838, 3836, 3826, 3816, 3832, 3850, 3823, 3838, 3356, 3827, 3361, 3810, 3847, 3842, 3817, 3834, 3840, 3837, 3832, 3803, 3378, 3838, 3837, 3816, 3844, 3839, 3805, 3355, 3844, 3835, 3837, 3835, 3834, 3841, 3348, 3843, 3806, 3814, 3840, 3845, 3835, 3349, 3841, 3820, 3831, 3832, 3804, 3831, 3824, 3833, 3832, 3831, 3843, 3831, 3836, 3842, 3809, 3836, 3838, 3839, 3833, 3124, 3832, 3349, 3824, 3839, 3842, 3814, 3814, 3840, 3827, 3829, 3834, 3841, 3840, 3851, 3845, 3828, 3842, 3834, 3846, 3362, 3840, 3821, 3817, 3828, 2544, 3839, 3842, 3836, 3844, 3851, 3845, 3845, 3837, 3808, 3839, 3836, 3821, 3841, 3815, 3848, 3825, 3840, 3842, 3843, 3838, 3833, 3362, 3843, 3352, 3842, 3834, 3839, 3840, 3805, 3358, 3832, 3835, 3843, 3833, 3845, 3830, 3839, 3825, 3844, 3826, 3831, 3842, 3837, 3351, 3827, 3823, 3841, 3811, 3840, 3841, 3845, 3844, 3830, 3841, 3811, 3841, 3839, 3822, 3836, 3351, 3811, 3349, 3844, 3831, 3841, 3836, 3806, 3841, 3826, 3814, 3827, 3830, 3812, 3845, 3843, 3829, 3813, 3840, 3846, 3834, 3844, 3834, 3833, 3829, 3845, 3802, 3836, 3846, 3831, 3835, 3849, 3827, 3842, 3823, 3842, 3831, 3828, 3827, 3816, 3833, 3841, 3842, 3841, 3836, 3826, 3824, 3359, 3812, 3819, 3835, 3834, 3848, 3846, 3824, 3837, 3842, 3849, 3842, 3847, 3362, 3846, 3842, 3841, 3827, 3824, 3839, 3841, 3853, 3355, 3845, 3835, 3834, 3838, 3838, 3362, 3827, 3823, 3815, 3842, 3836, 3823, 3841, 3839, 3824, 3842, 3832, 3835, 3824, 3833, 3370, 3821, 3818, 3811, 3828, 3839, 3839, 3834, 3806, 3840, 3819, 3840, 3829, 3831, 3820, 3820, 3829, 3350, 3831, 3840, 3841, 3818, 3844, 3846, 3824, 3846, 3847, 3837, 3821, 3833, 3838, 3809, 3834, 3842, 3829, 3840, 3844, 3844, 3816, 3841, 3839, 3844, 3845, 3842, 3804, 3837, 3842, 3827, 3357, 3820, 3845, 3820, 3827, 3818, 3833, 3837, 3835, 3844, 3813, 3841, 3802, 3844, 3844, 3844, 3839, 3835, 3839, 3836, 3827, 3846, 3831, 3836, 3835, 3825, 3825, 3835, 3829, 3806, 3827, 3825, 3844, 3841, 3850, 3839, 3828, 3831, 3350, 3835, 3841, 3756, 3837, 3817, 3837, 3837, 3844, 3830, 3837, 3828, 3842, 3839, 3827, 3818, 3840, 3815, 3812, 3842, 3817, 3838, 3834, 3358, 3838, 3840, 3362, 3833, 3824, 3831, 3821, 3825, 3828, 3825, 3366, 3839, 3841, 3841, 3834, 3844, 3846, 3362, 3833, 3843, 3820, 3841, 3844, 3834, 3836, 3808, 3827, 3841, 3833, 3818, 3840, 3820, 3839, 3839, 3356, 3841, 3840, 3838, 3838, 3844, 3842, 3833, 3840, 3841, 3831, 3839, 3352, 3825, 3818, 3830, 3838, 3840, 3845, 3816, 3839, 3835, 3813, 3837, 3839, 3822, 3835, 3810, 3846, 3821, 3841, 3843, 3834, 3848, 3816, 3832, 3829, 3836, 3819, 3833, 3832, 3812, 3825, 3810, 3841, 3812, 3354, 3826, 3824, 3840, 3831, 3823, 3834, 3847, 3833, 3838, 3844, 3829, 3838, 3816, 3838, 3839, 3824, 3834, 3824, 3806, 3835, 3828, 3812, 3838, 3829, 3811, 3250, 3816, 3832, 3839, 3837, 3837, 3828, 3821, 3832, 3347, 3840, 3813, 3805, 3836, 3832, 3351, 3835, 3803, 3817, 3842, 3833, 3364, 3841, 3830, 3834, 3841, 3820, 3830, 3839, 3813, 3351, 3831, 3843, 3841, 3831, 3836, 3818, 3836, 3829, 3822, 3832, 3840, 3840, 3839, 3827, 3813, 3837, 3841, 3819, 3838, 3837, 3846, 3835, 3836, 3828, 3831, 3835, 3815, 3828, 3731, 3832, 3354, 3822, 3834, 3843, 3811, 3837, 3351, 3364, 3833, 3835, 3844, 3838, 3840, 3841, 3836, 3818, 3811, 3838, 3841, 3350, 3847, 3846, 3839, 3843, 3362, 3817, 3825, 3828, 3829, 3826, 3846, 3843, 3829, 3841, 3838, 3820, 3820, 3821, 3842, 3839, 3838, 3841, 3834, 3824, 3816, 3815, 3842, 3821, 3835, 3834, 3833, 3355, 3827, 3354, 3828, 3832, 3842, 3837, 3829, 3827, 3835, 3835, 3837, 3356, 3845, 3835, 3829, 3824, 3801, 3842, 3850, 3840, 3843, 3819, 3362, 3848, 3843, 3836, 3842, 3823, 3829, 3832, 3832, 3846, 3807, 3839, 3838, 3833, 3824, 3838, 3836, 3837, 3845, 3357, 3347, 3828, 3821, 3844, 3814, 3833, 3840, 3845, 3835, 3838, 3843, 3840, 3848, 3838, 3836, 3853, 3847, 3853, 3815, 3843, 3833, 3838, 3365, 3810, 3835, 3826, 3820, 3831, 3841, 3837, 3840, 3838, 3835, 3832, 3842, 3837, 3832, 3817, 3840, 3845, 3843, 3362, 3841, 3841, 3832, 3838, 3841, 3844, 3356, 3841, 3841, 3839, 3356, 3834, 3808, 3837, 3817, 3818, 3827, 3830, 3833, 2597, 3813, 3801, 3829, 3807, 3831, 3824, 3829, 3842, 3807, 3833, 3841, 3831, 3821, 3806, 3361, 3833, 3840, 3833, 3842, 3847, 3793, 3827, 3821, 3842, 3832, 3841, 3827, 3817, 3829, 3838, 3841, 3846, 3843, 3840, 3833, 3846, 3837, 3836, 3840, 3832, 3807, 3843, 3834, 3830, 3838, 3817, 3843, 3840, 3839, 3846, 3830, 3835, 3836, 3806, 3835, 3357, 3831, 3843, 3840, 3832, 3362, 3840, 3835, 3357, 3820, 3846, 3839, 3841, 3847, 3838, 2918, 3841, 3843, 3832, 3840, 3836, 3848, 3826, 3360, 3816, 3841, 3837, 3844, 3822, 3815, 3835, 3809, 3823, 3815, 3807, 3843, 3818, 3839, 3811, 3842, 3833, 3839, 3828, 3842, 3817, 3843, 3841, 3812, 3841, 3823, 3839, 3837, 3844, 3823, 3845, 3359, 3818, 3832, 3819, 3810, 3844, 3844, 3837, 3843, 3819, 3814, 3843, 3829, 3843, 3819, 3828, 3832, 3812, 3835, 3840, 3842, 3841, 3831, 3823, 3822, 3843, 3356, 3841, 3839, 3841, 3840, 3826, 3840, 3838, 3839, 3840, 3821, 3836, 3838, 3838, 3831, 3839, 3837, 3830, 3835, 3835, 3845, 3821, 3829, 3840, 3841, 3841, 3843, 3812, 3842, 3825, 3847, 3823, 3843, 3807, 3841, 3838, 3362, 3355, 3835, 3815, 3837, 3843, 3819, 3838, 3842, 3810, 3362, 3837, 3840, 3852, 3362, 3824, 3839, 3841, 3831, 3839, 3836, 3850, 3842, 3837, 3831, 3823, 3828, 3843, 3838, 3349, 3825, 3813, 3823, 3827, 3830, 3816, 3843, 3816, 3836, 3839, 3832, 3839, 3850, 3806, 3347, 3350, 3826, 3834, 3837, 3845, 3839, 3838, 3838, 3833, 3837, 3829, 3822, 3359, 3842, 3851, 3836, 3841, 3818, 3831, 3833, 3354, 3835, 3362, 3842, 3348, 3835, 3844, 3830, 3842, 3821, 3833, 3835, 3846, 3815, 3839, 3825, 3845, 3828, 3355, 3841, 3842, 3833, 3840, 3828, 3843, 3831, 3835, 3833, 3828, 3840, 3829, 3845, 3844, 3828, 3827, 3827, 3821, 3840, 3822, 3815, 3841, 3829, 3846, 3845, 3833, 3826, 3841, 3352, 3847, 3362, 3839, 3351, 3848, 3360, 3840, 3825, 3829, 3823, 3823, 3844, 3849, 3827, 3362, 3828, 3842, 3834, 3844, 3357, 3840, 3826, 3825, 3850, 3832, 3845, 3807, 3846, 3836, 3837, 3843, 3843, 3824, 3835, 3836, 3815, 3844, 3844, 3813, 3813, 3824, 3823, 3357, 3355, 3839, 3840, 3846, 3812, 3843, 3808, 3844, 3814, 3845, 3841, 3839, 3843, 3840, 3849, 3807, 3828, 3830, 3362, 3828, 3813, 3843, 3843, 3836, 3845, 3834, 3840, 3838, 3828, 3834, 3812, 3848, 3853, 3835, 3845, 3354, 3818, 3843, 3843, 3836, 3843, 3843, 3355, 3810, 3836, 3837, 3349, 3829, 3837, 3824, 3835, 3818, 3832, 3840, 3830, 3809, 3826, 3362, 3833, 3840, 3847, 3845, 3843, 3839, 3831, 3838, 3819, 3362, 3835, 3835, 3820, 3815, 3833, 3834, 3812, 3808, 3354, 3351, 3832, 3850, 3830, 3827, 3853, 3350, 3844, 3840, 3364, 3827, 3835, 3831, 3844, 3853, 3842, 3828, 3833, 3814, 3846, 3834, 3843, 3818, 3838, 3815, 3813, 3827, 3828, 3826, 3822, 3836, 3842, 3846, 3361, 3811, 3819, 3811, 3830, 3808, 3841, 3348, 3815, 3826, 3835, 3347, 3845, 3836, 3844, 3843, 3851, 3361, 3811, 3362, 3847, 3838, 3820, 3825, 3842, 3818, 3843, 3834, 3828, 3823, 3839, 3350, 3843, 3826, 3847, 3832, 3804, 3827, 3829, 3834, 3825, 3818, 3833, 3841, 3844, 3822, 3831, 3834, 3843, 3813, 3841, 3805, 3847, 3834, 3845, 3839, 3848, 3843, 3836, 3816, 3842, 3844, 3842, 3352, 3834, 3822, 3842, 3827, 3843, 3830, 3835, 3834, 3839, 3811, 3354, 3817, 3825, 3351, 3825, 3817, 3827, 3846, 3841, 3830, 3831, 3815, 3811, 3837, 3814, 3839, 3846, 3805, 3835, 3842, 3807, 3844, 3845, 3846, 3821, 3817, 3841, 3840, 3828, 3816, 3847, 3820, 3356, 3830, 3842, 3839, 3834, 3850, 3826, 3836, 3817, 3848, 3835, 3843, 3844, 3819, 3812, 3829, 3803, 3833, 3832, 3843, 3824, 3832, 3829, 3833, 3827, 3839, 3818, 3832, 3830, 3826, 3837, 3842, 3835, 3804, 3826, 3839, 3839, 3829, 3838, 3836, 3839, 3846, 3839, 3842, 3831, 3843, 3846, 3845, 3828, 3834, 3811, 3844, 3837, 3841, 3845, 3834, 3825, 3836, 3805, 3824, 3361, 3809, 3841, 3840, 3362, 3845, 3844, 3836, 3840, 3844, 3841, 3836, 3845, 3835, 3822, 3823, 3844, 3833, 3844, 3844, 3824, 3818, 3839, 3819, 3843, 3841, 3834, 3815, 3853, 3362, 3829, 3826, 3844, 3844, 3839, 3828, 3844, 3836, 3837, 3841, 3832, 3822, 3843, 3836, 3826, 3846, 3820, 3842, 3837, 3845, 3838, 3830, 3805, 3836, 3844, 3826, 3820, 3839, 3816, 3837, 3348, 3822, 3826, 3807, 3828, 3842, 3827, 3818, 3844, 3843, 3832, 3829, 3838, 3834, 3844, 3842, 3835, 3836, 3847, 3828, 3837, 3838, 3845, 3840, 3835, 3825, 3819, 3829, 3846, 3828, 3841, 3822, 3823, 3845, 3842, 3834, 3843, 3811, 3843, 3839, 3830, 3845, 3843, 3832, 3805, 3845, 3846, 3844, 3820, 3843, 3828, 3839, 3827, 3842, 3828, 3361, 3850, 3830, 3813, 3812, 3845, 3822, 3831, 3837, 3842, 3357, 3820, 3817, 3834, 3836, 3817, 3836, 3828, 3809, 3843, 3847, 3840, 3828, 3845, 3835, 3362, 3842, 3836, 3801, 3830, 3813, 3825, 3828, 3842, 3367, 3845, 3837, 3812, 3801, 3834, 3821, 3824, 3845, 3842, 3840, 3830, 3830, 3817, 3844, 3829, 3818, 3839, 3843, 3837, 3842, 3842, 3841, 3842, 3836, 3829, 3841, 3841, 3840, 3835, 3820, 3845, 3835, 3843, 3845, 3845, 3825, 3840, 3844, 3840, 3844, 3843, 3362, 3836, 3833, 3842, 3350, 3836, 3828, 3835, 3816, 3841, 3859, 3837, 3841, 3821, 3821, 3834, 3840, 3838, 3828, 3826, 3838, 3345, 3844, 3845, 3825, 3848, 3353, 3843, 3563, 3839, 3813, 3840, 3846, 3840, 3816, 3831, 3812, 3818, 3844, 3806, 3834, 3842, 3843, 3804, 3828, 3840, 3837, 3842, 3829, 3811, 3829, 3836, 3820, 3843, 3828, 3825, 3808, 3846, 3361, 3834, 3835, 3362, 3835, 3845, 3839, 3839, 3803, 3829, 3842, 3811, 3810, 3842, 3810, 3837, 3841, 3827, 3351, 3826, 3359, 3837, 3848, 3824, 3833, 3819, 3810, 3839, 3831, 3841, 3833, 3823, 3844, 3835, 3836, 3840, 3833, 3804, 3764, 3840, 3806, 3842, 3827, 3805, 3828, 3843, 3846, 3829, 3843, 3349, 3846, 3817, 3833, 3831, 3827, 3842, 3818, 3830, 3839, 3833, 3835, 3838, 3845, 3840, 3851, 3835, 3835, 3827, 3832, 3852, 3801, 3828, 3845, 3840, 3835, 3823, 3792, 3836, 3816, 3816, 3361, 3821, 3826, 3841, 3844, 3825, 3844, 3832, 3819, 3837, 3833, 3820, 3815, 3834, 3819, 3362, 3838, 3844, 3823, 3822, 3836, 3843, 3844, 3840, 3819, 3834, 3836, 3837, 3840, 3836, 3839, 3840, 3818, 3364, 3835, 3822, 3362, 3837, 3821, 3816, 3846, 3818, 3352, 3813, 3831, 3831, 3807, 3828, 3823, 3815, 3811, 3824, 3830, 3841, 3843, 3844, 3828, 3827, 3842, 3842, 3830, 3351, 3841, 3842, 3824, 3839, 3812, 3841, 3836, 3842, 3840, 3837, 3840, 3826, 3840, 3824, 3840, 3812, 3830, 3827, 3841, 3834, 3844, 3828, 3836, 3848, 3847, 3845, 3844, 3832, 3362, 3827, 3834, 3833, 3842, 3844, 3827, 3841, 3827, 3835, 3841, 3804, 3825, 3821, 3835, 3832, 3830, 3836, 3809, 3829, 3841, 3845, 3834, 3823, 3831, 3845, 3842, 3832, 3835, 3824, 3836, 3849, 3838, 3843, 3841, 3823, 3840, 3848, 3841, 3819, 3842, 3821, 2955, 3834, 3830, 3356, 3840, 3829, 3854, 3362, 3353, 3834, 3846, 3835, 3842, 3851, 3844, 3842, 3352, 3838, 3833, 3841, 3831, 3834, 3843, 3831, 3821, 3840, 3844, 3852, 3352, 3359, 3840, 3818, 3843, 3839, 3835, 3829, 3356, 3837, 3814, 3362, 3807, 3842, 3821, 3842, 3823, 3837, 3841, 3841, 3827, 3829, 3351, 3846, 3842, 3850, 3838, 3845, 3348, 3348, 3817, 3844, 3832, 3825, 3845, 3816, 3837, 3835, 3832, 3821, 3826, 3828, 3817, 3839, 3847, 3840, 3841, 3831, 3830, 3845, 3835, 3813, 3813, 3835, 3832, 3834, 3833, 3839, 3351, 3847, 3835, 3839, 3831, 3574, 3844, 3835, 3815, 3834, 3829, 3808, 3354, 3838, 3848, 3836, 3831, 3831, 3844, 3841, 3817, 3349, 3803, 3842, 3835, 3829, 3827, 3835, 3838, 3362, 3832, 3829, 3835, 3843, 3837, 3843, 3816, 3843, 3841, 3815, 3847, 3822, 3349, 3840, 3841, 3847, 3846, 3814, 3842, 3801, 3362, 3848, 3845, 3834, 3357, 3827, 3840, 3836, 3821, 3828, 3838, 3850, 3832, 3838, 3845, 3823, 3833, 3837, 3846, 3844, 3808, 3831, 3838, 3831, 3831, 3838, 3853, 3833, 3823, 3841, 3830, 3842, 3820, 3829, 3822, 3839, 3842, 3843, 3806, 3837, 3834, 3802, 3820, 3839, 3814, 3845, 3845, 3813, 3841, 3840, 3838, 3839, 3833, 3839, 3843, 3833, 3835, 3847, 3820, 3838, 3843, 3841, 3805, 3836, 3841, 3832, 3831, 3830, 3349, 3802, 3846, 3842, 3351, 3823, 3804, 3815, 3843, 3827, 3824, 3843, 3820, 3810, 3813, 3829, 3823, 3822, 3832, 3843, 3835, 3825, 3816, 3809, 3828, 3826, 3841, 3853, 3827, 3814, 3839, 3834, 3811, 3838, 3840, 3840, 3361, 3838, 3814, 3810, 3830, 3852, 3355, 3839, 3828, 3841, 3845, 3362, 3842, 3819, 3846, 3842, 3840, 3853, 3827, 3831, 3839, 3830, 3840, 3844, 3833, 3841, 3842, 3805, 3831, 3830, 3840, 3812, 3845, 3833, 3848, 3842, 3831, 3833, 3854, 3839, 3844, 3830, 3827, 3837, 3831, 3362, 3811, 3843, 3833, 3845, 3817, 3840, 3834, 3819, 3842, 3838, 3837, 3814, 3824, 3827, 3835, 3836, 3845, 3821, 3843, 3827, 3853, 3826, 3832, 3838, 3832, 3840, 3842, 3839, 3349, 3826, 3833, 3833, 3843, 3358, 3833, 3831, 3827, 3840, 3802, 3841, 3839, 3832, 3836, 3815, 3847, 3847, 3843, 3813, 3840, 3842, 3841, 3849, 3833, 3814, 3840, 3836, 3820, 3842, 3832, 3838, 3836, 3836, 3828, 3813, 3855, 3181, 3839, 3844, 3826, 3829, 3836, 3820, 3839, 3834, 3811, 3831, 3846, 3838, 3837, 3812, 3835, 3837, 3358, 3844, 3825, 3853, 3841, 3831, 3843, 3826, 3834, 3835, 3842, 3354, 3845, 3811, 3829, 3840, 3820, 3827, 3830, 3837, 3837, 3835, 3840, 3834, 3804, 3839, 3841, 3356, 3843, 3844, 3843, 3844, 3819, 3843, 3838, 3842, 3826, 3845, 3844, 3852, 3836, 3813, 3838, 3840, 3816, 3832, 3835, 3829, 3834, 3845, 3834, 3824, 3839, 3362, 3840, 3829, 3847, 3840, 3841, 3360, 3842, 3819, 3843, 3360, 3841, 3362, 3837, 3843, 3845, 3832, 3828, 3844, 3828, 3841, 3819, 3829, 3836, 3833, 3836, 3818, 3355, 3828, 3845, 3838, 3847, 3843, 3849, 3841, 3841, 3831, 3827, 3835, 3837, 3833, 3823, 3812, 3847, 3842, 3821, 3844, 3845, 3841, 3822, 3840, 3845, 3804, 3832, 3812, 3826, 3356, 3804, 3849, 3825, 3821, 3839, 3825, 3843, 3826, 3836, 3361, 3834, 3812, 3841, 3841, 3809, 3824, 3826, 3828, 3835, 3844, 3842, 3844, 3362, 3827, 3826, 3833, 3808, 3825, 3834, 3843, 3838, 3830, 3842, 3830, 3823, 3835, 3837, 3835, 3816, 3841, 3835, 3842, 3837, 3816, 3836, 3828, 3841, 3836, 3840, 3836, 3820, 3837, 3842, 3828, 3843, 3841, 3835, 3851, 3817, 3823, 3354, 3833, 3843, 3362, 3835, 3828, 3839, 3844, 3843, 3824, 3835, 3833, 3843, 3837, 3842, 3847, 3837, 3829, 3838, 3827, 3827, 3831, 3846, 3820, 3846, 3829, 3847, 3834, 3841, 3833, 3813, 3805, 3831, 3843, 3833, 3839, 3817, 3841, 3838, 3845, 3842, 3846, 3838, 3819, 3832, 3847, 3359, 3838, 3818, 3812, 3832, 3845, 3832, 3828, 3811, 3837, 3844, 3811, 3842, 3834, 3827, 3844, 3833, 3841, 3836, 3840, 3844, 3844, 3828, 3810, 3825, 3848, 3838, 3802, 3818, 3829, 3843, 3844, 3349, 3843, 3820, 3823, 3818, 3707, 3362, 3835, 3838, 3814, 3817, 3840, 3844, 3843, 3349, 3822, 3844, 3838, 3845, 3820, 3820, 3839, 3841, 3826, 3821, 3848, 3830, 3840, 3843, 3845, 3840, 3841, 3833, 3838, 3839, 3842, 3841, 3831, 3843, 3809, 3842, 3818, 3840, 3820, 3833, 3819, 3850, 3838, 3805, 3834, 3822, 3809, 3839, 3841, 3843, 3835, 3359, 3807, 3822, 3840, 3829, 3831, 3830, 3844, 3804, 3810, 3840, 3827, 3845, 3845, 3847, 3839, 3362, 3820, 3843, 3822, 3840, 3831, 3841, 3830, 3837, 3842, 3819, 3843, 3352, 3840, 3836, 3842, 3838, 3813, 3850, 3835, 3838, 3850, 3362, 3811, 3350, 3835, 3842, 3841, 3825, 3838, 3824, 3822, 3830, 3830, 3839, 3840, 3820, 3838, 3825, 3820, 3841, 3842, 3836, 3842, 3834, 3826, 3840, 3833, 3832, 3842, 3842, 3836, 3846, 3834, 3830, 3830, 3819, 3828, 3836, 3825, 3839, 3837, 3838, 3848, 3830, 3840, 3844, 3838, 3815, 3845, 3831, 3838, 3821, 3830, 3830, 3844, 3837, 3839, 3844, 3841, 3347, 3839, 3845, 3852, 3842, 3820, 3847, 3838, 3839, 3810, 3841, 3837, 3820, 3818, 3838, 3840, 3815, 3834, 3843, 3811, 3824, 3848, 3840, 3841, 3832, 3843, 3353, 3823, 3841, 3842, 3805, 3828, 3807, 3826, 3820, 3359, 3832, 3820, 3835, 3828, 3837, 3359, 3811, 3833, 3814, 3822, 3833, 3841, 3354, 3830, 3839, 3827, 3840, 3356, 3850, 3820, 3361, 3832, 3833, 3826, 3844, 3846, 3832, 3835, 3841, 3836, 3353, 3834, 3838, 3842, 3835, 3828, 3803, 3832, 3801, 3826, 3831, 3837, 3844, 3845, 3838, 3822, 3843, 3850, 3843, 3837, 3847, 3847, 3834, 3842, 3842, 3825, 3362, 3842, 3843, 3839, 3842, 3823, 3840, 3834, 3839, 3836, 3838, 3840, 3846, 3842, 3844, 3821, 3842, 3848, 3838, 3821, 3353, 3835, 3841, 3845, 3840, 3839, 3844, 3855, 3841, 3821, 3841, 3851, 3843, 3844, 3845, 3353, 3839, 3804, 3831, 3839, 3803, 3351, 3836, 3839, 3837, 3824, 3826, 3832, 3842, 3820, 3846, 3815, 3843, 3347, 3828, 3825, 3837, 3829, 3834, 3837, 3838, 3814, 3834, 3845, 3807, 3842, 3831, 3845, 3832, 3824, 3843, 3838, 3842, 3828, 3840, 3835, 3841, 3851, 3843, 3832, 3838, 3847, 3822, 3821, 3831, 3833, 3836, 3837, 3832, 3831, 3355, 3842, 3821, 3834, 3355, 3837, 3818, 3843, 3818, 3849, 3842, 3850, 3815, 3841, 3356, 3842, 3847, 3845, 3825, 3839, 3354, 3812, 3842, 3807, 3812, 3349, 3818, 3835, 3837, 3832, 3841, 3829, 3838, 3821, 3353, 3841, 3841, 3826, 3844, 3839, 3837, 3835, 3841, 3840, 3837, 3838, 3837, 3840, 3840, 3349, 3832, 3835, 3841, 3830, 3830, 3843, 3838, 3092, 3812, 3842, 3828, 3818, 3838, 3846, 3844, 3821, 3850, 3818, 3356, 3836, 3822, 3819, 3836, 3844, 3843, 3360, 3844, 3846, 3836, 3839, 3840, 3843, 3840, 3811, 3815, 3834, 3832, 3830, 3839, 3826, 3851, 3827, 3815, 3826, 3848, 3844, 3831, 3817, 3361, 3834, 3843, 3838, 3836, 3846, 3838, 3809, 3827, 3842, 3830, 3843, 3846, 3834, 3812, 3832, 3848, 3839, 3361, 3833, 3815, 3838, 3825, 3843, 3829, 3836, 3815, 3839, 3826, 3846, 3847, 3840, 3836, 3840, 3841, 3824, 3844, 3844, 3820, 3843, 3823, 3827, 3351, 3836, 3852, 3815, 3842, 3810, 3829, 3838, 3845, 3813, 3842, 3358, 3837, 3852, 3844, 3847, 3843, 3833, 3828, 3848, 3841, 3353, 3837, 3846, 3838, 3832, 3834, 3851, 3803, 3841, 3834, 3828, 3832, 3826, 3825, 3846, 3817, 3354, 3830, 3839, 3843, 3816, 3829, 3842, 3847, 3825, 3845, 3825, 3845, 3836, 3827, 3533, 3824, 3844, 3834, 3840, 3817, 3815, 3828, 3832, 3844, 3837, 3828, 3828, 3820, 3819, 3803, 3840, 3843, 3839, 3826, 3826, 3845, 3807, 3845, 3842, 3844, 3840, 3839, 3840, 3837, 3832, 3814, 3827, 3359, 3829, 3827, 3833, 3354, 3836, 3840, 3842, 3804, 3820, 3842, 3831, 3836, 3820, 3832, 3838, 3840, 3840, 3837, 3826, 2886, 3841, 3357, 3827, 3822, 3834, 3846, 3843, 3839, 3847, 3842, 3841, 3838, 3848, 3837, 3350, 3828, 3830, 3835, 3809, 3844, 3824, 3376, 3845, 3840, 3827, 3834, 3851, 3839, 3803, 3820, 3828, 3845, 3362, 3820, 3841, 3821, 3844, 3813, 3826, 3851, 3844, 3809, 3817, 3821, 3840, 3839, 3835, 3811, 3817, 3841, 3826, 3844, 3823, 3819, 3816, 3840, 3836, 3814, 3843, 3844, 3837, 3837, 3819, 3817, 3830, 3827, 3841, 3839, 3829, 3836, 3847, 3828, 3851, 3828, 3847, 3827, 3836, 3840, 3845, 3839, 3835, 3804, 3838, 3815, 3832, 3819, 3820, 3831, 3847, 3807, 3849, 3821, 3830, 3845, 3820, 3847, 3827, 3831, 3834, 3818, 3838, 3842, 3836, 3837, 3819, 3842, 3355, 3822, 3816, 3362, 3840, 3834, 3843, 3827, 3817, 3840, 3847, 3364, 3831, 3840, 3830, 3836, 3841, 3806, 3842, 3823, 3834, 3831, 3816, 3827, 3841, 3848, 3842, 3803, 3843, 3848, 3841, 3359, 3836, 3828, 3840, 3840, 3834, 3824, 3836, 3830, 3846, 3809, 3839, 3840, 3850, 3845, 3831, 3815, 3818, 3810, 3840, 3362, 3842, 3840, 3845, 3821, 3825, 3844, 3837, 3830, 3843, 3832, 3839, 3839, 3823, 3349, 3838, 3842, 3842, 3821, 3822, 3813, 3837, 3831, 3831, 3834, 3840, 3838, 3835, 3834, 3348, 3840, 3832, 3842, 3818, 3362, 3841, 3822, 3840, 3832, 3821, 3843, 3832, 3845, 3807, 3832, 3847, 3838, 3825, 3842, 3845, 3823, 3830, 3844, 3821, 3842, 3823, 3821, 3845, 3814, 3840, 3840, 3840, 3825, 3833, 3832, 3841, 3814, 3362, 3811, 3840, 3833, 3841, 3814, 3841, 3843, 3844, 3840, 3832, 3833, 3840, 3846, 3840, 3823, 3357, 3840, 3842, 3829, 3833, 3844, 3826, 3845, 3845, 3825, 3818, 3841, 3837, 3838, 3835, 3355, 3842, 3825, 3362, 3843, 3835, 3822, 3836, 3836, 3837, 3837, 3846, 3846, 3843, 3834, 3841, 3829, 3841, 3835, 3842, 3810, 3828, 3838, 3824, 3836, 3838, 3354, 3844, 3824, 3834, 3842, 3353, 3830, 3844, 3806, 3837, 3839, 3838, 3839, 3828, 3839, 3824, 3832, 3821, 3837, 3810, 3849, 3825, 3828, 3837, 3351, 3833, 3809, 3820, 3844, 3834, 3758, 3362, 3844, 3830, 3834, 3845, 3834, 3822, 3829, 3830, 3825, 3821, 3829, 3361, 3842, 3835, 3829, 3822, 3842, 3845, 3827, 3836, 3838, 3834, 3362, 3813, 3837, 3838, 3844, 3838, 3838, 3358, 3840, 3844, 3840, 3846, 3838, 3837, 3838, 3827, 3824, 3840, 3850, 3836, 3812, 3823, 3820, 3852, 3845, 3841, 3839, 3834, 3813, 3830, 3833, 3829, 3842, 3844, 3351, 3836, 3817, 3360, 3836, 3842, 3819, 3812, 3818, 3839, 3844, 3840, 3829, 3808, 3815, 3853, 3829, 3845, 3835, 3743, 3834, 3813, 3821, 3849, 3357, 3842, 3845, 3848, 3843, 3841, 3816, 3827, 3851, 3828, 3837, 3095, 3831, 3845, 3837, 3843, 3804, 3837, 3803, 3809, 3838, 3816, 3843, 3833, 3805, 3833, 3803, 3845, 3832, 3842, 3830, 3843, 3845, 3840, 3842, 3831, 3845, 3850, 3843, 3841, 3821, 3811, 3841, 3818, 3356, 3825, 3835, 3841, 3834, 3829, 3834, 3836, 3820, 3834, 3817, 3840, 3819, 3834, 3829, 3824, 3820, 3839, 3840, 3842, 3845, 3838, 3839, 3846, 3811, 3833, 3355, 3846, 3843, 3842, 3835, 3839, 3832, 3823, 3845, 3362, 3835, 3846, 3842, 3844, 3810, 3810, 3838, 3814, 3847, 3840, 3356, 3819, 3820, 3808, 3841, 3830, 3826, 3824, 3839, 3808, 3820, 3841, 3823, 3834, 3818, 3351, 3811, 3820, 3833, 3821, 3805, 3839, 3835, 3837, 3818, 3841, 3843, 3819, 3827, 3834, 3832, 3838, 3834, 3833, 3838, 3362, 3830, 3844, 3844, 3844, 3359, 3839, 3840, 3850, 3813, 3831, 3824, 3818, 3825, 3839, 3827, 3821, 3831, 3804, 3349, 3837, 3803, 3845, 3815, 3806, 3836, 3840, 3830, 3837, 3360, 3813, 3813, 3840, 3362, 3825, 3820, 3844, 3839, 3358, 3811, 3812, 3839, 3839, 3843, 3822, 3828, 3842, 3842, 3835, 3825, 3839, 3830, 3803, 3842, 3816, 3830, 3841, 3820, 3824, 3830, 3826, 3838, 3361, 3816, 3838, 3848, 3829, 3838, 3832, 3845, 3834, 3838, 3353, 3830, 3844, 3845, 3845, 3841, 3845, 3804, 3819, 3835, 3827, 3813, 3840, 3836, 3844, 3823, 3847, 3826, 3841, 3810, 3828, 3829, 3843, 3845, 3830, 3844, 3846, 3837, 3835, 3810, 3841, 3841, 3839, 3809, 3842, 3853, 3839, 3356, 3841, 3841, 3839, 3850, 3589, 3833, 3824, 3841, 3844, 3815, 3829, 3839, 3834, 3830, 3823, 3823, 3844, 3831, 3843, 3826, 3349, 3348, 3820, 3827, 3815, 3833, 3837, 3827, 3832, 3822, 3829, 3842, 3834, 3838, 3808, 3352, 3818, 3845, 3833, 3834, 3847, 3844, 3839, 3823, 3834, 3846, 3819, 3839, 3826, 3843, 3843, 3817, 3844, 3845, 3824, 3827, 3827, 3836, 3807, 3840, 3845, 3842, 3823, 3815, 3835, 3842, 3841, 3841, 3849, 3846, 3838, 3837, 3831, 3838, 3835, 3843, 3838, 3827, 3819, 3836, 3821, 3817, 3828, 3815, 3828, 3821, 3826, 3842, 3832, 3817, 3822, 3832, 3838, 3803, 3839, 3831, 3824, 3354, 3726, 3827, 3842, 3834, 3832, 3821, 3822, 3846, 3843, 3348, 3836, 3814, 3842, 3842, 3838, 3807, 3824, 3841, 3824, 3829, 3828, 3837, 3839, 3842, 3831, 3846, 3843, 3841, 3820, 3843, 3842, 3808, 3841, 3834, 3817, 3836, 3835, 3846, 3829, 3832, 3837, 3850, 3815, 3362, 3842, 3807, 3362, 3820, 3820, 3821, 3844, 3843, 3827, 3835, 3810, 3820, 3816, 3819, 3843, 3838, 3835, 3829, 3845, 3830, 3844, 3813, 3826, 3806, 3808, 3817, 3806, 3826, 3840, 3848, 3822, 3845, 3837, 3812, 3841, 3818, 3815, 3837, 3836, 3827, 3806, 3843, 3840, 3819, 3358, 3804, 3816, 3356, 3834, 3839, 3843, 3833, 3816, 3832, 3805, 3835, 3823, 3833, 3355, 3359, 3811, 3841, 3835, 3847, 3349, 3362, 3350, 3821, 3846, 3837, 3824, 3817, 3853, 3838, 3841, 3842, 3806, 3364, 3826, 3837, 3847, 3839, 3357, 3834, 3801, 3830, 3842, 3831, 3818, 3845, 3836, 3837, 3819, 3839, 3844, 3854, 3845, 3843, 3833, 3810, 3820, 3842, 3831, 3824, 3846, 3834, 3479, 3845, 3817, 3839, 3816, 3805, 3835, 3841, 3848, 3821, 3821, 3810, 3827, 3843, 3847, 3835, 3846, 3348, 3836, 3839, 3828, 3829, 3834, 3846, 3819, 3839, 3817, 3832, 3809, 3838, 3827, 3812, 3834, 3837, 3843, 3811, 3837, 3841, 3836, 3351, 3838, 3834, 3363, 3838, 3812, 3843, 3813, 3831, 3823, 3814, 3822, 3827, 3844, 3829, 3841, 3844, 3818, 3835, 3821, 3819, 3842, 3840, 3832, 3845, 3830, 3817, 3811, 3819, 3840, 3840, 3842, 3825, 3843, 3804, 3827, 3841, 3832, 3827, 3354, 3840, 3834, 3834, 3825, 3837, 3837, 3834, 3811, 3829, 3825, 3820, 3823, 3827, 3814, 3847, 3843, 3835, 3818, 3825, 3825, 3353, 3841, 3830, 3349, 3832, 3836, 3840, 3847, 3814, 3836, 3837, 3807, 3804, 3814, 3824, 3361, 3801, 3838, 3853, 3827, 3818, 3839, 3838, 3840, 3814, 3821, 3842, 3846, 3831, 3839, 3821, 3828, 3842, 3846, 3843, 3831, 3831, 3825, 3801, 3820, 3836, 3830, 3842, 3823, 3844, 3825, 3832, 3843, 3849, 3833, 3830, 3843, 3843, 3816, 3821, 3843, 3845, 3838, 3825, 3838, 3833, 3351, 3840, 3820, 3833, 3843, 3814, 3817, 3833, 3819, 3813, 3421, 3841, 3822, 3813, 3354, 3830, 3830, 3840, 3842, 3829, 3830, 3835, 3835, 3819, 3834, 3811, 3818, 3848, 3828, 3819, 3835, 3812, 3840, 3847, 3844, 3816, 3846, 3843, 3351, 3818, 3840, 3821, 3837, 3841, 3820, 3842, 3833, 3838, 3843, 3350, 3845, 3832, 3837, 3830, 3362, 3831, 3841, 3842, 3843, 3800, 3839, 3847, 3832, 3843, 3818, 3354, 3838, 3842, 3810, 3833, 3826, 3842, 3834, 3806, 3837, 3835, 3846, 3835, 3832, 3838, 3820, 3823, 3837, 3841, 3839, 3841, 3359, 3827, 3836, 3827, 3834, 3837, 3819, 3837, 3835, 3813, 3825, 3831, 3838, 3846, 3823, 3837, 3843, 3827, 3814, 3841, 3826, 3802, 3839, 3825, 3828, 3853, 3812, 3358, 3829, 3839, 3843, 3833, 3824, 3357, 3804, 3822, 3833, 3838, 3819, 3814, 3843, 3804, 3839, 3845, 3836, 3828, 3818, 3837, 3843, 3808, 3824, 3811, 3842, 3838, 3837, 3839, 3818, 3818, 3831, 3821, 3827, 3831, 3827, 3842, 3844, 3830, 3825, 3820, 3802, 3844, 3812, 3827, 3843, 3830, 3823, 3845, 3835, 3841, 3818, 3847, 3826, 3817, 3844, 3835, 3810, 3844, 3842, 3838, 3850, 3467, 3843, 3835, 3829, 3839, 3833, 3826, 3362, 3835, 3819, 3848, 3826, 3830, 3841, 3836, 3830, 3823, 3824, 3356, 3843, 3843, 3827, 3839, 3830, 3834, 3838, 3348, 3847, 3824, 3827, 3834, 3842, 3830, 3845, 3841, 3815, 3848, 3817, 3833, 3823, 3820, 3844, 3840, 3833, 3353, 3833, 3833, 3815, 3842, 3843, 3826, 3838, 3840, 3093, 3834, 3805, 3829, 3813, 3839, 3843, 3834, 3829, 3357, 3836, 3826, 3837, 3841, 3844, 3838, 3820, 3847, 3833, 3836, 3844, 3803, 3837, 3815, 3836, 3831, 3836, 3835, 3809, 3832, 3357, 3813, 3831, 3840, 3816, 3840, 3833, 3826, 3813, 3833, 3353, 3843, 3844, 3813, 3832, 3847, 3815, 3844, 3822, 3826, 3836, 3812, 3824, 3844, 3846, 3847, 3840, 3832, 3830, 3834, 3835, 3844, 3842, 3839, 3844, 3847, 3841, 3829, 3839, 3842, 3844, 3834, 3361, 3828, 3834, 3846, 3832, 3831, 3822, 3839, 3355, 3832, 3839, 3847, 3825, 3808, 3834, 3841, 3826, 3813, 3830, 3828, 3822, 3844, 3845, 3824, 3838, 3842, 3829, 3826, 3834, 3832, 3832, 3353, 3821, 3837, 3354, 3837, 3846, 3844, 3821, 3842, 3839, 3839, 3844, 3844, 3844, 3825, 3841, 3842, 3836, 3828, 3830, 3825, 3845, 3835, 3825, 3846, 3843, 3834, 3842, 3817, 3839, 3844, 3835, 3843, 3839, 3361, 3835, 3810, 3826, 3828, 3842, 3810, 3840, 3839, 3834, 3824, 3843, 3838, 3838, 3819, 3843, 3819, 3841, 3841, 3825, 3811, 3828, 3842, 3842, 3846, 3842, 3834, 3838, 3850, 3837, 3362, 3816, 3840, 3841, 3817, 3355, 3840, 3843, 3352, 3839, 3814, 3820, 3849, 3844, 3843, 3844, 3830, 3847, 3847, 3844, 3835, 3853, 3841, 3819, 3845, 3835, 3825, 3844, 3829, 3183, 3843, 3835, 3835, 3823, 3840, 3844, 3833, 3837, 3806, 3840, 3818, 3834, 3352, 3824, 3840, 3808, 3851, 3829, 3843, 3849, 3827, 3838, 3823, 3841, 3835, 3842, 3832, 3807, 3844, 3842, 3842, 3830, 3819, 3827, 3814, 3366, 3823, 3843, 3829, 3840, 3829, 3841, 3357, 3813, 3827, 3833, 3840, 3840, 3361, 3842, 3841, 3826, 3833, 3843, 3844, 3831, 3839, 3844, 3844, 3840, 3818, 3350, 3845, 3839, 3827, 3835, 3825, 3815, 3840, 3833, 3812, 3844, 3843, 3831, 3843, 3840, 3812, 3823, 3843, 3834, 3846, 3841, 3362, 3815, 3830, 3824, 3834, 3823, 3836, 3839, 3845, 3824, 3825, 3844, 3838, 3837, 3834, 3820, 3703, 3829, 3363, 3842, 3843, 3839, 3818, 3831, 3349, 3803, 3840, 3843, 3356, 3832, 3825, 3831, 3822, 3832, 3831, 3845, 3840, 3846, 3814, 3848, 3810, 3843, 3839, 3843, 3829, 3842, 3839, 3845, 3840, 3844, 3840, 3835, 3805, 3837, 3809, 3833, 3845, 3351, 3841, 3352, 3842, 3804, 3841, 3824, 3846, 3840, 3816, 3845, 3351, 3834, 3813, 3825, 3827, 3833, 3836, 3837, 3361, 3816, 3839, 3354, 3822, 3842, 3842, 3831, 3807, 3827, 3359, 3847, 3837, 3825, 3360, 3815, 3361, 3826, 3841, 3842, 3844, 3843, 3821, 3812, 3359, 3841, 3817, 3824, 3813, 3833, 3833, 3821, 3832, 3832, 3843, 3808, 3830, 3844, 3836, 3820, 3837, 3835, 3824, 3822, 3840, 3844, 3847, 3817, 3813, 3809, 3356, 3838, 3827, 3840, 3832, 3357, 3813, 3839, 3829, 3826, 3837, 3844, 3826, 3822, 3839, 3803, 3831, 3841, 3350, 3822, 3839, 3838, 3812, 3836, 3830, 3842, 3829, 3827, 3837, 3821, 3825, 3820, 3832, 3822, 3835, 3839, 3839, 3850, 3839, 3838, 3825, 3835, 3359, 3817, 3827, 3840, 3838, 3847, 3837, 3843, 3828, 3833, 3831, 3835, 3837, 3832, 3352, 3846, 3807, 3847, 3842, 3842, 3818, 3836, 3830, 3845, 3811, 3837, 3813, 3847, 3842, 3840, 3835, 3841, 3844, 3349, 3835, 3842, 3841, 3843, 3845, 3826, 3838, 3820, 3822, 3835, 3839, 3836, 3837, 3828, 3830, 3835, 3356, 3832, 3821, 3840, 3830, 3832, 3840, 3839, 3356, 3838, 3842, 3826, 3825, 3849, 3351, 3834, 3815, 3846, 3831, 3362, 3353, 3832, 3844, 3350, 3837, 3843, 3353, 3833, 3814, 3840, 3843, 3833, 3355, 3826, 3833, 3838, 3830, 3842, 3833, 3832, 3842, 3842, 3832, 3354, 3842, 3842, 3817, 3362, 3832, 3828, 3819, 3835, 3836, 3820, 3819, 3818, 3848, 3824, 3819, 3841, 3833, 3829, 3812, 3824, 3846, 3833, 3849, 3843, 3842, 3829, 3843, 3837, 3820, 3838, 3837, 3827, 3843, 3832, 3827, 3830, 3837, 3825, 3837, 3836, 3843, 3843, 3832, 3839, 3809, 3855, 3841, 3820, 3842, 3836, 3843, 3844, 3823, 3843, 3836, 3802, 3826, 3836, 3841, 3831, 3828, 3815, 3839, 3839, 3359, 3846, 3828, 3844, 3832, 3813, 3840, 3842, 3822, 3843, 3818, 3818, 3353, 3843, 3835, 3820, 3817, 3842, 3819, 3848, 3841, 3844, 3842, 3831, 3838, 3812, 3824, 3830, 3830, 3827, 3837, 3804, 3362, 3837, 3814, 3844, 3832, 3822, 3344, 3823, 3826, 3809, 3847, 3350, 3831, 3837, 3841, 3837, 3819, 3838, 3842, 3842, 3833, 3841, 3827, 3839, 3846, 3838, 3837, 3838, 3349, 3832, 3833, 3831, 3833, 3845, 3813, 3854, 3806, 3843, 3829, 3838, 3838, 3833, 3811, 3845, 3841, 3848, 3845, 3851, 3837, 3831, 3838, 3844, 3839, 3841, 3834, 3836, 3829, 3836, 3835, 3811, 3812, 3844, 3833, 3838, 3840, 3843, 3830, 3362, 3833, 3832, 3347, 3355, 3828, 3813, 3828, 3840, 3841, 3847, 3819, 3835, 3838, 3836, 3833, 3813, 3811, 3353, 3364, 3829, 3828, 3823, 3843, 3845, 3818, 3835, 3842, 3832, 3839, 3834, 3843, 3840, 3845, 3807, 3843, 3821, 3835, 3831, 3352, 3826, 3835, 3821, 3812, 3843, 3831, 3843, 3812, 3834, 3836, 3350, 3828, 3838, 3848, 3840, 3357, 3841, 3832, 3826, 3835, 3815, 3824, 3824, 3351, 3843, 3825, 3362, 3823, 3788, 3844, 3834, 3851, 3834, 3841, 3837, 3836, 3842, 3842, 3820, 3844, 3846, 3843, 3748, 3844, 3840, 3843, 3827, 3831, 3843, 3831, 3824, 3812, 3843, 3844, 3840, 3837, 3362, 3830, 3840, 3826, 3834, 3842, 3836, 3838, 3839, 3839, 3842, 3429, 3822, 3842, 3837, 3835, 3825, 3840, 3825, 3843, 3839, 3839, 3840, 3835, 3834, 3821, 3824, 3846, 3843, 3841, 3839, 3823, 3847, 3838, 3833, 3834, 3835, 3352, 3845, 3803, 3839, 3766, 3827, 3835, 3840, 3840, 3833, 3842, 3815, 3821, 3834, 3846, 3844, 3819, 3841, 3809, 3844, 2918, 3842, 3853, 3818, 3807, 3837, 3843, 3833, 3840, 3813, 3824, 3819, 3844, 3361, 3841, 3832, 3840, 3836, 3829, 3844, 3837, 3832, 3851, 3841, 3811, 3837, 3832, 3843, 3816, 3830, 3848, 3833, 3842, 3837, 3835, 3833, 3811, 3838, 3834, 3813, 3836, 3830, 3842, 3845, 3834, 3844, 3842, 3831, 3840, 3824, 3811, 3825, 3837, 3842, 3812, 3816, 3848, 3826, 3828, 3846, 3842, 3843, 3827, 3824, 3834, 3831, 3838, 3362, 3829, 3836, 3836, 3839, 3830, 3812, 3841, 3818, 3836, 3840, 3827, 3813, 3842, 3806, 3844, 3349, 3836, 3842, 3355, 3814, 3839, 3832, 3842, 3837, 3844, 3837, 3851, 3807, 3833, 3844, 3843, 3832, 3830, 3360, 3829, 3831, 3846, 3835, 3833, 3814, 3833, 3812, 3828, 3833, 3837, 3830, 3838, 3839, 3836, 3832, 3840, 3832, 3834, 3849, 3825, 3832, 3841, 3820, 3825, 3835, 3830, 3842, 3828, 3814, 3825, 3827, 3829, 3831, 3828, 3836, 3840, 3830, 3820, 3351, 3848, 3359, 3818, 3831, 3830, 3834, 3839, 3825, 3845, 3827, 3848, 3810, 3841, 3826, 3846, 3837, 3833, 3841, 3838, 3837, 3846, 3841, 3821, 3828, 3824, 3351, 3843, 3362, 3842, 3837, 3844, 3816, 3823, 3836, 3838, 3829, 3843, 3812, 3836, 3844, 3834, 3834, 3842, 3835, 3844, 3813, 3839, 3838, 3841, 3843, 3840, 3843, 3836, 3825, 3847, 3315, 3851, 3843, 3824, 3841, 3766, 3828, 3839, 3840, 3825, 3838, 3819, 3832, 3837, 3842, 3847, 3551, 3844, 3824, 3810, 3839, 3838, 3816, 3825, 3821, 3821, 3845, 3845, 3362, 3836, 3835, 3839, 3812, 3831, 3839, 3843, 3836, 3823, 3348, 3832, 3828, 3840, 3842, 3362, 3844, 3841, 3838, 3816, 3816, 3841, 3834, 3806, 3835, 3842, 3829, 3840, 3836, 3807, 3358, 3848, 3832, 3841, 3844, 3822, 3828, 3852, 3831, 3842, 3841, 3840, 3814, 3806, 3832, 3844, 3834, 3827, 3843, 3831, 3362, 3821, 3842, 3838, 3802, 3826, 3838, 3830, 3829, 3364, 3829, 3834, 3839, 3852, 3831, 3833, 3351, 3821, 3821, 3834, 3809, 3830, 3847, 3822, 3831, 3833, 3826, 3832, 3847, 3835, 3842, 3843, 3841, 3852, 3830, 3841, 3820, 3840, 3846, 3842, 3844, 3844, 3823, 3834, 3843, 3821, 3819, 3814, 3831, 3356, 3837, 3842, 3827, 3828, 3840, 3842, 3827, 3841, 3821, 3825, 3837, 3831, 3822, 3842, 3843, 3843, 3352, 3805, 3824, 3843, 3841, 3836, 3837, 3820, 3803, 3830, 3831, 3356, 3836, 3821, 3845, 3842, 3841, 3834, 3820, 3824, 3836, 3821, 3844, 3835, 3834, 3841, 3821, 3802, 3835, 3838, 3844, 3820, 3839, 3842, 3841, 3850, 3832, 3830, 3817, 3832, 3844, 3840, 3849, 3845, 3826, 3352, 3811, 3840, 3849, 3351, 3826, 3822, 3845, 3843, 3828, 3846, 3833, 3836, 3836, 3834, 3830, 3832, 3825, 3808, 3832, 3831, 3838, 3821, 3835, 3832, 3805, 3825, 3836, 3830, 3837, 3833, 3844, 3843, 3846, 3834, 3832, 3840, 3842, 3842, 3357, 3837, 3839, 3833, 3362, 3838, 3842, 3834, 3844, 3832, 3844, 3844, 3838, 3836, 3842, 3843, 3832, 3832, 3827, 3814, 3848, 3358, 3842, 3827, 3820, 3359, 3814, 3825, 3348, 3828, 3838, 3837, 3362, 3844, 3833, 3823, 3839, 3814, 3837, 3822, 3357, 3362, 3844, 3825, 3845, 3832, 3814, 3350, 3846, 3844, 3837, 3820, 3822, 3824, 3844, 3842, 3837, 3845, 3833, 3832, 3838, 3832, 3840, 3841, 3841, 3847, 3844, 3843, 3355, 3833, 3843, 3832, 3842, 3836, 3840, 3836, 3839, 3819, 3841, 3829, 3841, 3830, 3820, 3818, 3843, 3848, 3840, 3816, 3844, 3812, 3357, 3805, 3818, 3847, 3830, 3812, 3848, 3355, 3820, 3837, 3826, 3833, 3843, 3847, 3841, 3816, 3834, 3807, 3856, 3804, 3837, 3843, 3832, 3824, 3831, 3843, 3826, 3362, 3838, 3827, 3841, 3840, 3826, 3822, 3839, 3843, 3843, 3828, 3824, 3813, 3839, 3362, 3831, 3835, 3807, 3842, 3824, 3806, 3835, 3846, 3826, 3846, 3353, 3834, 3844, 3844, 3840, 3812, 3835, 3836, 3839, 3837, 3817, 3847, 3833, 3844, 3838, 3834, 3827, 3826, 3841, 3846, 3836, 3825, 3357, 3839, 3816, 3841, 3839, 3814, 3829, 3835, 3826, 3830, 3843, 3804, 3831, 3354, 3817, 3838, 3837, 3830, 3844, 3820, 3834, 3842, 3816, 3832, 3357, 3846, 3831, 3823, 3823, 3842, 3822, 3806, 3843, 3834, 3356, 3829, 3818, 3835, 3823, 3840, 3837, 3834, 3841, 3815, 3825, 3834, 3832, 3845, 3817, 3821, 3817, 3838, 3832, 3837, 3832, 3839, 3821, 3836, 3824, 3838, 3839, 3841, 3814, 3841, 3844, 3831, 3820, 3817, 3839, 3843, 3839, 3842, 3364, 3843, 3839, 3809, 3837, 3841, 3836, 3842, 3819, 3831, 3832, 3844, 3836, 3353, 3826, 3389, 3838, 3829, 3843, 3843, 3820, 3843, 3817, 3826, 3796, 3360, 3827, 3812, 3829, 3839, 3810, 3840, 3837, 3810, 3834, 3832, 3846, 3835, 3837, 3839, 3842, 3830, 3362, 3830, 3840, 3815, 3810, 3812, 3837, 3835, 3811, 3847, 3841, 3846, 3835, 3827, 3820, 3845, 3824, 3834, 3349, 3841, 3835, 3843, 3837, 3817, 3846, 3815, 3841, 3351, 3845, 3844, 3841, 3839, 3838, 3830, 3839, 3844, 3830, 3822, 3839, 3815, 3844, 3838, 3830, 3840, 3848, 3357, 3831, 3843, 3840, 3843, 3842, 3833, 3844, 3838, 3842, 3839, 3816, 3831, 3838, 3810, 3822, 3814, 3812, 3825, 3848, 3356, 3840, 3842, 3841, 3848, 3815, 3835, 3846, 3824, 3838, 3847, 3840, 3842, 3829, 3827, 3842, 3354, 3830, 3817, 3459, 3820, 3844, 3839, 3841, 3848, 3845, 3832, 3819, 3826, 3846, 3839, 3833, 3829, 3842, 3833, 3835, 3834, 3836, 3835, 3824, 3848, 3840, 3812, 3811, 3843, 3812, 3826, 3804, 3834, 3829, 3830, 3843, 3831, 3398, 3843, 3819, 3827, 3845, 3827, 3840, 3818, 3362, 3817, 3672, 3842, 3841, 3840, 3842, 3835, 3829, 3844, 3836, 3841, 3835, 3839, 3805, 3846, 3839, 3359, 3834, 3834, 3833, 3845, 3837, 3844, 3840, 3842, 3840, 3843, 3838, 3359, 3827, 3843, 3804, 3834, 3836, 3356, 3808, 3839, 3842, 3800, 3839, 3844, 3349, 3831, 3844, 3813, 3842, 3819, 3837, 3354, 3847, 3838, 3816, 3841, 3842, 3354, 3362, 3817, 3830, 3839, 3844, 3834, 3825, 3814, 3803, 3838, 3841, 3828, 3824, 3825, 3846, 3826, 3820, 3830, 3821, 3816, 3836, 3843, 3800, 2918, 3834, 3807, 3835, 3843, 3838, 3844, 3843, 3840, 3844, 3841, 3841, 3828, 3840, 3846, 3837, 3842, 3806, 3842, 3823, 3844, 3839, 3812, 3842, 3830, 3808, 3828, 3844, 3836, 3838, 3840, 3841, 3838, 3833, 3829, 3821, 3849, 3836, 3838, 3835, 3848, 3836, 3840, 3837, 3835, 3831, 3348, 3847, 3817, 3830, 3844, 3843, 3844, 3839, 3841, 3842, 3818, 3801, 3829, 3821, 3835, 3838, 3839, 3838, 3827, 3831, 3809, 3841, 3833, 3850, 3830, 3845, 3845, 3824, 3832, 3324, 3842, 3840, 3827, 3841, 3835, 3839, 3833, 3835, 3840, 3804, 3352, 3821, 3807, 3828, 3838, 3847, 3825, 3837, 3355, 3356, 3817, 3841, 3354, 3842, 3844, 3824, 3840, 3836, 3847, 3834, 3828, 3838, 3817, 3845, 3833, 3835, 3843, 3843, 3842, 3823, 3818, 3837, 3843, 3840, 3823, 3359, 3842, 3364, 3844, 3843, 3833, 3827, 3843, 3823, 3797, 3842, 3803, 3819, 3353, 3844, 3840, 3831, 3843, 3844, 3839, 3831, 3840, 3348, 3840, 3826, 3810, 3837, 3821, 3820, 3836, 3818, 3837, 3839, 3837, 3840, 3831, 3828, 3807, 3811, 3850, 3844, 3836, 3833, 3834, 3841, 3848, 3362, 3834, 3829, 3835, 3841, 3840, 3838, 3849, 3349, 3827, 3809, 3838, 3846, 3814, 3826, 3821, 3831, 3833, 3847, 3810, 3842, 3830, 3357, 3829, 3814, 3829, 3835, 3819, 3839, 3355, 3831, 3844, 3834, 3825, 3841, 3821, 3838, 3838, 3845, 3845, 3830, 3833, 3839, 3848, 3837, 3846, 3362, 3844, 3836, 3348, 3827, 3838, 3813, 3806, 3825, 3815, 3362, 3815, 3838, 3822, 3816, 3833, 3832, 3852, 3827, 3841, 3836, 3844, 3835, 3825, 3837, 3851, 3842, 3815, 3828, 3833, 3843, 3841, 3834, 3833, 3828, 3828, 3839, 3848, 3845, 3810, 3848, 3835, 3827, 3359, 3828, 3822, 3841, 3809, 3821, 3837, 3833, 3805, 3811, 3826, 3843, 3834, 3830, 3835, 3815, 3835, 3839, 3837, 3835, 3842, 3834, 3803, 3840, 3825, 3838, 3832, 3833, 3846, 3854, 3847, 3830, 3842, 3850, 3840, 3840, 3821, 3809, 3840, 3825, 3845, 3827, 3351, 3840, 3835, 3843, 3832, 3821, 3833, 3833, 3844, 3852, 3823, 3849, 3843, 3842, 3843, 3837, 3817, 3841, 3839, 3841, 3846, 3809, 3825, 3844, 3824, 3844, 3838, 3846, 3828, 3350, 3843, 3839, 3842, 3823, 3841, 3820, 3745, 3832, 3351, 3845, 3838, 3817, 3353, 3816, 3836, 3846, 3843, 3842, 3816, 3353, 3843, 3815, 3832, 3836, 3853, 3846, 3843, 3816, 3841, 3837, 3808, 3832, 3833, 3839, 3844, 3841, 3810, 3819, 3821, 3829, 3845, 3812, 3834, 3847, 3851, 3837, 3354, 3840, 3830, 3821, 3834, 3834, 3350, 3833, 3839, 3821, 3837, 3810, 3840, 3814, 3839, 3841, 3828, 3362, 3842, 3845, 3821, 3843, 3497, 3815, 3839, 3845, 3836, 3828, 3841, 3833, 3848, 3840, 3815, 3826, 3842, 3844, 3841, 3843, 3825, 3842, 3854, 3841, 3835, 3834, 3824, 3819, 3829, 3821, 3847, 3835, 3831, 3845, 3835, 3836, 3842, 3824, 3835, 3831, 3840, 3845, 3850, 3833, 3843, 3837, 3842, 3840, 3819, 3829, 3825, 3799, 3833, 3836, 3351, 3842, 3845, 3828, 3362, 3840, 3835, 3821, 3836, 3820, 3837, 3842, 3829, 3827, 3836, 3820, 3362, 3843, 3804, 3836, 3839, 3815, 3833, 3817, 3843, 3348, 3843, 3823, 3809, 3842, 3837, 3842, 3826, 3846, 3835, 3832, 3816, 3829, 3842, 3830, 3842, 3815, 3813, 3841, 3839, 3827, 3818, 3362, 3356, 3845, 3354, 3342, 3846, 3837, 3767, 3826, 3840, 3842, 3823, 3840, 3815, 3841, 3842, 3824, 3802, 3845, 3829, 3853, 3831, 3803, 3832, 3834, 3828, 3813, 3843, 3841, 3356, 3813, 3351, 3845, 3841, 3831, 3833, 3825, 3835, 3834, 3816, 3832, 3835, 3828, 3842, 3828, 3352, 3837, 3828, 3357, 3805, 3835, 3813, 3807, 3357, 3836, 3833, 3814, 3833, 3824, 3819, 3841, 3810, 3839, 3831, 3819, 3842, 3840, 3834, 3836, 3829, 3829, 3826, 3821, 3823, 3817, 3807, 3836, 3840, 3838, 3843, 3836, 3835, 3825, 3817, 3830, 3837, 3820, 3812, 3838, 3843, 3843, 3835, 3848, 3843, 3836, 3843, 3825, 3843, 3804, 3818, 3361, 3815, 3842, 3828, 3833, 3841, 3834, 3815, 3846, 3823, 3827, 3842, 3811, 3844, 3358, 3351, 3836, 3837, 3848, 3831, 3830, 3362, 3829, 3825, 3823, 3847, 3843, 3841, 3831, 3838, 3843, 3822, 3822, 3842, 3838, 3849, 3834, 3840, 3817, 3814, 3849, 3825, 3842, 3357, 3838, 3825, 3831, 3822, 3840, 3823, 3362, 3841, 3837, 3843, 3825, 3823, 3835, 3844, 3799, 3356, 3843, 3827, 3846, 3844, 3349, 3500, 3842, 3842, 3812, 3847, 3845, 3352, 3843, 3838, 3843, 3828, 3843, 3353, 3834, 3825, 3836, 3842, 3847, 3832, 3817, 3845, 3811, 3837, 3820, 3831, 3833, 3829, 3841, 3836, 3834, 3817, 3842, 3806, 3802, 3845, 3802, 3847, 3842, 3835, 3839, 3853, 3841, 3833, 3836, 3822, 3834, 3818, 3842, 3838, 3843, 3835, 3807, 3840, 3816, 3837, 3843, 3839, 3851, 3847, 3842, 3833, 3843, 3831, 3842, 3370, 3821, 3842, 3851, 3807, 3818, 3838, 3849, 3809, 3845, 3362, 3844, 3840, 3841, 3358, 3844, 3841, 3837, 3843, 3843, 3351, 3836, 3817, 3845, 3822, 3837, 3834, 3834, 3350, 3353, 3838, 3834, 3845, 3842, 3836, 3843, 3840, 3825, 3840, 3811, 3831, 3842, 3834, 3857, 3819, 3829, 3846, 3817, 3836, 3843, 3845, 3845, 3834, 3830, 3844, 3841, 3838, 3840, 3816, 3843, 3843, 3839, 3829, 3845, 3828, 3838, 3835, 3825, 3837, 3845, 3827, 3825, 3846, 3841, 3811, 3827, 3829, 3844, 3822, 3833, 3839, 3816, 3842, 3836, 3824, 3354, 3846, 3798, 3834, 3810, 3811, 3830, 3833, 3845, 3821, 3825, 3840, 3816, 3832, 3840, 3836, 3829, 3845, 3840, 3813, 3347, 3839, 3808, 3364, 3839, 3816, 3362, 3808, 3814, 3826, 3838, 3822, 3588, 3842, 3850, 3829, 3841, 3839, 3830, 3841, 3840, 3844, 3821, 3833, 3836, 3353, 3839, 3836, 3836, 3820, 3822, 3836, 3813, 3839, 3843, 3842, 3846, 3362, 3746, 3821, 3811, 3830, 3841, 3815, 3352, 3825, 3816, 3832, 3841, 3828, 3839, 3833, 3845, 3823, 3821, 3836, 3814, 3822, 3839, 3362, 3831, 3843, 3840, 3817, 3844, 3812, 3823, 3834, 3833, 3832, 3828, 3843, 3838, 3831, 3814, 3842, 3813, 3838, 3824, 3834, 3831, 3844, 3845, 3838, 3837, 3823, 3842, 3835, 3822, 3825, 3840, 3836, 3850, 3829, 3842, 3814, 3823, 3829, 3833, 3845, 3820, 3824, 3776, 3836, 3846, 3832, 3830, 3826, 3824, 3836, 3840, 3818, 3828, 3825, 3840, 3839, 3840, 3353, 3830, 3846, 3829, 3360, 3850, 3840, 3842, 3814, 3820, 3832, 3835, 3835, 3842, 3826, 3437, 3827, 3833, 3820, 3817, 3835, 3845, 3820, 3848, 3843, 3849, 3842, 3840, 3804, 3847, 3844, 3624, 3842, 3826, 3827, 3841, 3844, 3804, 3811, 3837, 3844, 3839, 3820, 3826, 3821, 3807, 3835, 3838, 3834, 3835, 3825, 3804, 3847, 3818, 3844, 3831, 3828, 3826, 3830, 3836, 3837, 3820, 3841, 3835, 3839, 3839, 3820, 3831, 3841, 3819, 3851, 3841, 3830, 3836, 3832, 3805, 3814, 3838, 3826, 3840, 3820, 3840, 3842, 3835, 3842, 3840, 3829, 3832, 3837, 3843, 3843, 3828, 3840, 3362, 3834, 3833, 3829, 3844, 3818, 3351, 3835, 3812, 3837, 3842, 3847, 3843, 3845, 3822, 3348, 3838, 3832, 3836, 3833, 3833, 3846, 3836, 3835, 3842, 3837, 3844, 3831, 3822, 3835, 3811, 3835, 3824, 3351, 3819, 3835, 3836, 3818, 3829, 3816, 3840, 3840, 3845, 3844, 3837, 3835, 3833, 3827, 3842, 3818, 3832, 3808, 3835, 3834, 3840, 3818, 3837, 3846, 3820, 3842, 3840, 3840, 3843, 3839, 3816, 3839, 3828, 3835, 3617, 3812, 3832, 3840, 3362, 3838, 3350, 3842, 3821, 3842, 3836, 3839, 3837, 3840, 3841, 3842, 3802, 3838, 3842, 3844, 3835, 3831, 3817, 3839, 3836, 3840, 3822, 3818, 3828, 3837, 3844, 3842, 3811, 3833, 3807, 3801, 2916, 3846, 3807, 3828, 3842, 3836, 3357, 3841, 3362, 2917, 3848, 3818, 3834, 3845, 3839, 3838, 3845, 3371, 3828, 3843, 3824, 3840, 3812, 3847, 3814, 3833, 3814, 3831, 3825, 3843, 3821, 3811, 3832, 3830, 3843, 3817, 3844, 3825, 3826, 3843, 3841, 3326, 3847, 3834, 3835, 3816, 3837, 3829, 3839, 3831, 3838, 3841, 3836, 3844, 3838, 3841, 3615, 3840, 3843, 3830, 3805, 3779, 3842, 3816, 3837, 3820, 3839, 3832, 3827, 3818, 3832, 3845, 3816, 3834, 3844, 3839, 3838, 3835, 3842, 3846, 3833, 3833, 3826, 3817, 3843, 3813, 3841, 3831, 3831, 3844, 3833, 3819, 3818, 3842, 3819, 3839, 3834, 3816, 3844, 3843, 3835, 3851, 3841, 3831, 3838, 3833, 3831, 3840, 3834, 3843, 3840, 3830, 3801, 3840, 3844, 3834, 3832, 3810, 3841, 3836, 3830, 3847, 3843, 3824, 3843, 3819, 3841, 3846, 3846, 3841, 3831, 3845, 3840, 3838, 3838, 3844, 3360, 3845, 3829, 3846, 3834, 3831, 3821, 3814, 3843, 3843, 3838, 3817, 3814, 3828, 3835, 3362, 3835, 3091, 3844, 3832, 3840, 3828, 3845, 3838, 3819, 3836, 3846, 3815, 3362, 3838, 3815, 3829, 3362, 3827, 3351, 3840, 3830, 3845, 3835, 3844, 3828, 3813, 3800, 3847, 3833, 3830, 3833, 3841, 3833, 3841, 3848, 3362, 3840, 3823, 3827, 3843, 3838, 3834, 3814, 3842, 3822, 3825, 3827, 3350, 3842, 3814, 3841, 3840, 3827, 3823, 3838, 3826, 3833, 3836, 3357, 3347, 3852, 3838, 3832, 3834, 3845, 3841, 3823, 3844, 3830, 3829, 3842, 3352, 3836, 3812, 3837, 3805, 3828, 3810, 3824, 3844, 3846, 3362, 3826, 3818, 3822, 3832, 3845, 3811, 3362, 3358, 3842, 3831, 3834, 3848, 3843, 3841, 3828, 3828, 3829, 3834, 3839, 3829, 3810, 3839, 3833, 3359, 3835, 3842, 3356, 3828, 3830, 3824, 3812, 3837, 3821, 3811, 3839, 3355, 3836, 3822, 3804, 3820, 3821, 3848, 3838, 3843, 3837, 3844, 3826, 3825, 3821, 3831, 3830, 3362, 3840, 3831, 3843, 3825, 3842, 3837, 3830, 3813, 3842, 3826, 3843, 3828, 3843, 3841, 3825, 3805, 3842, 3846, 3843, 3824, 3838, 3823, 3362, 3831, 3837, 3842, 3814, 3836, 3835, 3843, 3827, 3834, 3837, 3357, 3820, 3839, 3847, 3839, 3830, 3843, 3828, 3841, 3818, 3840, 3842, 3841, 3834, 3787, 3841, 3828, 3843, 3843, 3832, 3831, 3838, 3844, 3839, 3821, 3842, 3808, 3844, 3837, 3837, 3833, 3843, 3837, 3825, 3834, 3823, 3841, 3838, 3842, 3845, 3843, 3820, 3811, 3822, 3832, 3843, 3842, 3830, 3843, 3848, 3833, 3841, 3844, 3835, 3357, 3840, 3844, 3840, 3826, 3834, 3813, 3832, 3838, 3844, 3831, 3364, 3835, 3836, 3835, 3358, 3841, 3842, 3835, 3352, 3845, 3359, 3820, 3846, 3837, 3817, 3358, 3840, 3842, 3830, 3840, 3845, 3850, 3842, 3818, 3832, 3814, 3843, 3832, 3816, 3361, 3843, 3814, 3845, 3809, 3816, 3845, 3830, 3835, 3852, 3842, 3845, 3831, 3830, 3362, 3842, 3846, 3836, 3831, 3843, 3839, 3830, 3359, 3838, 3820, 3831, 3846, 3831, 3830, 3838, 3842, 3765, 3825, 3804, 3839, 3833, 3843, 3825, 3837, 3837, 3837, 3835, 3844, 3822, 3827, 3844, 3808, 3828, 3368, 3355, 3819, 3348, 3848, 3832, 3828, 3815, 3800, 3832, 3828, 3843, 3813, 3838, 3844, 3840, 3821, 3844, 3832, 3841, 3803, 3803, 3846, 3819, 3828, 3838, 3838, 3831, 3803, 3359, 3845, 3830, 3823, 3830, 3843, 3845, 3846, 3842, 3815, 3842, 3842, 3843, 3833, 3814, 3831, 3846, 3845, 3845, 3830, 3809, 3808, 3846, 3831, 3839, 3842, 3841, 3843, 3843, 3800, 3848, 3816, 3828, 3840, 3844, 3836, 3830, 3836, 3851, 3840, 3824, 3831, 3831, 3841, 3841, 3843, 3826, 3843, 3814, 3843, 3833, 3840, 3844, 3818, 3830, 3845, 3838, 3840, 3810, 3843, 3826, 3843, 3818, 3841, 3841, 3836, 3812, 3353, 3836, 3817, 3837, 3833, 3831, 3850, 3842, 3823, 3834, 3839, 3839, 3822, 3832, 3843, 3843, 3845, 3844, 3837, 3824, 3841, 3835, 3838, 3834, 3811, 3844, 3830, 3817, 3843, 3842, 3831, 3816, 3846, 3811, 3836, 3840, 3836, 3842, 3841, 3833, 3843, 3839, 3812, 3840, 3818, 3840, 3835, 3833, 3844, 3844, 3843, 3813, 3846, 3838, 3839, 3846, 3833, 3842, 3829, 3843, 3362, 3835, 3819, 3844, 3809, 3367, 3346, 3845, 3845, 3844, 3824, 3829, 3828, 3847, 3843, 3831, 3833, 3823, 3829, 3840, 3840, 3836, 3841, 3808, 3830, 3839, 3847, 3841, 3813, 3362, 3828, 3836, 3824, 3816, 3845, 3830, 3810, 3823, 3751, 3845, 3826, 3819, 3828, 3815, 3830, 3813, 3843, 3814, 3847, 3845, 3842, 3842, 3843, 3843, 3845, 3808, 3841, 3354, 3369, 3838, 3839, 3804, 3813, 3847, 3827, 3840, 3811, 3831, 3836, 3843, 3841, 3822, 3813, 3833, 3849, 3835, 3826, 3842, 3836, 3843, 3816, 3841, 3829, 3840, 3829, 3358, 3817, 3823, 3802, 3843, 3836, 3843, 3844, 3843, 3828, 3841, 3833, 3838, 3805, 3818, 3825, 3842, 3836, 3823, 3829, 3847, 3843, 3824, 3844, 3353, 3829, 3809, 3844, 3833, 3828, 3824, 3819, 3836, 3843, 3816, 3841, 3844, 3843, 3833, 3841, 3838, 3836, 3830, 3832, 3830, 3844, 3831, 3362, 3845, 3358, 3828, 3370, 3845, 3834, 3826, 3819, 3848, 3839, 3837, 3814, 3836, 3841, 3842, 3847, 3839, 3820, 3807, 3843, 3806, 3361, 3837, 3828, 3820, 3845, 3352, 3349, 3824, 3833, 3833, 3837, 3806, 3839, 3615, 3817, 3813, 3805, 3840, 3842, 3805, 3833, 3846, 3835, 3841, 3844, 3841, 3840, 3807, 3807, 3842, 3830, 3834, 3838, 3778, 3838, 3804, 3833, 3355, 3834, 3837, 3839, 3843, 3846, 3841, 3833, 3823, 3819, 3837, 3822, 3811, 3810, 3821, 3816, 3814, 3846, 3839, 3843, 3358, 3815, 3804, 3839, 3831, 3816, 3812, 3821, 3846, 3828, 3839, 3842, 3840, 3829, 3361, 3835, 3826, 3819, 3830, 3827, 3831, 3840, 3836, 3846, 3826, 3511, 3842, 3841, 3831, 3842, 3823, 3818, 3829, 3838, 3844, 3816, 3827, 3846, 3842, 3841, 3828, 3840, 3838, 3831, 3847, 3841, 3826, 3843, 3838, 3826, 3843, 3840, 3810, 3828, 3820, 3840, 3835, 3838, 3841, 3844, 3825, 3819, 3834, 3834, 3838, 3833, 3839, 3362, 3843, 3832, 3817, 3845, 3841, 3831, 3814, 3842, 3818, 3815, 3358, 3843, 3837, 3832, 3358, 3814, 3837, 3356, 3839, 3830, 3846, 3811, 3851, 3351, 3842, 3833, 3825, 3815, 3834, 3810, 3835, 3838, 3826, 3835, 3835, 3831, 3845, 3814, 3829, 3841, 3834, 3806, 3834, 3360, 3806, 3848, 3817, 3827, 3803, 3831, 3834, 3845, 3847, 3822, 3845, 3843, 3836, 3835, 3818, 3840, 3833, 3817, 3849, 3841, 3847, 3828, 3803, 3813, 3841, 3826, 3357, 3824, 3836, 3843, 3841, 3845, 3837, 3814, 3822, 3851, 3821, 3832, 3355, 3829, 3823, 3842, 3837, 3844, 3823, 3842, 3821, 3819, 3598, 3838, 3818, 3825, 3839, 3830, 3812, 3826, 3831, 3844, 3841, 3822, 3835, 3836, 3827, 3830, 3822, 3359, 3847, 3827, 3831, 3834, 3842, 3818, 3347, 3846, 3835, 3844, 3827, 3830, 3829, 3845, 3807, 3835, 3842, 3833, 3844, 3841, 3838, 3833, 3840, 3842, 3844, 3822, 3810, 3818, 3807, 3839, 3822, 3846, 3843, 3833, 3838, 3836, 3844, 3822, 3822, 3842, 3845, 3840, 3830, 3836, 3817, 3839, 3839, 3837, 3843, 3834, 3849, 3834, 3853, 3838, 3803, 3843, 3841, 3842, 3839, 3831, 3820, 3829, 3841, 3842, 3846, 3836, 3843, 3840, 3836, 3839, 3357, 3807, 3833, 3846, 3845, 3836, 3820, 3817, 3841, 3840, 3843, 3844, 3825, 3830, 3831, 3836, 3841, 3840, 3841, 3837, 3818, 3814, 3842, 3835, 3845, 3827, 3348, 3843, 3803, 3842, 3839, 3807, 3839, 3810, 3855, 3843, 3821, 3849, 3835, 3819, 3832, 3822, 3838, 3836, 3836, 3842, 3814, 3830, 3823, 3838, 3832, 3826, 3351, 3824, 3849, 3843, 3842, 3842, 3827, 3832, 3836, 3833, 3830, 3841, 3841, 3833, 3822, 3821, 3845, 3832, 3838, 3840, 3354, 3845, 3823, 3842, 3844, 3839, 3838, 3841, 3815, 3815, 3846, 3837, 3823, 3802, 3842, 3847, 3836, 3845, 3843, 3819, 3841, 3821, 3840, 3830, 3819, 3845, 3838, 3819, 3826, 3818, 3840, 3840, 3833, 3826, 3830, 3830, 3845, 3847, 3824, 3838, 3822, 3841, 3838, 3842, 3836, 3838, 3835, 3837, 3819, 3847, 3827, 3834, 3814, 2919, 3840, 3840, 3840, 3846, 3834, 3827, 3838, 3820, 3843, 3823, 3842, 3832, 3843, 3795, 3846, 3841, 3832, 3835, 3823, 3825, 3838, 3840, 3353, 3819, 3843, 3824, 3823, 3837, 3840, 3831, 3358, 3838, 3837, 3816, 3814, 3830, 3816, 3828, 3836, 3845, 3840, 3838, 3843, 3845, 3831, 3843, 3810, 3848, 3830, 3825, 3819, 3825, 3840, 3804, 3841, 3834, 3828, 3841, 3844, 3826, 3831, 3840, 3838, 3842, 3842, 3818, 3844, 3831, 3807, 3840, 3834, 3835, 3825, 3839, 3826, 3823, 3803, 3826, 3822, 3824, 3838, 3841, 3824, 3846, 3837, 3842, 3837, 3349, 3819, 3846, 3833, 3822, 3829, 3841, 3840, 3349, 3834, 3812, 3840, 3841, 3842, 3842, 3846, 3835, 3810, 3847, 3831, 3837, 3841, 3813, 3816, 3834, 3351, 3843, 3832, 3844, 3849, 3841, 3841, 3839, 3838, 3840, 3819, 3838, 3351, 3817, 3838, 3803, 3824, 3809, 3830, 3808, 3804, 3810, 3843, 3848, 3836, 3843, 3821, 3843, 3839, 3836, 3852, 3837, 3829, 3829, 3818, 3838, 3849, 3351, 3814, 3824, 3833, 3350, 3840, 3842, 3831, 3362, 3839, 3819, 3818, 3828, 3834, 3838, 3842, 3849, 3846, 3846, 3843, 3846, 3838, 3809, 3814, 3840, 3838, 3352, 3841, 3843, 3805, 3843, 3834, 3829, 3822, 3828, 3811, 3838, 3845, 3837, 3845, 3826, 3850, 3827, 3840, 3826, 3840, 3822, 3844, 3353, 3813, 3829, 3837, 3835, 3349, 3834, 3837, 3825, 3371, 3830, 3838, 3844, 3840, 3834, 3843, 3838, 3841, 3833, 3836, 3842, 3834, 3836, 3820, 3826, 3813, 3819, 3840, 3846, 3832, 3825, 3842, 3838, 3830, 3844, 3830, 3837, 3847, 3837, 3825, 3350, 3837, 3842, 3827, 3842, 3835, 3840, 3843, 3844, 3846, 3845, 3826, 3841, 3839, 3829, 3840, 3836, 3836, 3844, 3838, 3359, 3817, 3844, 3824, 3832, 3815, 3819, 3853, 3839, 3841, 3835, 3835, 3842, 3821, 3837, 3826, 3841, 3814, 3823, 3827, 3808, 3828, 3837, 3841, 3845, 3833, 3823, 3822, 3841, 3811, 3841, 3840, 3844, 3825, 3835, 3362, 3825, 3843, 3844, 3829, 3843, 3825, 3831, 3823, 3836, 3839, 3842, 3845, 3835, 3833, 3839, 3834, 3819, 3838, 3841, 3843, 3838, 3820, 3358, 3834, 3836, 3355, 3844, 3827, 3839, 3818, 3831, 3826, 3820, 3816, 3843, 3834, 3829, 3348, 3818, 3832, 3844, 3827, 3830, 3352, 3351, 3841, 3842, 3827, 3840, 3803, 3815, 3817, 3823, 3827, 3838, 3830, 3844, 3842, 3830, 3838, 3354, 3835, 3831, 3846, 3841, 3844, 3839, 3840, 3830, 3843, 3349, 3842, 3844, 3815, 3802, 3842, 3840, 3829, 3827, 3838, 3830, 3833, 3836, 3828, 3815, 3846, 3835, 3819, 3827, 3362, 3818, 3840, 3844, 3832, 3840, 3844, 3841, 3831, 3830, 3837, 3845, 3841, 3830, 3840, 3842, 3836, 3842, 3818, 3766, 3831, 3836, 3806, 3840, 3829, 3824, 3841, 3847, 3822, 3831, 3842, 3842, 3839, 3845, 3830, 3842, 3843, 3837, 3835, 3824, 3834, 3848, 3849, 3828, 3838, 3815, 3839, 3838, 3815, 3838, 3843, 3809, 3835, 3822, 3835, 3834, 3845, 3818, 3842, 3827, 3841, 3846, 3827, 3841, 3839, 3831, 3845, 3836, 3808, 3838, 3829, 3361, 3844, 3841, 3828, 3829, 3371, 3842, 3824, 3834, 3803, 3828, 3845, 3845, 3807, 3361, 3843, 3843, 3840, 3853, 3815, 3829, 3841, 3813, 3835, 3818, 3826, 3836, 3804, 3845, 3813, 3811, 3841, 3830, 3827, 3843, 3840, 3841, 3845, 3845, 3825, 3839, 3845, 3829, 3827, 3831, 3841, 3805, 3840, 3842, 3349, 3843, 3850, 3819, 3812, 3842, 3818, 3836, 3832, 3823, 3830, 3828, 3810, 3841, 3397, 3829, 3839, 3840, 3815, 3820, 3854, 3822, 3834, 3842, 3846, 3845, 3840, 3825, 3354, 3842, 3841, 3846, 3268, 3838, 3852, 3837, 3808, 3844, 3837, 3816, 3838, 3829, 3810, 3842, 3841, 3829, 3825, 3845, 3842, 3840, 3362, 3362, 3838, 3816, 3839, 3826, 3838, 3828, 3844, 3820, 3364, 3844, 3837, 3830, 3822, 3842, 3836, 3845, 3840, 3839, 3352, 3362, 3803, 3846, 3816, 3817, 3833, 3845, 3841, 3822, 3357, 3840, 3844, 3823, 3840, 3841, 3839, 3834, 3843, 3813, 3811, 3814, 3823, 3838, 3844, 3840, 3345, 3352, 3836, 3818, 3804, 3846, 3839, 3817, 3822, 3847, 3827, 3828, 3841, 3490\n  y sizes: 11100\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "resnet_model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb66e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cdd41bba00>,\n",
       " <matplotlib.lines.Line2D at 0x1cdd41ab910>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0995ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9908fbd2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU use: 4\n",
      "Use TF keras...\n",
      "Model 1D: resnet18 Mem single: 0.06\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000_no_top.h5\n",
      "44920640/44920640 [==============================] - 8s 0us/step\n",
      "Model 2D: resnet18 Mem single: 0.09\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [10]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [11]: Conv2D stage1_unit1_conv1\n",
      "Set for [11]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [13]: Activation stage1_unit1_relu2\n",
      "Set for [13]: Activation stage1_unit1_relu2\n",
      "Extract for [14]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [14]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [15]: Conv2D stage1_unit1_conv2\n",
      "Set for [15]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [16]: Conv2D stage1_unit1_sc\n",
      "Set for [16]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [17]: Add add_8\n",
      "Set for [17]: Add add\n",
      "Warning: different names!\n",
      "Extract for [18]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [18]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [19]: Activation stage1_unit2_relu1\n",
      "Set for [19]: Activation stage1_unit2_relu1\n",
      "Extract for [20]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [20]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [21]: Conv2D stage1_unit2_conv1\n",
      "Set for [21]: Conv1D stage1_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [22]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [22]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [23]: Activation stage1_unit2_relu2\n",
      "Set for [23]: Activation stage1_unit2_relu2\n",
      "Extract for [24]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [24]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [25]: Conv2D stage1_unit2_conv2\n",
      "Set for [25]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [26]: Add add_9\n",
      "Set for [26]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [27]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [27]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [28]: Activation stage2_unit1_relu1\n",
      "Set for [28]: Activation stage2_unit1_relu1\n",
      "Extract for [29]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [29]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [30]: Conv2D stage2_unit1_conv1\n",
      "Set for [30]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 128) (3, 64, 128)\n",
      "Extract for [31]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [31]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [32]: Activation stage2_unit1_relu2\n",
      "Set for [32]: Activation stage2_unit1_relu2\n",
      "Extract for [33]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [33]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n",
      "Extract for [34]: Conv2D stage2_unit1_conv2\n",
      "Set for [34]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [35]: Conv2D stage2_unit1_sc\n",
      "Set for [35]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 128) (1, 64, 128)\n",
      "Extract for [36]: Add add_10\n",
      "Set for [36]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [37]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [37]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [38]: Activation stage2_unit2_relu1\n",
      "Set for [38]: Activation stage2_unit2_relu1\n",
      "Extract for [39]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [39]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [40]: Conv2D stage2_unit2_conv1\n",
      "Set for [40]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [41]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [41]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [42]: Activation stage2_unit2_relu2\n",
      "Set for [42]: Activation stage2_unit2_relu2\n",
      "Extract for [43]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [43]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [44]: Conv2D stage2_unit2_conv2\n",
      "Set for [44]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [45]: Add add_11\n",
      "Set for [45]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [46]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [46]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [47]: Activation stage3_unit1_relu1\n",
      "Set for [47]: Activation stage3_unit1_relu1\n",
      "Extract for [48]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [48]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [49]: Conv2D stage3_unit1_conv1\n",
      "Set for [49]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 256) (3, 128, 256)\n",
      "Extract for [50]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [50]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [51]: Activation stage3_unit1_relu2\n",
      "Set for [51]: Activation stage3_unit1_relu2\n",
      "Extract for [52]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [52]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [53]: Conv2D stage3_unit1_conv2\n",
      "Set for [53]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [54]: Conv2D stage3_unit1_sc\n",
      "Set for [54]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 128, 256) (1, 128, 256)\n",
      "Extract for [55]: Add add_12\n",
      "Set for [55]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [56]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [56]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [57]: Activation stage3_unit2_relu1\n",
      "Set for [57]: Activation stage3_unit2_relu1\n",
      "Extract for [58]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [58]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [59]: Conv2D stage3_unit2_conv1\n",
      "Set for [59]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [60]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [60]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [61]: Activation stage3_unit2_relu2\n",
      "Set for [61]: Activation stage3_unit2_relu2\n",
      "Extract for [62]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [62]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [63]: Conv2D stage3_unit2_conv2\n",
      "Set for [63]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [64]: Add add_13\n",
      "Set for [64]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [65]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [65]: BatchNormalization stage4_unit1_bn1\n",
      "Extract for [66]: Activation stage4_unit1_relu1\n",
      "Set for [66]: Activation stage4_unit1_relu1\n",
      "Extract for [67]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [67]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [68]: Conv2D stage4_unit1_conv1\n",
      "Set for [68]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 512) (3, 256, 512)\n",
      "Extract for [69]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [69]: BatchNormalization stage4_unit1_bn2\n",
      "Extract for [70]: Activation stage4_unit1_relu2\n",
      "Set for [70]: Activation stage4_unit1_relu2\n",
      "Extract for [71]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [71]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [72]: Conv2D stage4_unit1_conv2\n",
      "Set for [72]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [73]: Conv2D stage4_unit1_sc\n",
      "Set for [73]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n",
      "Extract for [74]: Add add_14\n",
      "Set for [74]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [75]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [75]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [76]: Activation stage4_unit2_relu1\n",
      "Set for [76]: Activation stage4_unit2_relu1\n",
      "Extract for [77]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [77]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [78]: Conv2D stage4_unit2_conv1\n",
      "Set for [78]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [79]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [79]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [80]: Activation stage4_unit2_relu2\n",
      "Set for [80]: Activation stage4_unit2_relu2\n",
      "Extract for [81]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [81]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [82]: Conv2D stage4_unit2_conv2\n",
      "Set for [82]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [83]: Add add_15\n",
      "Set for [83]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [84]: BatchNormalization bn1\n",
      "Set for [84]: BatchNormalization bn1\n",
      "Extract for [85]: Activation relu1\n",
      "Set for [85]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model 1D: resnet34 Mem single: 0.09\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n",
      "85521592/85521592 [==============================] - 20s 0us/step\n",
      "Model 2D: resnet34 Mem single: 0.15\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [10]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [11]: Conv2D stage1_unit1_conv1\n",
      "Set for [11]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [13]: Activation stage1_unit1_relu2\n",
      "Set for [13]: Activation stage1_unit1_relu2\n",
      "Extract for [14]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [14]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [15]: Conv2D stage1_unit1_conv2\n",
      "Set for [15]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [16]: Conv2D stage1_unit1_sc\n",
      "Set for [16]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [17]: Add add_16\n",
      "Set for [17]: Add add\n",
      "Warning: different names!\n",
      "Extract for [18]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [18]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [19]: Activation stage1_unit2_relu1\n",
      "Set for [19]: Activation stage1_unit2_relu1\n",
      "Extract for [20]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [20]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [21]: Conv2D stage1_unit2_conv1\n",
      "Set for [21]: Conv1D stage1_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [22]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [22]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [23]: Activation stage1_unit2_relu2\n",
      "Set for [23]: Activation stage1_unit2_relu2\n",
      "Extract for [24]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [24]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [25]: Conv2D stage1_unit2_conv2\n",
      "Set for [25]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [26]: Add add_17\n",
      "Set for [26]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [27]: BatchNormalization stage1_unit3_bn1\n",
      "Set for [27]: BatchNormalization stage1_unit3_bn1\n",
      "Extract for [28]: Activation stage1_unit3_relu1\n",
      "Set for [28]: Activation stage1_unit3_relu1\n",
      "Extract for [29]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [29]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [30]: Conv2D stage1_unit3_conv1\n",
      "Set for [30]: Conv1D stage1_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [31]: BatchNormalization stage1_unit3_bn2\n",
      "Set for [31]: BatchNormalization stage1_unit3_bn2\n",
      "Extract for [32]: Activation stage1_unit3_relu2\n",
      "Set for [32]: Activation stage1_unit3_relu2\n",
      "Extract for [33]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [33]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n",
      "Extract for [34]: Conv2D stage1_unit3_conv2\n",
      "Set for [34]: Conv1D stage1_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [35]: Add add_18\n",
      "Set for [35]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [36]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [36]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [37]: Activation stage2_unit1_relu1\n",
      "Set for [37]: Activation stage2_unit1_relu1\n",
      "Extract for [38]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [38]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [39]: Conv2D stage2_unit1_conv1\n",
      "Set for [39]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 128) (3, 64, 128)\n",
      "Extract for [40]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [40]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [41]: Activation stage2_unit1_relu2\n",
      "Set for [41]: Activation stage2_unit1_relu2\n",
      "Extract for [42]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [42]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [43]: Conv2D stage2_unit1_conv2\n",
      "Set for [43]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [44]: Conv2D stage2_unit1_sc\n",
      "Set for [44]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 128) (1, 64, 128)\n",
      "Extract for [45]: Add add_19\n",
      "Set for [45]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [46]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [46]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [47]: Activation stage2_unit2_relu1\n",
      "Set for [47]: Activation stage2_unit2_relu1\n",
      "Extract for [48]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [48]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [49]: Conv2D stage2_unit2_conv1\n",
      "Set for [49]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [50]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [50]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [51]: Activation stage2_unit2_relu2\n",
      "Set for [51]: Activation stage2_unit2_relu2\n",
      "Extract for [52]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [52]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [53]: Conv2D stage2_unit2_conv2\n",
      "Set for [53]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [54]: Add add_20\n",
      "Set for [54]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [55]: BatchNormalization stage2_unit3_bn1\n",
      "Set for [55]: BatchNormalization stage2_unit3_bn1\n",
      "Extract for [56]: Activation stage2_unit3_relu1\n",
      "Set for [56]: Activation stage2_unit3_relu1\n",
      "Extract for [57]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [57]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [58]: Conv2D stage2_unit3_conv1\n",
      "Set for [58]: Conv1D stage2_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [59]: BatchNormalization stage2_unit3_bn2\n",
      "Set for [59]: BatchNormalization stage2_unit3_bn2\n",
      "Extract for [60]: Activation stage2_unit3_relu2\n",
      "Set for [60]: Activation stage2_unit3_relu2\n",
      "Extract for [61]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [61]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [62]: Conv2D stage2_unit3_conv2\n",
      "Set for [62]: Conv1D stage2_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [63]: Add add_21\n",
      "Set for [63]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [64]: BatchNormalization stage2_unit4_bn1\n",
      "Set for [64]: BatchNormalization stage2_unit4_bn1\n",
      "Extract for [65]: Activation stage2_unit4_relu1\n",
      "Set for [65]: Activation stage2_unit4_relu1\n",
      "Extract for [66]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [66]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [67]: Conv2D stage2_unit4_conv1\n",
      "Set for [67]: Conv1D stage2_unit4_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [68]: BatchNormalization stage2_unit4_bn2\n",
      "Set for [68]: BatchNormalization stage2_unit4_bn2\n",
      "Extract for [69]: Activation stage2_unit4_relu2\n",
      "Set for [69]: Activation stage2_unit4_relu2\n",
      "Extract for [70]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [70]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [71]: Conv2D stage2_unit4_conv2\n",
      "Set for [71]: Conv1D stage2_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [72]: Add add_22\n",
      "Set for [72]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [73]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [73]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [74]: Activation stage3_unit1_relu1\n",
      "Set for [74]: Activation stage3_unit1_relu1\n",
      "Extract for [75]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [75]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [76]: Conv2D stage3_unit1_conv1\n",
      "Set for [76]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 256) (3, 128, 256)\n",
      "Extract for [77]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [77]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [78]: Activation stage3_unit1_relu2\n",
      "Set for [78]: Activation stage3_unit1_relu2\n",
      "Extract for [79]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [79]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [80]: Conv2D stage3_unit1_conv2\n",
      "Set for [80]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [81]: Conv2D stage3_unit1_sc\n",
      "Set for [81]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 128, 256) (1, 128, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [82]: Add add_23\n",
      "Set for [82]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [83]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [83]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [84]: Activation stage3_unit2_relu1\n",
      "Set for [84]: Activation stage3_unit2_relu1\n",
      "Extract for [85]: ZeroPadding2D zero_padding2d_18\n",
      "Set for [85]: ZeroPadding1D zero_padding1d_18\n",
      "Warning: different names!\n",
      "Extract for [86]: Conv2D stage3_unit2_conv1\n",
      "Set for [86]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [87]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [87]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [88]: Activation stage3_unit2_relu2\n",
      "Set for [88]: Activation stage3_unit2_relu2\n",
      "Extract for [89]: ZeroPadding2D zero_padding2d_19\n",
      "Set for [89]: ZeroPadding1D zero_padding1d_19\n",
      "Warning: different names!\n",
      "Extract for [90]: Conv2D stage3_unit2_conv2\n",
      "Set for [90]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [91]: Add add_24\n",
      "Set for [91]: Add add_8\n",
      "Warning: different names!\n",
      "Extract for [92]: BatchNormalization stage3_unit3_bn1\n",
      "Set for [92]: BatchNormalization stage3_unit3_bn1\n",
      "Extract for [93]: Activation stage3_unit3_relu1\n",
      "Set for [93]: Activation stage3_unit3_relu1\n",
      "Extract for [94]: ZeroPadding2D zero_padding2d_20\n",
      "Set for [94]: ZeroPadding1D zero_padding1d_20\n",
      "Warning: different names!\n",
      "Extract for [95]: Conv2D stage3_unit3_conv1\n",
      "Set for [95]: Conv1D stage3_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [96]: BatchNormalization stage3_unit3_bn2\n",
      "Set for [96]: BatchNormalization stage3_unit3_bn2\n",
      "Extract for [97]: Activation stage3_unit3_relu2\n",
      "Set for [97]: Activation stage3_unit3_relu2\n",
      "Extract for [98]: ZeroPadding2D zero_padding2d_21\n",
      "Set for [98]: ZeroPadding1D zero_padding1d_21\n",
      "Warning: different names!\n",
      "Extract for [99]: Conv2D stage3_unit3_conv2\n",
      "Set for [99]: Conv1D stage3_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [100]: Add add_25\n",
      "Set for [100]: Add add_9\n",
      "Warning: different names!\n",
      "Extract for [101]: BatchNormalization stage3_unit4_bn1\n",
      "Set for [101]: BatchNormalization stage3_unit4_bn1\n",
      "Extract for [102]: Activation stage3_unit4_relu1\n",
      "Set for [102]: Activation stage3_unit4_relu1\n",
      "Extract for [103]: ZeroPadding2D zero_padding2d_22\n",
      "Set for [103]: ZeroPadding1D zero_padding1d_22\n",
      "Warning: different names!\n",
      "Extract for [104]: Conv2D stage3_unit4_conv1\n",
      "Set for [104]: Conv1D stage3_unit4_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [105]: BatchNormalization stage3_unit4_bn2\n",
      "Set for [105]: BatchNormalization stage3_unit4_bn2\n",
      "Extract for [106]: Activation stage3_unit4_relu2\n",
      "Set for [106]: Activation stage3_unit4_relu2\n",
      "Extract for [107]: ZeroPadding2D zero_padding2d_23\n",
      "Set for [107]: ZeroPadding1D zero_padding1d_23\n",
      "Warning: different names!\n",
      "Extract for [108]: Conv2D stage3_unit4_conv2\n",
      "Set for [108]: Conv1D stage3_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [109]: Add add_26\n",
      "Set for [109]: Add add_10\n",
      "Warning: different names!\n",
      "Extract for [110]: BatchNormalization stage3_unit5_bn1\n",
      "Set for [110]: BatchNormalization stage3_unit5_bn1\n",
      "Extract for [111]: Activation stage3_unit5_relu1\n",
      "Set for [111]: Activation stage3_unit5_relu1\n",
      "Extract for [112]: ZeroPadding2D zero_padding2d_24\n",
      "Set for [112]: ZeroPadding1D zero_padding1d_24\n",
      "Warning: different names!\n",
      "Extract for [113]: Conv2D stage3_unit5_conv1\n",
      "Set for [113]: Conv1D stage3_unit5_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [114]: BatchNormalization stage3_unit5_bn2\n",
      "Set for [114]: BatchNormalization stage3_unit5_bn2\n",
      "Extract for [115]: Activation stage3_unit5_relu2\n",
      "Set for [115]: Activation stage3_unit5_relu2\n",
      "Extract for [116]: ZeroPadding2D zero_padding2d_25\n",
      "Set for [116]: ZeroPadding1D zero_padding1d_25\n",
      "Warning: different names!\n",
      "Extract for [117]: Conv2D stage3_unit5_conv2\n",
      "Set for [117]: Conv1D stage3_unit5_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [118]: Add add_27\n",
      "Set for [118]: Add add_11\n",
      "Warning: different names!\n",
      "Extract for [119]: BatchNormalization stage3_unit6_bn1\n",
      "Set for [119]: BatchNormalization stage3_unit6_bn1\n",
      "Extract for [120]: Activation stage3_unit6_relu1\n",
      "Set for [120]: Activation stage3_unit6_relu1\n",
      "Extract for [121]: ZeroPadding2D zero_padding2d_26\n",
      "Set for [121]: ZeroPadding1D zero_padding1d_26\n",
      "Warning: different names!\n",
      "Extract for [122]: Conv2D stage3_unit6_conv1\n",
      "Set for [122]: Conv1D stage3_unit6_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [123]: BatchNormalization stage3_unit6_bn2\n",
      "Set for [123]: BatchNormalization stage3_unit6_bn2\n",
      "Extract for [124]: Activation stage3_unit6_relu2\n",
      "Set for [124]: Activation stage3_unit6_relu2\n",
      "Extract for [125]: ZeroPadding2D zero_padding2d_27\n",
      "Set for [125]: ZeroPadding1D zero_padding1d_27\n",
      "Warning: different names!\n",
      "Extract for [126]: Conv2D stage3_unit6_conv2\n",
      "Set for [126]: Conv1D stage3_unit6_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [127]: Add add_28\n",
      "Set for [127]: Add add_12\n",
      "Warning: different names!\n",
      "Extract for [128]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [128]: BatchNormalization stage4_unit1_bn1\n",
      "Extract for [129]: Activation stage4_unit1_relu1\n",
      "Set for [129]: Activation stage4_unit1_relu1\n",
      "Extract for [130]: ZeroPadding2D zero_padding2d_28\n",
      "Set for [130]: ZeroPadding1D zero_padding1d_28\n",
      "Warning: different names!\n",
      "Extract for [131]: Conv2D stage4_unit1_conv1\n",
      "Set for [131]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 512) (3, 256, 512)\n",
      "Extract for [132]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [132]: BatchNormalization stage4_unit1_bn2\n",
      "Extract for [133]: Activation stage4_unit1_relu2\n",
      "Set for [133]: Activation stage4_unit1_relu2\n",
      "Extract for [134]: ZeroPadding2D zero_padding2d_29\n",
      "Set for [134]: ZeroPadding1D zero_padding1d_29\n",
      "Warning: different names!\n",
      "Extract for [135]: Conv2D stage4_unit1_conv2\n",
      "Set for [135]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [136]: Conv2D stage4_unit1_sc\n",
      "Set for [136]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n",
      "Extract for [137]: Add add_29\n",
      "Set for [137]: Add add_13\n",
      "Warning: different names!\n",
      "Extract for [138]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [138]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [139]: Activation stage4_unit2_relu1\n",
      "Set for [139]: Activation stage4_unit2_relu1\n",
      "Extract for [140]: ZeroPadding2D zero_padding2d_30\n",
      "Set for [140]: ZeroPadding1D zero_padding1d_30\n",
      "Warning: different names!\n",
      "Extract for [141]: Conv2D stage4_unit2_conv1\n",
      "Set for [141]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [142]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [142]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [143]: Activation stage4_unit2_relu2\n",
      "Set for [143]: Activation stage4_unit2_relu2\n",
      "Extract for [144]: ZeroPadding2D zero_padding2d_31\n",
      "Set for [144]: ZeroPadding1D zero_padding1d_31\n",
      "Warning: different names!\n",
      "Extract for [145]: Conv2D stage4_unit2_conv2\n",
      "Set for [145]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [146]: Add add_30\n",
      "Set for [146]: Add add_14\n",
      "Warning: different names!\n",
      "Extract for [147]: BatchNormalization stage4_unit3_bn1\n",
      "Set for [147]: BatchNormalization stage4_unit3_bn1\n",
      "Extract for [148]: Activation stage4_unit3_relu1\n",
      "Set for [148]: Activation stage4_unit3_relu1\n",
      "Extract for [149]: ZeroPadding2D zero_padding2d_32\n",
      "Set for [149]: ZeroPadding1D zero_padding1d_32\n",
      "Warning: different names!\n",
      "Extract for [150]: Conv2D stage4_unit3_conv1\n",
      "Set for [150]: Conv1D stage4_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [151]: BatchNormalization stage4_unit3_bn2\n",
      "Set for [151]: BatchNormalization stage4_unit3_bn2\n",
      "Extract for [152]: Activation stage4_unit3_relu2\n",
      "Set for [152]: Activation stage4_unit3_relu2\n",
      "Extract for [153]: ZeroPadding2D zero_padding2d_33\n",
      "Set for [153]: ZeroPadding1D zero_padding1d_33\n",
      "Warning: different names!\n",
      "Extract for [154]: Conv2D stage4_unit3_conv2\n",
      "Set for [154]: Conv1D stage4_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [155]: Add add_31\n",
      "Set for [155]: Add add_15\n",
      "Warning: different names!\n",
      "Extract for [156]: BatchNormalization bn1\n",
      "Set for [156]: BatchNormalization bn1\n",
      "Extract for [157]: Activation relu1\n",
      "Set for [157]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1D: resnet50 Mem single: 0.21\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000_no_top.h5\n",
      "94592056/94592056 [==============================] - 16s 0us/step\n",
      "Model 2D: resnet50 Mem single: 0.24\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: Conv2D stage1_unit1_conv1\n",
      "Set for [10]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [11]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [11]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [12]: Activation stage1_unit1_relu2\n",
      "Set for [12]: Activation stage1_unit1_relu2\n",
      "Extract for [13]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [13]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [14]: Conv2D stage1_unit1_conv2\n",
      "Set for [14]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [15]: BatchNormalization stage1_unit1_bn3\n",
      "Set for [15]: BatchNormalization stage1_unit1_bn3\n",
      "Extract for [16]: Activation stage1_unit1_relu3\n",
      "Set for [16]: Activation stage1_unit1_relu3\n",
      "Extract for [17]: Conv2D stage1_unit1_conv3\n",
      "Set for [17]: Conv1D stage1_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [18]: Conv2D stage1_unit1_sc\n",
      "Set for [18]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [19]: Add add_16\n",
      "Set for [19]: Add add\n",
      "Warning: different names!\n",
      "Extract for [20]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [20]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [21]: Activation stage1_unit2_relu1\n",
      "Set for [21]: Activation stage1_unit2_relu1\n",
      "Extract for [22]: Conv2D stage1_unit2_conv1\n",
      "Set for [22]: Conv1D stage1_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 64) (1, 256, 64)\n",
      "Extract for [23]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [23]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [24]: Activation stage1_unit2_relu2\n",
      "Set for [24]: Activation stage1_unit2_relu2\n",
      "Extract for [25]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [25]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [26]: Conv2D stage1_unit2_conv2\n",
      "Set for [26]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [27]: BatchNormalization stage1_unit2_bn3\n",
      "Set for [27]: BatchNormalization stage1_unit2_bn3\n",
      "Extract for [28]: Activation stage1_unit2_relu3\n",
      "Set for [28]: Activation stage1_unit2_relu3\n",
      "Extract for [29]: Conv2D stage1_unit2_conv3\n",
      "Set for [29]: Conv1D stage1_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [30]: Add add_17\n",
      "Set for [30]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [31]: BatchNormalization stage1_unit3_bn1\n",
      "Set for [31]: BatchNormalization stage1_unit3_bn1\n",
      "Extract for [32]: Activation stage1_unit3_relu1\n",
      "Set for [32]: Activation stage1_unit3_relu1\n",
      "Extract for [33]: Conv2D stage1_unit3_conv1\n",
      "Set for [33]: Conv1D stage1_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 64) (1, 256, 64)\n",
      "Extract for [34]: BatchNormalization stage1_unit3_bn2\n",
      "Set for [34]: BatchNormalization stage1_unit3_bn2\n",
      "Extract for [35]: Activation stage1_unit3_relu2\n",
      "Set for [35]: Activation stage1_unit3_relu2\n",
      "Extract for [36]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [36]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [37]: Conv2D stage1_unit3_conv2\n",
      "Set for [37]: Conv1D stage1_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [38]: BatchNormalization stage1_unit3_bn3\n",
      "Set for [38]: BatchNormalization stage1_unit3_bn3\n",
      "Extract for [39]: Activation stage1_unit3_relu3\n",
      "Set for [39]: Activation stage1_unit3_relu3\n",
      "Extract for [40]: Conv2D stage1_unit3_conv3\n",
      "Set for [40]: Conv1D stage1_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [41]: Add add_18\n",
      "Set for [41]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [42]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [42]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [43]: Activation stage2_unit1_relu1\n",
      "Set for [43]: Activation stage2_unit1_relu1\n",
      "Extract for [44]: Conv2D stage2_unit1_conv1\n",
      "Set for [44]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 128) (1, 256, 128)\n",
      "Extract for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [46]: Activation stage2_unit1_relu2\n",
      "Set for [46]: Activation stage2_unit1_relu2\n",
      "Extract for [47]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [47]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [48]: Conv2D stage2_unit1_conv2\n",
      "Set for [48]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [49]: BatchNormalization stage2_unit1_bn3\n",
      "Set for [49]: BatchNormalization stage2_unit1_bn3\n",
      "Extract for [50]: Activation stage2_unit1_relu3\n",
      "Set for [50]: Activation stage2_unit1_relu3\n",
      "Extract for [51]: Conv2D stage2_unit1_conv3\n",
      "Set for [51]: Conv1D stage2_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [52]: Conv2D stage2_unit1_sc\n",
      "Set for [52]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n",
      "Extract for [53]: Add add_19\n",
      "Set for [53]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [54]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [54]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [55]: Activation stage2_unit2_relu1\n",
      "Set for [55]: Activation stage2_unit2_relu1\n",
      "Extract for [56]: Conv2D stage2_unit2_conv1\n",
      "Set for [56]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [57]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [57]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [58]: Activation stage2_unit2_relu2\n",
      "Set for [58]: Activation stage2_unit2_relu2\n",
      "Extract for [59]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [59]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [60]: Conv2D stage2_unit2_conv2\n",
      "Set for [60]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [61]: BatchNormalization stage2_unit2_bn3\n",
      "Set for [61]: BatchNormalization stage2_unit2_bn3\n",
      "Extract for [62]: Activation stage2_unit2_relu3\n",
      "Set for [62]: Activation stage2_unit2_relu3\n",
      "Extract for [63]: Conv2D stage2_unit2_conv3\n",
      "Set for [63]: Conv1D stage2_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [64]: Add add_20\n",
      "Set for [64]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [65]: BatchNormalization stage2_unit3_bn1\n",
      "Set for [65]: BatchNormalization stage2_unit3_bn1\n",
      "Extract for [66]: Activation stage2_unit3_relu1\n",
      "Set for [66]: Activation stage2_unit3_relu1\n",
      "Extract for [67]: Conv2D stage2_unit3_conv1\n",
      "Set for [67]: Conv1D stage2_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [68]: BatchNormalization stage2_unit3_bn2\n",
      "Set for [68]: BatchNormalization stage2_unit3_bn2\n",
      "Extract for [69]: Activation stage2_unit3_relu2\n",
      "Set for [69]: Activation stage2_unit3_relu2\n",
      "Extract for [70]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [70]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n",
      "Extract for [71]: Conv2D stage2_unit3_conv2\n",
      "Set for [71]: Conv1D stage2_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [72]: BatchNormalization stage2_unit3_bn3\n",
      "Set for [72]: BatchNormalization stage2_unit3_bn3\n",
      "Extract for [73]: Activation stage2_unit3_relu3\n",
      "Set for [73]: Activation stage2_unit3_relu3\n",
      "Extract for [74]: Conv2D stage2_unit3_conv3\n",
      "Set for [74]: Conv1D stage2_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [75]: Add add_21\n",
      "Set for [75]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [76]: BatchNormalization stage2_unit4_bn1\n",
      "Set for [76]: BatchNormalization stage2_unit4_bn1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [77]: Activation stage2_unit4_relu1\n",
      "Set for [77]: Activation stage2_unit4_relu1\n",
      "Extract for [78]: Conv2D stage2_unit4_conv1\n",
      "Set for [78]: Conv1D stage2_unit4_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [79]: BatchNormalization stage2_unit4_bn2\n",
      "Set for [79]: BatchNormalization stage2_unit4_bn2\n",
      "Extract for [80]: Activation stage2_unit4_relu2\n",
      "Set for [80]: Activation stage2_unit4_relu2\n",
      "Extract for [81]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [81]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [82]: Conv2D stage2_unit4_conv2\n",
      "Set for [82]: Conv1D stage2_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [83]: BatchNormalization stage2_unit4_bn3\n",
      "Set for [83]: BatchNormalization stage2_unit4_bn3\n",
      "Extract for [84]: Activation stage2_unit4_relu3\n",
      "Set for [84]: Activation stage2_unit4_relu3\n",
      "Extract for [85]: Conv2D stage2_unit4_conv3\n",
      "Set for [85]: Conv1D stage2_unit4_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [86]: Add add_22\n",
      "Set for [86]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [87]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [87]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [88]: Activation stage3_unit1_relu1\n",
      "Set for [88]: Activation stage3_unit1_relu1\n",
      "Extract for [89]: Conv2D stage3_unit1_conv1\n",
      "Set for [89]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 256) (1, 512, 256)\n",
      "Extract for [90]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [90]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [91]: Activation stage3_unit1_relu2\n",
      "Set for [91]: Activation stage3_unit1_relu2\n",
      "Extract for [92]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [92]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [93]: Conv2D stage3_unit1_conv2\n",
      "Set for [93]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [94]: BatchNormalization stage3_unit1_bn3\n",
      "Set for [94]: BatchNormalization stage3_unit1_bn3\n",
      "Extract for [95]: Activation stage3_unit1_relu3\n",
      "Set for [95]: Activation stage3_unit1_relu3\n",
      "Extract for [96]: Conv2D stage3_unit1_conv3\n",
      "Set for [96]: Conv1D stage3_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [97]: Conv2D stage3_unit1_sc\n",
      "Set for [97]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 512, 1024) (1, 512, 1024)\n",
      "Extract for [98]: Add add_23\n",
      "Set for [98]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [99]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [99]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [100]: Activation stage3_unit2_relu1\n",
      "Set for [100]: Activation stage3_unit2_relu1\n",
      "Extract for [101]: Conv2D stage3_unit2_conv1\n",
      "Set for [101]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [102]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [102]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [103]: Activation stage3_unit2_relu2\n",
      "Set for [103]: Activation stage3_unit2_relu2\n",
      "Extract for [104]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [104]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [105]: Conv2D stage3_unit2_conv2\n",
      "Set for [105]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [106]: BatchNormalization stage3_unit2_bn3\n",
      "Set for [106]: BatchNormalization stage3_unit2_bn3\n",
      "Extract for [107]: Activation stage3_unit2_relu3\n",
      "Set for [107]: Activation stage3_unit2_relu3\n",
      "Extract for [108]: Conv2D stage3_unit2_conv3\n",
      "Set for [108]: Conv1D stage3_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [109]: Add add_24\n",
      "Set for [109]: Add add_8\n",
      "Warning: different names!\n",
      "Extract for [110]: BatchNormalization stage3_unit3_bn1\n",
      "Set for [110]: BatchNormalization stage3_unit3_bn1\n",
      "Extract for [111]: Activation stage3_unit3_relu1\n",
      "Set for [111]: Activation stage3_unit3_relu1\n",
      "Extract for [112]: Conv2D stage3_unit3_conv1\n",
      "Set for [112]: Conv1D stage3_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [113]: BatchNormalization stage3_unit3_bn2\n",
      "Set for [113]: BatchNormalization stage3_unit3_bn2\n",
      "Extract for [114]: Activation stage3_unit3_relu2\n",
      "Set for [114]: Activation stage3_unit3_relu2\n",
      "Extract for [115]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [115]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [116]: Conv2D stage3_unit3_conv2\n",
      "Set for [116]: Conv1D stage3_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [117]: BatchNormalization stage3_unit3_bn3\n",
      "Set for [117]: BatchNormalization stage3_unit3_bn3\n",
      "Extract for [118]: Activation stage3_unit3_relu3\n",
      "Set for [118]: Activation stage3_unit3_relu3\n",
      "Extract for [119]: Conv2D stage3_unit3_conv3\n",
      "Set for [119]: Conv1D stage3_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [120]: Add add_25\n",
      "Set for [120]: Add add_9\n",
      "Warning: different names!\n",
      "Extract for [121]: BatchNormalization stage3_unit4_bn1\n",
      "Set for [121]: BatchNormalization stage3_unit4_bn1\n",
      "Extract for [122]: Activation stage3_unit4_relu1\n",
      "Set for [122]: Activation stage3_unit4_relu1\n",
      "Extract for [123]: Conv2D stage3_unit4_conv1\n",
      "Set for [123]: Conv1D stage3_unit4_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [124]: BatchNormalization stage3_unit4_bn2\n",
      "Set for [124]: BatchNormalization stage3_unit4_bn2\n",
      "Extract for [125]: Activation stage3_unit4_relu2\n",
      "Set for [125]: Activation stage3_unit4_relu2\n",
      "Extract for [126]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [126]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [127]: Conv2D stage3_unit4_conv2\n",
      "Set for [127]: Conv1D stage3_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [128]: BatchNormalization stage3_unit4_bn3\n",
      "Set for [128]: BatchNormalization stage3_unit4_bn3\n",
      "Extract for [129]: Activation stage3_unit4_relu3\n",
      "Set for [129]: Activation stage3_unit4_relu3\n",
      "Extract for [130]: Conv2D stage3_unit4_conv3\n",
      "Set for [130]: Conv1D stage3_unit4_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [131]: Add add_26\n",
      "Set for [131]: Add add_10\n",
      "Warning: different names!\n",
      "Extract for [132]: BatchNormalization stage3_unit5_bn1\n",
      "Set for [132]: BatchNormalization stage3_unit5_bn1\n",
      "Extract for [133]: Activation stage3_unit5_relu1\n",
      "Set for [133]: Activation stage3_unit5_relu1\n",
      "Extract for [134]: Conv2D stage3_unit5_conv1\n",
      "Set for [134]: Conv1D stage3_unit5_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [135]: BatchNormalization stage3_unit5_bn2\n",
      "Set for [135]: BatchNormalization stage3_unit5_bn2\n",
      "Extract for [136]: Activation stage3_unit5_relu2\n",
      "Set for [136]: Activation stage3_unit5_relu2\n",
      "Extract for [137]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [137]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [138]: Conv2D stage3_unit5_conv2\n",
      "Set for [138]: Conv1D stage3_unit5_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [139]: BatchNormalization stage3_unit5_bn3\n",
      "Set for [139]: BatchNormalization stage3_unit5_bn3\n",
      "Extract for [140]: Activation stage3_unit5_relu3\n",
      "Set for [140]: Activation stage3_unit5_relu3\n",
      "Extract for [141]: Conv2D stage3_unit5_conv3\n",
      "Set for [141]: Conv1D stage3_unit5_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [142]: Add add_27\n",
      "Set for [142]: Add add_11\n",
      "Warning: different names!\n",
      "Extract for [143]: BatchNormalization stage3_unit6_bn1\n",
      "Set for [143]: BatchNormalization stage3_unit6_bn1\n",
      "Extract for [144]: Activation stage3_unit6_relu1\n",
      "Set for [144]: Activation stage3_unit6_relu1\n",
      "Extract for [145]: Conv2D stage3_unit6_conv1\n",
      "Set for [145]: Conv1D stage3_unit6_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [146]: BatchNormalization stage3_unit6_bn2\n",
      "Set for [146]: BatchNormalization stage3_unit6_bn2\n",
      "Extract for [147]: Activation stage3_unit6_relu2\n",
      "Set for [147]: Activation stage3_unit6_relu2\n",
      "Extract for [148]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [148]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [149]: Conv2D stage3_unit6_conv2\n",
      "Set for [149]: Conv1D stage3_unit6_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [150]: BatchNormalization stage3_unit6_bn3\n",
      "Set for [150]: BatchNormalization stage3_unit6_bn3\n",
      "Extract for [151]: Activation stage3_unit6_relu3\n",
      "Set for [151]: Activation stage3_unit6_relu3\n",
      "Extract for [152]: Conv2D stage3_unit6_conv3\n",
      "Set for [152]: Conv1D stage3_unit6_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [153]: Add add_28\n",
      "Set for [153]: Add add_12\n",
      "Warning: different names!\n",
      "Extract for [154]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [154]: BatchNormalization stage4_unit1_bn1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [155]: Activation stage4_unit1_relu1\n",
      "Set for [155]: Activation stage4_unit1_relu1\n",
      "Extract for [156]: Conv2D stage4_unit1_conv1\n",
      "Set for [156]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 512) (1, 1024, 512)\n",
      "Extract for [157]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [157]: BatchNormalization stage4_unit1_bn2\n",
      "Extract for [158]: Activation stage4_unit1_relu2\n",
      "Set for [158]: Activation stage4_unit1_relu2\n",
      "Extract for [159]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [159]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [160]: Conv2D stage4_unit1_conv2\n",
      "Set for [160]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [161]: BatchNormalization stage4_unit1_bn3\n",
      "Set for [161]: BatchNormalization stage4_unit1_bn3\n",
      "Extract for [162]: Activation stage4_unit1_relu3\n",
      "Set for [162]: Activation stage4_unit1_relu3\n",
      "Extract for [163]: Conv2D stage4_unit1_conv3\n",
      "Set for [163]: Conv1D stage4_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [164]: Conv2D stage4_unit1_sc\n",
      "Set for [164]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 1024, 2048) (1, 1024, 2048)\n",
      "Extract for [165]: Add add_29\n",
      "Set for [165]: Add add_13\n",
      "Warning: different names!\n",
      "Extract for [166]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [166]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [167]: Activation stage4_unit2_relu1\n",
      "Set for [167]: Activation stage4_unit2_relu1\n",
      "Extract for [168]: Conv2D stage4_unit2_conv1\n",
      "Set for [168]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 2048, 512) (1, 2048, 512)\n",
      "Extract for [169]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [169]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [170]: Activation stage4_unit2_relu2\n",
      "Set for [170]: Activation stage4_unit2_relu2\n",
      "Extract for [171]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [171]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [172]: Conv2D stage4_unit2_conv2\n",
      "Set for [172]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [173]: BatchNormalization stage4_unit2_bn3\n",
      "Set for [173]: BatchNormalization stage4_unit2_bn3\n",
      "Extract for [174]: Activation stage4_unit2_relu3\n",
      "Set for [174]: Activation stage4_unit2_relu3\n",
      "Extract for [175]: Conv2D stage4_unit2_conv3\n",
      "Set for [175]: Conv1D stage4_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [176]: Add add_30\n",
      "Set for [176]: Add add_14\n",
      "Warning: different names!\n",
      "Extract for [177]: BatchNormalization stage4_unit3_bn1\n",
      "Set for [177]: BatchNormalization stage4_unit3_bn1\n",
      "Extract for [178]: Activation stage4_unit3_relu1\n",
      "Set for [178]: Activation stage4_unit3_relu1\n",
      "Extract for [179]: Conv2D stage4_unit3_conv1\n",
      "Set for [179]: Conv1D stage4_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 2048, 512) (1, 2048, 512)\n",
      "Extract for [180]: BatchNormalization stage4_unit3_bn2\n",
      "Set for [180]: BatchNormalization stage4_unit3_bn2\n",
      "Extract for [181]: Activation stage4_unit3_relu2\n",
      "Set for [181]: Activation stage4_unit3_relu2\n",
      "Extract for [182]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [182]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [183]: Conv2D stage4_unit3_conv2\n",
      "Set for [183]: Conv1D stage4_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [184]: BatchNormalization stage4_unit3_bn3\n",
      "Set for [184]: BatchNormalization stage4_unit3_bn3\n",
      "Extract for [185]: Activation stage4_unit3_relu3\n",
      "Set for [185]: Activation stage4_unit3_relu3\n",
      "Extract for [186]: Conv2D stage4_unit3_conv3\n",
      "Set for [186]: Conv1D stage4_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [187]: Add add_31\n",
      "Set for [187]: Add add_15\n",
      "Warning: different names!\n",
      "Extract for [188]: BatchNormalization bn1\n",
      "Set for [188]: BatchNormalization bn1\n",
      "Extract for [189]: Activation relu1\n",
      "Set for [189]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model 1D: resnet101 Mem single: 0.33\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet101_imagenet_1000_no_top.h5\n",
      "171164896/171164896 [==============================] - 29s 0us/step\n",
      "Model 2D: resnet101 Mem single: 0.38\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: Conv2D stage1_unit1_conv1\n",
      "Set for [10]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [11]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [11]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [12]: Activation stage1_unit1_relu2\n",
      "Set for [12]: Activation stage1_unit1_relu2\n",
      "Extract for [13]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [13]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [14]: Conv2D stage1_unit1_conv2\n",
      "Set for [14]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [15]: BatchNormalization stage1_unit1_bn3\n",
      "Set for [15]: BatchNormalization stage1_unit1_bn3\n",
      "Extract for [16]: Activation stage1_unit1_relu3\n",
      "Set for [16]: Activation stage1_unit1_relu3\n",
      "Extract for [17]: Conv2D stage1_unit1_conv3\n",
      "Set for [17]: Conv1D stage1_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [18]: Conv2D stage1_unit1_sc\n",
      "Set for [18]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [19]: Add add_33\n",
      "Set for [19]: Add add\n",
      "Warning: different names!\n",
      "Extract for [20]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [20]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [21]: Activation stage1_unit2_relu1\n",
      "Set for [21]: Activation stage1_unit2_relu1\n",
      "Extract for [22]: Conv2D stage1_unit2_conv1\n",
      "Set for [22]: Conv1D stage1_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 64) (1, 256, 64)\n",
      "Extract for [23]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [23]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [24]: Activation stage1_unit2_relu2\n",
      "Set for [24]: Activation stage1_unit2_relu2\n",
      "Extract for [25]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [25]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [26]: Conv2D stage1_unit2_conv2\n",
      "Set for [26]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [27]: BatchNormalization stage1_unit2_bn3\n",
      "Set for [27]: BatchNormalization stage1_unit2_bn3\n",
      "Extract for [28]: Activation stage1_unit2_relu3\n",
      "Set for [28]: Activation stage1_unit2_relu3\n",
      "Extract for [29]: Conv2D stage1_unit2_conv3\n",
      "Set for [29]: Conv1D stage1_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [30]: Add add_34\n",
      "Set for [30]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [31]: BatchNormalization stage1_unit3_bn1\n",
      "Set for [31]: BatchNormalization stage1_unit3_bn1\n",
      "Extract for [32]: Activation stage1_unit3_relu1\n",
      "Set for [32]: Activation stage1_unit3_relu1\n",
      "Extract for [33]: Conv2D stage1_unit3_conv1\n",
      "Set for [33]: Conv1D stage1_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 64) (1, 256, 64)\n",
      "Extract for [34]: BatchNormalization stage1_unit3_bn2\n",
      "Set for [34]: BatchNormalization stage1_unit3_bn2\n",
      "Extract for [35]: Activation stage1_unit3_relu2\n",
      "Set for [35]: Activation stage1_unit3_relu2\n",
      "Extract for [36]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [36]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [37]: Conv2D stage1_unit3_conv2\n",
      "Set for [37]: Conv1D stage1_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [38]: BatchNormalization stage1_unit3_bn3\n",
      "Set for [38]: BatchNormalization stage1_unit3_bn3\n",
      "Extract for [39]: Activation stage1_unit3_relu3\n",
      "Set for [39]: Activation stage1_unit3_relu3\n",
      "Extract for [40]: Conv2D stage1_unit3_conv3\n",
      "Set for [40]: Conv1D stage1_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [41]: Add add_35\n",
      "Set for [41]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [42]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [42]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [43]: Activation stage2_unit1_relu1\n",
      "Set for [43]: Activation stage2_unit1_relu1\n",
      "Extract for [44]: Conv2D stage2_unit1_conv1\n",
      "Set for [44]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 128) (1, 256, 128)\n",
      "Extract for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [46]: Activation stage2_unit1_relu2\n",
      "Set for [46]: Activation stage2_unit1_relu2\n",
      "Extract for [47]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [47]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [48]: Conv2D stage2_unit1_conv2\n",
      "Set for [48]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [49]: BatchNormalization stage2_unit1_bn3\n",
      "Set for [49]: BatchNormalization stage2_unit1_bn3\n",
      "Extract for [50]: Activation stage2_unit1_relu3\n",
      "Set for [50]: Activation stage2_unit1_relu3\n",
      "Extract for [51]: Conv2D stage2_unit1_conv3\n",
      "Set for [51]: Conv1D stage2_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [52]: Conv2D stage2_unit1_sc\n",
      "Set for [52]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [53]: Add add_36\n",
      "Set for [53]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [54]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [54]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [55]: Activation stage2_unit2_relu1\n",
      "Set for [55]: Activation stage2_unit2_relu1\n",
      "Extract for [56]: Conv2D stage2_unit2_conv1\n",
      "Set for [56]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [57]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [57]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [58]: Activation stage2_unit2_relu2\n",
      "Set for [58]: Activation stage2_unit2_relu2\n",
      "Extract for [59]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [59]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [60]: Conv2D stage2_unit2_conv2\n",
      "Set for [60]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [61]: BatchNormalization stage2_unit2_bn3\n",
      "Set for [61]: BatchNormalization stage2_unit2_bn3\n",
      "Extract for [62]: Activation stage2_unit2_relu3\n",
      "Set for [62]: Activation stage2_unit2_relu3\n",
      "Extract for [63]: Conv2D stage2_unit2_conv3\n",
      "Set for [63]: Conv1D stage2_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [64]: Add add_37\n",
      "Set for [64]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [65]: BatchNormalization stage2_unit3_bn1\n",
      "Set for [65]: BatchNormalization stage2_unit3_bn1\n",
      "Extract for [66]: Activation stage2_unit3_relu1\n",
      "Set for [66]: Activation stage2_unit3_relu1\n",
      "Extract for [67]: Conv2D stage2_unit3_conv1\n",
      "Set for [67]: Conv1D stage2_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [68]: BatchNormalization stage2_unit3_bn2\n",
      "Set for [68]: BatchNormalization stage2_unit3_bn2\n",
      "Extract for [69]: Activation stage2_unit3_relu2\n",
      "Set for [69]: Activation stage2_unit3_relu2\n",
      "Extract for [70]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [70]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n",
      "Extract for [71]: Conv2D stage2_unit3_conv2\n",
      "Set for [71]: Conv1D stage2_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [72]: BatchNormalization stage2_unit3_bn3\n",
      "Set for [72]: BatchNormalization stage2_unit3_bn3\n",
      "Extract for [73]: Activation stage2_unit3_relu3\n",
      "Set for [73]: Activation stage2_unit3_relu3\n",
      "Extract for [74]: Conv2D stage2_unit3_conv3\n",
      "Set for [74]: Conv1D stage2_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [75]: Add add_38\n",
      "Set for [75]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [76]: BatchNormalization stage2_unit4_bn1\n",
      "Set for [76]: BatchNormalization stage2_unit4_bn1\n",
      "Extract for [77]: Activation stage2_unit4_relu1\n",
      "Set for [77]: Activation stage2_unit4_relu1\n",
      "Extract for [78]: Conv2D stage2_unit4_conv1\n",
      "Set for [78]: Conv1D stage2_unit4_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [79]: BatchNormalization stage2_unit4_bn2\n",
      "Set for [79]: BatchNormalization stage2_unit4_bn2\n",
      "Extract for [80]: Activation stage2_unit4_relu2\n",
      "Set for [80]: Activation stage2_unit4_relu2\n",
      "Extract for [81]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [81]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [82]: Conv2D stage2_unit4_conv2\n",
      "Set for [82]: Conv1D stage2_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [83]: BatchNormalization stage2_unit4_bn3\n",
      "Set for [83]: BatchNormalization stage2_unit4_bn3\n",
      "Extract for [84]: Activation stage2_unit4_relu3\n",
      "Set for [84]: Activation stage2_unit4_relu3\n",
      "Extract for [85]: Conv2D stage2_unit4_conv3\n",
      "Set for [85]: Conv1D stage2_unit4_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [86]: Add add_39\n",
      "Set for [86]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [87]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [87]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [88]: Activation stage3_unit1_relu1\n",
      "Set for [88]: Activation stage3_unit1_relu1\n",
      "Extract for [89]: Conv2D stage3_unit1_conv1\n",
      "Set for [89]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 256) (1, 512, 256)\n",
      "Extract for [90]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [90]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [91]: Activation stage3_unit1_relu2\n",
      "Set for [91]: Activation stage3_unit1_relu2\n",
      "Extract for [92]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [92]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [93]: Conv2D stage3_unit1_conv2\n",
      "Set for [93]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [94]: BatchNormalization stage3_unit1_bn3\n",
      "Set for [94]: BatchNormalization stage3_unit1_bn3\n",
      "Extract for [95]: Activation stage3_unit1_relu3\n",
      "Set for [95]: Activation stage3_unit1_relu3\n",
      "Extract for [96]: Conv2D stage3_unit1_conv3\n",
      "Set for [96]: Conv1D stage3_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [97]: Conv2D stage3_unit1_sc\n",
      "Set for [97]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 512, 1024) (1, 512, 1024)\n",
      "Extract for [98]: Add add_40\n",
      "Set for [98]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [99]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [99]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [100]: Activation stage3_unit2_relu1\n",
      "Set for [100]: Activation stage3_unit2_relu1\n",
      "Extract for [101]: Conv2D stage3_unit2_conv1\n",
      "Set for [101]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [102]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [102]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [103]: Activation stage3_unit2_relu2\n",
      "Set for [103]: Activation stage3_unit2_relu2\n",
      "Extract for [104]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [104]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [105]: Conv2D stage3_unit2_conv2\n",
      "Set for [105]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [106]: BatchNormalization stage3_unit2_bn3\n",
      "Set for [106]: BatchNormalization stage3_unit2_bn3\n",
      "Extract for [107]: Activation stage3_unit2_relu3\n",
      "Set for [107]: Activation stage3_unit2_relu3\n",
      "Extract for [108]: Conv2D stage3_unit2_conv3\n",
      "Set for [108]: Conv1D stage3_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [109]: Add add_41\n",
      "Set for [109]: Add add_8\n",
      "Warning: different names!\n",
      "Extract for [110]: BatchNormalization stage3_unit3_bn1\n",
      "Set for [110]: BatchNormalization stage3_unit3_bn1\n",
      "Extract for [111]: Activation stage3_unit3_relu1\n",
      "Set for [111]: Activation stage3_unit3_relu1\n",
      "Extract for [112]: Conv2D stage3_unit3_conv1\n",
      "Set for [112]: Conv1D stage3_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [113]: BatchNormalization stage3_unit3_bn2\n",
      "Set for [113]: BatchNormalization stage3_unit3_bn2\n",
      "Extract for [114]: Activation stage3_unit3_relu2\n",
      "Set for [114]: Activation stage3_unit3_relu2\n",
      "Extract for [115]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [115]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [116]: Conv2D stage3_unit3_conv2\n",
      "Set for [116]: Conv1D stage3_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [117]: BatchNormalization stage3_unit3_bn3\n",
      "Set for [117]: BatchNormalization stage3_unit3_bn3\n",
      "Extract for [118]: Activation stage3_unit3_relu3\n",
      "Set for [118]: Activation stage3_unit3_relu3\n",
      "Extract for [119]: Conv2D stage3_unit3_conv3\n",
      "Set for [119]: Conv1D stage3_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [120]: Add add_42\n",
      "Set for [120]: Add add_9\n",
      "Warning: different names!\n",
      "Extract for [121]: BatchNormalization stage3_unit4_bn1\n",
      "Set for [121]: BatchNormalization stage3_unit4_bn1\n",
      "Extract for [122]: Activation stage3_unit4_relu1\n",
      "Set for [122]: Activation stage3_unit4_relu1\n",
      "Extract for [123]: Conv2D stage3_unit4_conv1\n",
      "Set for [123]: Conv1D stage3_unit4_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [124]: BatchNormalization stage3_unit4_bn2\n",
      "Set for [124]: BatchNormalization stage3_unit4_bn2\n",
      "Extract for [125]: Activation stage3_unit4_relu2\n",
      "Set for [125]: Activation stage3_unit4_relu2\n",
      "Extract for [126]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [126]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [127]: Conv2D stage3_unit4_conv2\n",
      "Set for [127]: Conv1D stage3_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [128]: BatchNormalization stage3_unit4_bn3\n",
      "Set for [128]: BatchNormalization stage3_unit4_bn3\n",
      "Extract for [129]: Activation stage3_unit4_relu3\n",
      "Set for [129]: Activation stage3_unit4_relu3\n",
      "Extract for [130]: Conv2D stage3_unit4_conv3\n",
      "Set for [130]: Conv1D stage3_unit4_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [131]: Add add_43\n",
      "Set for [131]: Add add_10\n",
      "Warning: different names!\n",
      "Extract for [132]: BatchNormalization stage3_unit5_bn1\n",
      "Set for [132]: BatchNormalization stage3_unit5_bn1\n",
      "Extract for [133]: Activation stage3_unit5_relu1\n",
      "Set for [133]: Activation stage3_unit5_relu1\n",
      "Extract for [134]: Conv2D stage3_unit5_conv1\n",
      "Set for [134]: Conv1D stage3_unit5_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [135]: BatchNormalization stage3_unit5_bn2\n",
      "Set for [135]: BatchNormalization stage3_unit5_bn2\n",
      "Extract for [136]: Activation stage3_unit5_relu2\n",
      "Set for [136]: Activation stage3_unit5_relu2\n",
      "Extract for [137]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [137]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [138]: Conv2D stage3_unit5_conv2\n",
      "Set for [138]: Conv1D stage3_unit5_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [139]: BatchNormalization stage3_unit5_bn3\n",
      "Set for [139]: BatchNormalization stage3_unit5_bn3\n",
      "Extract for [140]: Activation stage3_unit5_relu3\n",
      "Set for [140]: Activation stage3_unit5_relu3\n",
      "Extract for [141]: Conv2D stage3_unit5_conv3\n",
      "Set for [141]: Conv1D stage3_unit5_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [142]: Add add_44\n",
      "Set for [142]: Add add_11\n",
      "Warning: different names!\n",
      "Extract for [143]: BatchNormalization stage3_unit6_bn1\n",
      "Set for [143]: BatchNormalization stage3_unit6_bn1\n",
      "Extract for [144]: Activation stage3_unit6_relu1\n",
      "Set for [144]: Activation stage3_unit6_relu1\n",
      "Extract for [145]: Conv2D stage3_unit6_conv1\n",
      "Set for [145]: Conv1D stage3_unit6_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [146]: BatchNormalization stage3_unit6_bn2\n",
      "Set for [146]: BatchNormalization stage3_unit6_bn2\n",
      "Extract for [147]: Activation stage3_unit6_relu2\n",
      "Set for [147]: Activation stage3_unit6_relu2\n",
      "Extract for [148]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [148]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [149]: Conv2D stage3_unit6_conv2\n",
      "Set for [149]: Conv1D stage3_unit6_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [150]: BatchNormalization stage3_unit6_bn3\n",
      "Set for [150]: BatchNormalization stage3_unit6_bn3\n",
      "Extract for [151]: Activation stage3_unit6_relu3\n",
      "Set for [151]: Activation stage3_unit6_relu3\n",
      "Extract for [152]: Conv2D stage3_unit6_conv3\n",
      "Set for [152]: Conv1D stage3_unit6_conv3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [153]: Add add_45\n",
      "Set for [153]: Add add_12\n",
      "Warning: different names!\n",
      "Extract for [154]: BatchNormalization stage3_unit7_bn1\n",
      "Set for [154]: BatchNormalization stage3_unit7_bn1\n",
      "Extract for [155]: Activation stage3_unit7_relu1\n",
      "Set for [155]: Activation stage3_unit7_relu1\n",
      "Extract for [156]: Conv2D stage3_unit7_conv1\n",
      "Set for [156]: Conv1D stage3_unit7_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [157]: BatchNormalization stage3_unit7_bn2\n",
      "Set for [157]: BatchNormalization stage3_unit7_bn2\n",
      "Extract for [158]: Activation stage3_unit7_relu2\n",
      "Set for [158]: Activation stage3_unit7_relu2\n",
      "Extract for [159]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [159]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [160]: Conv2D stage3_unit7_conv2\n",
      "Set for [160]: Conv1D stage3_unit7_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [161]: BatchNormalization stage3_unit7_bn3\n",
      "Set for [161]: BatchNormalization stage3_unit7_bn3\n",
      "Extract for [162]: Activation stage3_unit7_relu3\n",
      "Set for [162]: Activation stage3_unit7_relu3\n",
      "Extract for [163]: Conv2D stage3_unit7_conv3\n",
      "Set for [163]: Conv1D stage3_unit7_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [164]: Add add_46\n",
      "Set for [164]: Add add_13\n",
      "Warning: different names!\n",
      "Extract for [165]: BatchNormalization stage3_unit8_bn1\n",
      "Set for [165]: BatchNormalization stage3_unit8_bn1\n",
      "Extract for [166]: Activation stage3_unit8_relu1\n",
      "Set for [166]: Activation stage3_unit8_relu1\n",
      "Extract for [167]: Conv2D stage3_unit8_conv1\n",
      "Set for [167]: Conv1D stage3_unit8_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [168]: BatchNormalization stage3_unit8_bn2\n",
      "Set for [168]: BatchNormalization stage3_unit8_bn2\n",
      "Extract for [169]: Activation stage3_unit8_relu2\n",
      "Set for [169]: Activation stage3_unit8_relu2\n",
      "Extract for [170]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [170]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [171]: Conv2D stage3_unit8_conv2\n",
      "Set for [171]: Conv1D stage3_unit8_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [172]: BatchNormalization stage3_unit8_bn3\n",
      "Set for [172]: BatchNormalization stage3_unit8_bn3\n",
      "Extract for [173]: Activation stage3_unit8_relu3\n",
      "Set for [173]: Activation stage3_unit8_relu3\n",
      "Extract for [174]: Conv2D stage3_unit8_conv3\n",
      "Set for [174]: Conv1D stage3_unit8_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [175]: Add add_47\n",
      "Set for [175]: Add add_14\n",
      "Warning: different names!\n",
      "Extract for [176]: BatchNormalization stage3_unit9_bn1\n",
      "Set for [176]: BatchNormalization stage3_unit9_bn1\n",
      "Extract for [177]: Activation stage3_unit9_relu1\n",
      "Set for [177]: Activation stage3_unit9_relu1\n",
      "Extract for [178]: Conv2D stage3_unit9_conv1\n",
      "Set for [178]: Conv1D stage3_unit9_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [179]: BatchNormalization stage3_unit9_bn2\n",
      "Set for [179]: BatchNormalization stage3_unit9_bn2\n",
      "Extract for [180]: Activation stage3_unit9_relu2\n",
      "Set for [180]: Activation stage3_unit9_relu2\n",
      "Extract for [181]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [181]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [182]: Conv2D stage3_unit9_conv2\n",
      "Set for [182]: Conv1D stage3_unit9_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [183]: BatchNormalization stage3_unit9_bn3\n",
      "Set for [183]: BatchNormalization stage3_unit9_bn3\n",
      "Extract for [184]: Activation stage3_unit9_relu3\n",
      "Set for [184]: Activation stage3_unit9_relu3\n",
      "Extract for [185]: Conv2D stage3_unit9_conv3\n",
      "Set for [185]: Conv1D stage3_unit9_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [186]: Add add_48\n",
      "Set for [186]: Add add_15\n",
      "Warning: different names!\n",
      "Extract for [187]: BatchNormalization stage3_unit10_bn1\n",
      "Set for [187]: BatchNormalization stage3_unit10_bn1\n",
      "Extract for [188]: Activation stage3_unit10_relu1\n",
      "Set for [188]: Activation stage3_unit10_relu1\n",
      "Extract for [189]: Conv2D stage3_unit10_conv1\n",
      "Set for [189]: Conv1D stage3_unit10_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [190]: BatchNormalization stage3_unit10_bn2\n",
      "Set for [190]: BatchNormalization stage3_unit10_bn2\n",
      "Extract for [191]: Activation stage3_unit10_relu2\n",
      "Set for [191]: Activation stage3_unit10_relu2\n",
      "Extract for [192]: ZeroPadding2D zero_padding2d_18\n",
      "Set for [192]: ZeroPadding1D zero_padding1d_18\n",
      "Warning: different names!\n",
      "Extract for [193]: Conv2D stage3_unit10_conv2\n",
      "Set for [193]: Conv1D stage3_unit10_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [194]: BatchNormalization stage3_unit10_bn3\n",
      "Set for [194]: BatchNormalization stage3_unit10_bn3\n",
      "Extract for [195]: Activation stage3_unit10_relu3\n",
      "Set for [195]: Activation stage3_unit10_relu3\n",
      "Extract for [196]: Conv2D stage3_unit10_conv3\n",
      "Set for [196]: Conv1D stage3_unit10_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [197]: Add add_49\n",
      "Set for [197]: Add add_16\n",
      "Warning: different names!\n",
      "Extract for [198]: BatchNormalization stage3_unit11_bn1\n",
      "Set for [198]: BatchNormalization stage3_unit11_bn1\n",
      "Extract for [199]: Activation stage3_unit11_relu1\n",
      "Set for [199]: Activation stage3_unit11_relu1\n",
      "Extract for [200]: Conv2D stage3_unit11_conv1\n",
      "Set for [200]: Conv1D stage3_unit11_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [201]: BatchNormalization stage3_unit11_bn2\n",
      "Set for [201]: BatchNormalization stage3_unit11_bn2\n",
      "Extract for [202]: Activation stage3_unit11_relu2\n",
      "Set for [202]: Activation stage3_unit11_relu2\n",
      "Extract for [203]: ZeroPadding2D zero_padding2d_19\n",
      "Set for [203]: ZeroPadding1D zero_padding1d_19\n",
      "Warning: different names!\n",
      "Extract for [204]: Conv2D stage3_unit11_conv2\n",
      "Set for [204]: Conv1D stage3_unit11_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [205]: BatchNormalization stage3_unit11_bn3\n",
      "Set for [205]: BatchNormalization stage3_unit11_bn3\n",
      "Extract for [206]: Activation stage3_unit11_relu3\n",
      "Set for [206]: Activation stage3_unit11_relu3\n",
      "Extract for [207]: Conv2D stage3_unit11_conv3\n",
      "Set for [207]: Conv1D stage3_unit11_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [208]: Add add_50\n",
      "Set for [208]: Add add_17\n",
      "Warning: different names!\n",
      "Extract for [209]: BatchNormalization stage3_unit12_bn1\n",
      "Set for [209]: BatchNormalization stage3_unit12_bn1\n",
      "Extract for [210]: Activation stage3_unit12_relu1\n",
      "Set for [210]: Activation stage3_unit12_relu1\n",
      "Extract for [211]: Conv2D stage3_unit12_conv1\n",
      "Set for [211]: Conv1D stage3_unit12_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [212]: BatchNormalization stage3_unit12_bn2\n",
      "Set for [212]: BatchNormalization stage3_unit12_bn2\n",
      "Extract for [213]: Activation stage3_unit12_relu2\n",
      "Set for [213]: Activation stage3_unit12_relu2\n",
      "Extract for [214]: ZeroPadding2D zero_padding2d_20\n",
      "Set for [214]: ZeroPadding1D zero_padding1d_20\n",
      "Warning: different names!\n",
      "Extract for [215]: Conv2D stage3_unit12_conv2\n",
      "Set for [215]: Conv1D stage3_unit12_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [216]: BatchNormalization stage3_unit12_bn3\n",
      "Set for [216]: BatchNormalization stage3_unit12_bn3\n",
      "Extract for [217]: Activation stage3_unit12_relu3\n",
      "Set for [217]: Activation stage3_unit12_relu3\n",
      "Extract for [218]: Conv2D stage3_unit12_conv3\n",
      "Set for [218]: Conv1D stage3_unit12_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [219]: Add add_51\n",
      "Set for [219]: Add add_18\n",
      "Warning: different names!\n",
      "Extract for [220]: BatchNormalization stage3_unit13_bn1\n",
      "Set for [220]: BatchNormalization stage3_unit13_bn1\n",
      "Extract for [221]: Activation stage3_unit13_relu1\n",
      "Set for [221]: Activation stage3_unit13_relu1\n",
      "Extract for [222]: Conv2D stage3_unit13_conv1\n",
      "Set for [222]: Conv1D stage3_unit13_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [223]: BatchNormalization stage3_unit13_bn2\n",
      "Set for [223]: BatchNormalization stage3_unit13_bn2\n",
      "Extract for [224]: Activation stage3_unit13_relu2\n",
      "Set for [224]: Activation stage3_unit13_relu2\n",
      "Extract for [225]: ZeroPadding2D zero_padding2d_21\n",
      "Set for [225]: ZeroPadding1D zero_padding1d_21\n",
      "Warning: different names!\n",
      "Extract for [226]: Conv2D stage3_unit13_conv2\n",
      "Set for [226]: Conv1D stage3_unit13_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [227]: BatchNormalization stage3_unit13_bn3\n",
      "Set for [227]: BatchNormalization stage3_unit13_bn3\n",
      "Extract for [228]: Activation stage3_unit13_relu3\n",
      "Set for [228]: Activation stage3_unit13_relu3\n",
      "Extract for [229]: Conv2D stage3_unit13_conv3\n",
      "Set for [229]: Conv1D stage3_unit13_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [230]: Add add_52\n",
      "Set for [230]: Add add_19\n",
      "Warning: different names!\n",
      "Extract for [231]: BatchNormalization stage3_unit14_bn1\n",
      "Set for [231]: BatchNormalization stage3_unit14_bn1\n",
      "Extract for [232]: Activation stage3_unit14_relu1\n",
      "Set for [232]: Activation stage3_unit14_relu1\n",
      "Extract for [233]: Conv2D stage3_unit14_conv1\n",
      "Set for [233]: Conv1D stage3_unit14_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [234]: BatchNormalization stage3_unit14_bn2\n",
      "Set for [234]: BatchNormalization stage3_unit14_bn2\n",
      "Extract for [235]: Activation stage3_unit14_relu2\n",
      "Set for [235]: Activation stage3_unit14_relu2\n",
      "Extract for [236]: ZeroPadding2D zero_padding2d_22\n",
      "Set for [236]: ZeroPadding1D zero_padding1d_22\n",
      "Warning: different names!\n",
      "Extract for [237]: Conv2D stage3_unit14_conv2\n",
      "Set for [237]: Conv1D stage3_unit14_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [238]: BatchNormalization stage3_unit14_bn3\n",
      "Set for [238]: BatchNormalization stage3_unit14_bn3\n",
      "Extract for [239]: Activation stage3_unit14_relu3\n",
      "Set for [239]: Activation stage3_unit14_relu3\n",
      "Extract for [240]: Conv2D stage3_unit14_conv3\n",
      "Set for [240]: Conv1D stage3_unit14_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [241]: Add add_53\n",
      "Set for [241]: Add add_20\n",
      "Warning: different names!\n",
      "Extract for [242]: BatchNormalization stage3_unit15_bn1\n",
      "Set for [242]: BatchNormalization stage3_unit15_bn1\n",
      "Extract for [243]: Activation stage3_unit15_relu1\n",
      "Set for [243]: Activation stage3_unit15_relu1\n",
      "Extract for [244]: Conv2D stage3_unit15_conv1\n",
      "Set for [244]: Conv1D stage3_unit15_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [245]: BatchNormalization stage3_unit15_bn2\n",
      "Set for [245]: BatchNormalization stage3_unit15_bn2\n",
      "Extract for [246]: Activation stage3_unit15_relu2\n",
      "Set for [246]: Activation stage3_unit15_relu2\n",
      "Extract for [247]: ZeroPadding2D zero_padding2d_23\n",
      "Set for [247]: ZeroPadding1D zero_padding1d_23\n",
      "Warning: different names!\n",
      "Extract for [248]: Conv2D stage3_unit15_conv2\n",
      "Set for [248]: Conv1D stage3_unit15_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [249]: BatchNormalization stage3_unit15_bn3\n",
      "Set for [249]: BatchNormalization stage3_unit15_bn3\n",
      "Extract for [250]: Activation stage3_unit15_relu3\n",
      "Set for [250]: Activation stage3_unit15_relu3\n",
      "Extract for [251]: Conv2D stage3_unit15_conv3\n",
      "Set for [251]: Conv1D stage3_unit15_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [252]: Add add_54\n",
      "Set for [252]: Add add_21\n",
      "Warning: different names!\n",
      "Extract for [253]: BatchNormalization stage3_unit16_bn1\n",
      "Set for [253]: BatchNormalization stage3_unit16_bn1\n",
      "Extract for [254]: Activation stage3_unit16_relu1\n",
      "Set for [254]: Activation stage3_unit16_relu1\n",
      "Extract for [255]: Conv2D stage3_unit16_conv1\n",
      "Set for [255]: Conv1D stage3_unit16_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [256]: BatchNormalization stage3_unit16_bn2\n",
      "Set for [256]: BatchNormalization stage3_unit16_bn2\n",
      "Extract for [257]: Activation stage3_unit16_relu2\n",
      "Set for [257]: Activation stage3_unit16_relu2\n",
      "Extract for [258]: ZeroPadding2D zero_padding2d_24\n",
      "Set for [258]: ZeroPadding1D zero_padding1d_24\n",
      "Warning: different names!\n",
      "Extract for [259]: Conv2D stage3_unit16_conv2\n",
      "Set for [259]: Conv1D stage3_unit16_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [260]: BatchNormalization stage3_unit16_bn3\n",
      "Set for [260]: BatchNormalization stage3_unit16_bn3\n",
      "Extract for [261]: Activation stage3_unit16_relu3\n",
      "Set for [261]: Activation stage3_unit16_relu3\n",
      "Extract for [262]: Conv2D stage3_unit16_conv3\n",
      "Set for [262]: Conv1D stage3_unit16_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [263]: Add add_55\n",
      "Set for [263]: Add add_22\n",
      "Warning: different names!\n",
      "Extract for [264]: BatchNormalization stage3_unit17_bn1\n",
      "Set for [264]: BatchNormalization stage3_unit17_bn1\n",
      "Extract for [265]: Activation stage3_unit17_relu1\n",
      "Set for [265]: Activation stage3_unit17_relu1\n",
      "Extract for [266]: Conv2D stage3_unit17_conv1\n",
      "Set for [266]: Conv1D stage3_unit17_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [267]: BatchNormalization stage3_unit17_bn2\n",
      "Set for [267]: BatchNormalization stage3_unit17_bn2\n",
      "Extract for [268]: Activation stage3_unit17_relu2\n",
      "Set for [268]: Activation stage3_unit17_relu2\n",
      "Extract for [269]: ZeroPadding2D zero_padding2d_25\n",
      "Set for [269]: ZeroPadding1D zero_padding1d_25\n",
      "Warning: different names!\n",
      "Extract for [270]: Conv2D stage3_unit17_conv2\n",
      "Set for [270]: Conv1D stage3_unit17_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [271]: BatchNormalization stage3_unit17_bn3\n",
      "Set for [271]: BatchNormalization stage3_unit17_bn3\n",
      "Extract for [272]: Activation stage3_unit17_relu3\n",
      "Set for [272]: Activation stage3_unit17_relu3\n",
      "Extract for [273]: Conv2D stage3_unit17_conv3\n",
      "Set for [273]: Conv1D stage3_unit17_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [274]: Add add_56\n",
      "Set for [274]: Add add_23\n",
      "Warning: different names!\n",
      "Extract for [275]: BatchNormalization stage3_unit18_bn1\n",
      "Set for [275]: BatchNormalization stage3_unit18_bn1\n",
      "Extract for [276]: Activation stage3_unit18_relu1\n",
      "Set for [276]: Activation stage3_unit18_relu1\n",
      "Extract for [277]: Conv2D stage3_unit18_conv1\n",
      "Set for [277]: Conv1D stage3_unit18_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [278]: BatchNormalization stage3_unit18_bn2\n",
      "Set for [278]: BatchNormalization stage3_unit18_bn2\n",
      "Extract for [279]: Activation stage3_unit18_relu2\n",
      "Set for [279]: Activation stage3_unit18_relu2\n",
      "Extract for [280]: ZeroPadding2D zero_padding2d_26\n",
      "Set for [280]: ZeroPadding1D zero_padding1d_26\n",
      "Warning: different names!\n",
      "Extract for [281]: Conv2D stage3_unit18_conv2\n",
      "Set for [281]: Conv1D stage3_unit18_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [282]: BatchNormalization stage3_unit18_bn3\n",
      "Set for [282]: BatchNormalization stage3_unit18_bn3\n",
      "Extract for [283]: Activation stage3_unit18_relu3\n",
      "Set for [283]: Activation stage3_unit18_relu3\n",
      "Extract for [284]: Conv2D stage3_unit18_conv3\n",
      "Set for [284]: Conv1D stage3_unit18_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [285]: Add add_57\n",
      "Set for [285]: Add add_24\n",
      "Warning: different names!\n",
      "Extract for [286]: BatchNormalization stage3_unit19_bn1\n",
      "Set for [286]: BatchNormalization stage3_unit19_bn1\n",
      "Extract for [287]: Activation stage3_unit19_relu1\n",
      "Set for [287]: Activation stage3_unit19_relu1\n",
      "Extract for [288]: Conv2D stage3_unit19_conv1\n",
      "Set for [288]: Conv1D stage3_unit19_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [289]: BatchNormalization stage3_unit19_bn2\n",
      "Set for [289]: BatchNormalization stage3_unit19_bn2\n",
      "Extract for [290]: Activation stage3_unit19_relu2\n",
      "Set for [290]: Activation stage3_unit19_relu2\n",
      "Extract for [291]: ZeroPadding2D zero_padding2d_27\n",
      "Set for [291]: ZeroPadding1D zero_padding1d_27\n",
      "Warning: different names!\n",
      "Extract for [292]: Conv2D stage3_unit19_conv2\n",
      "Set for [292]: Conv1D stage3_unit19_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [293]: BatchNormalization stage3_unit19_bn3\n",
      "Set for [293]: BatchNormalization stage3_unit19_bn3\n",
      "Extract for [294]: Activation stage3_unit19_relu3\n",
      "Set for [294]: Activation stage3_unit19_relu3\n",
      "Extract for [295]: Conv2D stage3_unit19_conv3\n",
      "Set for [295]: Conv1D stage3_unit19_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [296]: Add add_58\n",
      "Set for [296]: Add add_25\n",
      "Warning: different names!\n",
      "Extract for [297]: BatchNormalization stage3_unit20_bn1\n",
      "Set for [297]: BatchNormalization stage3_unit20_bn1\n",
      "Extract for [298]: Activation stage3_unit20_relu1\n",
      "Set for [298]: Activation stage3_unit20_relu1\n",
      "Extract for [299]: Conv2D stage3_unit20_conv1\n",
      "Set for [299]: Conv1D stage3_unit20_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [300]: BatchNormalization stage3_unit20_bn2\n",
      "Set for [300]: BatchNormalization stage3_unit20_bn2\n",
      "Extract for [301]: Activation stage3_unit20_relu2\n",
      "Set for [301]: Activation stage3_unit20_relu2\n",
      "Extract for [302]: ZeroPadding2D zero_padding2d_28\n",
      "Set for [302]: ZeroPadding1D zero_padding1d_28\n",
      "Warning: different names!\n",
      "Extract for [303]: Conv2D stage3_unit20_conv2\n",
      "Set for [303]: Conv1D stage3_unit20_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [304]: BatchNormalization stage3_unit20_bn3\n",
      "Set for [304]: BatchNormalization stage3_unit20_bn3\n",
      "Extract for [305]: Activation stage3_unit20_relu3\n",
      "Set for [305]: Activation stage3_unit20_relu3\n",
      "Extract for [306]: Conv2D stage3_unit20_conv3\n",
      "Set for [306]: Conv1D stage3_unit20_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [307]: Add add_59\n",
      "Set for [307]: Add add_26\n",
      "Warning: different names!\n",
      "Extract for [308]: BatchNormalization stage3_unit21_bn1\n",
      "Set for [308]: BatchNormalization stage3_unit21_bn1\n",
      "Extract for [309]: Activation stage3_unit21_relu1\n",
      "Set for [309]: Activation stage3_unit21_relu1\n",
      "Extract for [310]: Conv2D stage3_unit21_conv1\n",
      "Set for [310]: Conv1D stage3_unit21_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [311]: BatchNormalization stage3_unit21_bn2\n",
      "Set for [311]: BatchNormalization stage3_unit21_bn2\n",
      "Extract for [312]: Activation stage3_unit21_relu2\n",
      "Set for [312]: Activation stage3_unit21_relu2\n",
      "Extract for [313]: ZeroPadding2D zero_padding2d_29\n",
      "Set for [313]: ZeroPadding1D zero_padding1d_29\n",
      "Warning: different names!\n",
      "Extract for [314]: Conv2D stage3_unit21_conv2\n",
      "Set for [314]: Conv1D stage3_unit21_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [315]: BatchNormalization stage3_unit21_bn3\n",
      "Set for [315]: BatchNormalization stage3_unit21_bn3\n",
      "Extract for [316]: Activation stage3_unit21_relu3\n",
      "Set for [316]: Activation stage3_unit21_relu3\n",
      "Extract for [317]: Conv2D stage3_unit21_conv3\n",
      "Set for [317]: Conv1D stage3_unit21_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [318]: Add add_60\n",
      "Set for [318]: Add add_27\n",
      "Warning: different names!\n",
      "Extract for [319]: BatchNormalization stage3_unit22_bn1\n",
      "Set for [319]: BatchNormalization stage3_unit22_bn1\n",
      "Extract for [320]: Activation stage3_unit22_relu1\n",
      "Set for [320]: Activation stage3_unit22_relu1\n",
      "Extract for [321]: Conv2D stage3_unit22_conv1\n",
      "Set for [321]: Conv1D stage3_unit22_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [322]: BatchNormalization stage3_unit22_bn2\n",
      "Set for [322]: BatchNormalization stage3_unit22_bn2\n",
      "Extract for [323]: Activation stage3_unit22_relu2\n",
      "Set for [323]: Activation stage3_unit22_relu2\n",
      "Extract for [324]: ZeroPadding2D zero_padding2d_30\n",
      "Set for [324]: ZeroPadding1D zero_padding1d_30\n",
      "Warning: different names!\n",
      "Extract for [325]: Conv2D stage3_unit22_conv2\n",
      "Set for [325]: Conv1D stage3_unit22_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [326]: BatchNormalization stage3_unit22_bn3\n",
      "Set for [326]: BatchNormalization stage3_unit22_bn3\n",
      "Extract for [327]: Activation stage3_unit22_relu3\n",
      "Set for [327]: Activation stage3_unit22_relu3\n",
      "Extract for [328]: Conv2D stage3_unit22_conv3\n",
      "Set for [328]: Conv1D stage3_unit22_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [329]: Add add_61\n",
      "Set for [329]: Add add_28\n",
      "Warning: different names!\n",
      "Extract for [330]: BatchNormalization stage3_unit23_bn1\n",
      "Set for [330]: BatchNormalization stage3_unit23_bn1\n",
      "Extract for [331]: Activation stage3_unit23_relu1\n",
      "Set for [331]: Activation stage3_unit23_relu1\n",
      "Extract for [332]: Conv2D stage3_unit23_conv1\n",
      "Set for [332]: Conv1D stage3_unit23_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [333]: BatchNormalization stage3_unit23_bn2\n",
      "Set for [333]: BatchNormalization stage3_unit23_bn2\n",
      "Extract for [334]: Activation stage3_unit23_relu2\n",
      "Set for [334]: Activation stage3_unit23_relu2\n",
      "Extract for [335]: ZeroPadding2D zero_padding2d_31\n",
      "Set for [335]: ZeroPadding1D zero_padding1d_31\n",
      "Warning: different names!\n",
      "Extract for [336]: Conv2D stage3_unit23_conv2\n",
      "Set for [336]: Conv1D stage3_unit23_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [337]: BatchNormalization stage3_unit23_bn3\n",
      "Set for [337]: BatchNormalization stage3_unit23_bn3\n",
      "Extract for [338]: Activation stage3_unit23_relu3\n",
      "Set for [338]: Activation stage3_unit23_relu3\n",
      "Extract for [339]: Conv2D stage3_unit23_conv3\n",
      "Set for [339]: Conv1D stage3_unit23_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [340]: Add add_62\n",
      "Set for [340]: Add add_29\n",
      "Warning: different names!\n",
      "Extract for [341]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [341]: BatchNormalization stage4_unit1_bn1\n",
      "Extract for [342]: Activation stage4_unit1_relu1\n",
      "Set for [342]: Activation stage4_unit1_relu1\n",
      "Extract for [343]: Conv2D stage4_unit1_conv1\n",
      "Set for [343]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 512) (1, 1024, 512)\n",
      "Extract for [344]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [344]: BatchNormalization stage4_unit1_bn2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [345]: Activation stage4_unit1_relu2\n",
      "Set for [345]: Activation stage4_unit1_relu2\n",
      "Extract for [346]: ZeroPadding2D zero_padding2d_32\n",
      "Set for [346]: ZeroPadding1D zero_padding1d_32\n",
      "Warning: different names!\n",
      "Extract for [347]: Conv2D stage4_unit1_conv2\n",
      "Set for [347]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [348]: BatchNormalization stage4_unit1_bn3\n",
      "Set for [348]: BatchNormalization stage4_unit1_bn3\n",
      "Extract for [349]: Activation stage4_unit1_relu3\n",
      "Set for [349]: Activation stage4_unit1_relu3\n",
      "Extract for [350]: Conv2D stage4_unit1_conv3\n",
      "Set for [350]: Conv1D stage4_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [351]: Conv2D stage4_unit1_sc\n",
      "Set for [351]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 1024, 2048) (1, 1024, 2048)\n",
      "Extract for [352]: Add add_63\n",
      "Set for [352]: Add add_30\n",
      "Warning: different names!\n",
      "Extract for [353]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [353]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [354]: Activation stage4_unit2_relu1\n",
      "Set for [354]: Activation stage4_unit2_relu1\n",
      "Extract for [355]: Conv2D stage4_unit2_conv1\n",
      "Set for [355]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 2048, 512) (1, 2048, 512)\n",
      "Extract for [356]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [356]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [357]: Activation stage4_unit2_relu2\n",
      "Set for [357]: Activation stage4_unit2_relu2\n",
      "Extract for [358]: ZeroPadding2D zero_padding2d_33\n",
      "Set for [358]: ZeroPadding1D zero_padding1d_33\n",
      "Warning: different names!\n",
      "Extract for [359]: Conv2D stage4_unit2_conv2\n",
      "Set for [359]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [360]: BatchNormalization stage4_unit2_bn3\n",
      "Set for [360]: BatchNormalization stage4_unit2_bn3\n",
      "Extract for [361]: Activation stage4_unit2_relu3\n",
      "Set for [361]: Activation stage4_unit2_relu3\n",
      "Extract for [362]: Conv2D stage4_unit2_conv3\n",
      "Set for [362]: Conv1D stage4_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [363]: Add add_64\n",
      "Set for [363]: Add add_31\n",
      "Warning: different names!\n",
      "Extract for [364]: BatchNormalization stage4_unit3_bn1\n",
      "Set for [364]: BatchNormalization stage4_unit3_bn1\n",
      "Extract for [365]: Activation stage4_unit3_relu1\n",
      "Set for [365]: Activation stage4_unit3_relu1\n",
      "Extract for [366]: Conv2D stage4_unit3_conv1\n",
      "Set for [366]: Conv1D stage4_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 2048, 512) (1, 2048, 512)\n",
      "Extract for [367]: BatchNormalization stage4_unit3_bn2\n",
      "Set for [367]: BatchNormalization stage4_unit3_bn2\n",
      "Extract for [368]: Activation stage4_unit3_relu2\n",
      "Set for [368]: Activation stage4_unit3_relu2\n",
      "Extract for [369]: ZeroPadding2D zero_padding2d_34\n",
      "Set for [369]: ZeroPadding1D zero_padding1d_34\n",
      "Warning: different names!\n",
      "Extract for [370]: Conv2D stage4_unit3_conv2\n",
      "Set for [370]: Conv1D stage4_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [371]: BatchNormalization stage4_unit3_bn3\n",
      "Set for [371]: BatchNormalization stage4_unit3_bn3\n",
      "Extract for [372]: Activation stage4_unit3_relu3\n",
      "Set for [372]: Activation stage4_unit3_relu3\n",
      "Extract for [373]: Conv2D stage4_unit3_conv3\n",
      "Set for [373]: Conv1D stage4_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [374]: Add add_65\n",
      "Set for [374]: Add add_32\n",
      "Warning: different names!\n",
      "Extract for [375]: BatchNormalization bn1\n",
      "Set for [375]: BatchNormalization bn1\n",
      "Extract for [376]: Activation relu1\n",
      "Set for [376]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model 1D: resnet152 Mem single: 0.45\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet152_imagenet_1000_no_top.h5\n",
      "234326024/234326024 [==============================] - 41s 0us/step\n",
      "Model 2D: resnet152 Mem single: 0.53\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: Conv2D stage1_unit1_conv1\n",
      "Set for [10]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [11]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [11]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [12]: Activation stage1_unit1_relu2\n",
      "Set for [12]: Activation stage1_unit1_relu2\n",
      "Extract for [13]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [13]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [14]: Conv2D stage1_unit1_conv2\n",
      "Set for [14]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [15]: BatchNormalization stage1_unit1_bn3\n",
      "Set for [15]: BatchNormalization stage1_unit1_bn3\n",
      "Extract for [16]: Activation stage1_unit1_relu3\n",
      "Set for [16]: Activation stage1_unit1_relu3\n",
      "Extract for [17]: Conv2D stage1_unit1_conv3\n",
      "Set for [17]: Conv1D stage1_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [18]: Conv2D stage1_unit1_sc\n",
      "Set for [18]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [19]: Add add_50\n",
      "Set for [19]: Add add\n",
      "Warning: different names!\n",
      "Extract for [20]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [20]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [21]: Activation stage1_unit2_relu1\n",
      "Set for [21]: Activation stage1_unit2_relu1\n",
      "Extract for [22]: Conv2D stage1_unit2_conv1\n",
      "Set for [22]: Conv1D stage1_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 64) (1, 256, 64)\n",
      "Extract for [23]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [23]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [24]: Activation stage1_unit2_relu2\n",
      "Set for [24]: Activation stage1_unit2_relu2\n",
      "Extract for [25]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [25]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [26]: Conv2D stage1_unit2_conv2\n",
      "Set for [26]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [27]: BatchNormalization stage1_unit2_bn3\n",
      "Set for [27]: BatchNormalization stage1_unit2_bn3\n",
      "Extract for [28]: Activation stage1_unit2_relu3\n",
      "Set for [28]: Activation stage1_unit2_relu3\n",
      "Extract for [29]: Conv2D stage1_unit2_conv3\n",
      "Set for [29]: Conv1D stage1_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [30]: Add add_51\n",
      "Set for [30]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [31]: BatchNormalization stage1_unit3_bn1\n",
      "Set for [31]: BatchNormalization stage1_unit3_bn1\n",
      "Extract for [32]: Activation stage1_unit3_relu1\n",
      "Set for [32]: Activation stage1_unit3_relu1\n",
      "Extract for [33]: Conv2D stage1_unit3_conv1\n",
      "Set for [33]: Conv1D stage1_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 64) (1, 256, 64)\n",
      "Extract for [34]: BatchNormalization stage1_unit3_bn2\n",
      "Set for [34]: BatchNormalization stage1_unit3_bn2\n",
      "Extract for [35]: Activation stage1_unit3_relu2\n",
      "Set for [35]: Activation stage1_unit3_relu2\n",
      "Extract for [36]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [36]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [37]: Conv2D stage1_unit3_conv2\n",
      "Set for [37]: Conv1D stage1_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [38]: BatchNormalization stage1_unit3_bn3\n",
      "Set for [38]: BatchNormalization stage1_unit3_bn3\n",
      "Extract for [39]: Activation stage1_unit3_relu3\n",
      "Set for [39]: Activation stage1_unit3_relu3\n",
      "Extract for [40]: Conv2D stage1_unit3_conv3\n",
      "Set for [40]: Conv1D stage1_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 64, 256) (1, 64, 256)\n",
      "Extract for [41]: Add add_52\n",
      "Set for [41]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [42]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [42]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [43]: Activation stage2_unit1_relu1\n",
      "Set for [43]: Activation stage2_unit1_relu1\n",
      "Extract for [44]: Conv2D stage2_unit1_conv1\n",
      "Set for [44]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 256, 128) (1, 256, 128)\n",
      "Extract for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [46]: Activation stage2_unit1_relu2\n",
      "Set for [46]: Activation stage2_unit1_relu2\n",
      "Extract for [47]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [47]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [48]: Conv2D stage2_unit1_conv2\n",
      "Set for [48]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [49]: BatchNormalization stage2_unit1_bn3\n",
      "Set for [49]: BatchNormalization stage2_unit1_bn3\n",
      "Extract for [50]: Activation stage2_unit1_relu3\n",
      "Set for [50]: Activation stage2_unit1_relu3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [51]: Conv2D stage2_unit1_conv3\n",
      "Set for [51]: Conv1D stage2_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [52]: Conv2D stage2_unit1_sc\n",
      "Set for [52]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n",
      "Extract for [53]: Add add_53\n",
      "Set for [53]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [54]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [54]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [55]: Activation stage2_unit2_relu1\n",
      "Set for [55]: Activation stage2_unit2_relu1\n",
      "Extract for [56]: Conv2D stage2_unit2_conv1\n",
      "Set for [56]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [57]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [57]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [58]: Activation stage2_unit2_relu2\n",
      "Set for [58]: Activation stage2_unit2_relu2\n",
      "Extract for [59]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [59]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [60]: Conv2D stage2_unit2_conv2\n",
      "Set for [60]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [61]: BatchNormalization stage2_unit2_bn3\n",
      "Set for [61]: BatchNormalization stage2_unit2_bn3\n",
      "Extract for [62]: Activation stage2_unit2_relu3\n",
      "Set for [62]: Activation stage2_unit2_relu3\n",
      "Extract for [63]: Conv2D stage2_unit2_conv3\n",
      "Set for [63]: Conv1D stage2_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [64]: Add add_54\n",
      "Set for [64]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [65]: BatchNormalization stage2_unit3_bn1\n",
      "Set for [65]: BatchNormalization stage2_unit3_bn1\n",
      "Extract for [66]: Activation stage2_unit3_relu1\n",
      "Set for [66]: Activation stage2_unit3_relu1\n",
      "Extract for [67]: Conv2D stage2_unit3_conv1\n",
      "Set for [67]: Conv1D stage2_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [68]: BatchNormalization stage2_unit3_bn2\n",
      "Set for [68]: BatchNormalization stage2_unit3_bn2\n",
      "Extract for [69]: Activation stage2_unit3_relu2\n",
      "Set for [69]: Activation stage2_unit3_relu2\n",
      "Extract for [70]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [70]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n",
      "Extract for [71]: Conv2D stage2_unit3_conv2\n",
      "Set for [71]: Conv1D stage2_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [72]: BatchNormalization stage2_unit3_bn3\n",
      "Set for [72]: BatchNormalization stage2_unit3_bn3\n",
      "Extract for [73]: Activation stage2_unit3_relu3\n",
      "Set for [73]: Activation stage2_unit3_relu3\n",
      "Extract for [74]: Conv2D stage2_unit3_conv3\n",
      "Set for [74]: Conv1D stage2_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [75]: Add add_55\n",
      "Set for [75]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [76]: BatchNormalization stage2_unit4_bn1\n",
      "Set for [76]: BatchNormalization stage2_unit4_bn1\n",
      "Extract for [77]: Activation stage2_unit4_relu1\n",
      "Set for [77]: Activation stage2_unit4_relu1\n",
      "Extract for [78]: Conv2D stage2_unit4_conv1\n",
      "Set for [78]: Conv1D stage2_unit4_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [79]: BatchNormalization stage2_unit4_bn2\n",
      "Set for [79]: BatchNormalization stage2_unit4_bn2\n",
      "Extract for [80]: Activation stage2_unit4_relu2\n",
      "Set for [80]: Activation stage2_unit4_relu2\n",
      "Extract for [81]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [81]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [82]: Conv2D stage2_unit4_conv2\n",
      "Set for [82]: Conv1D stage2_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [83]: BatchNormalization stage2_unit4_bn3\n",
      "Set for [83]: BatchNormalization stage2_unit4_bn3\n",
      "Extract for [84]: Activation stage2_unit4_relu3\n",
      "Set for [84]: Activation stage2_unit4_relu3\n",
      "Extract for [85]: Conv2D stage2_unit4_conv3\n",
      "Set for [85]: Conv1D stage2_unit4_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [86]: Add add_56\n",
      "Set for [86]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [87]: BatchNormalization stage2_unit5_bn1\n",
      "Set for [87]: BatchNormalization stage2_unit5_bn1\n",
      "Extract for [88]: Activation stage2_unit5_relu1\n",
      "Set for [88]: Activation stage2_unit5_relu1\n",
      "Extract for [89]: Conv2D stage2_unit5_conv1\n",
      "Set for [89]: Conv1D stage2_unit5_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [90]: BatchNormalization stage2_unit5_bn2\n",
      "Set for [90]: BatchNormalization stage2_unit5_bn2\n",
      "Extract for [91]: Activation stage2_unit5_relu2\n",
      "Set for [91]: Activation stage2_unit5_relu2\n",
      "Extract for [92]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [92]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [93]: Conv2D stage2_unit5_conv2\n",
      "Set for [93]: Conv1D stage2_unit5_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [94]: BatchNormalization stage2_unit5_bn3\n",
      "Set for [94]: BatchNormalization stage2_unit5_bn3\n",
      "Extract for [95]: Activation stage2_unit5_relu3\n",
      "Set for [95]: Activation stage2_unit5_relu3\n",
      "Extract for [96]: Conv2D stage2_unit5_conv3\n",
      "Set for [96]: Conv1D stage2_unit5_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [97]: Add add_57\n",
      "Set for [97]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [98]: BatchNormalization stage2_unit6_bn1\n",
      "Set for [98]: BatchNormalization stage2_unit6_bn1\n",
      "Extract for [99]: Activation stage2_unit6_relu1\n",
      "Set for [99]: Activation stage2_unit6_relu1\n",
      "Extract for [100]: Conv2D stage2_unit6_conv1\n",
      "Set for [100]: Conv1D stage2_unit6_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [101]: BatchNormalization stage2_unit6_bn2\n",
      "Set for [101]: BatchNormalization stage2_unit6_bn2\n",
      "Extract for [102]: Activation stage2_unit6_relu2\n",
      "Set for [102]: Activation stage2_unit6_relu2\n",
      "Extract for [103]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [103]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [104]: Conv2D stage2_unit6_conv2\n",
      "Set for [104]: Conv1D stage2_unit6_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [105]: BatchNormalization stage2_unit6_bn3\n",
      "Set for [105]: BatchNormalization stage2_unit6_bn3\n",
      "Extract for [106]: Activation stage2_unit6_relu3\n",
      "Set for [106]: Activation stage2_unit6_relu3\n",
      "Extract for [107]: Conv2D stage2_unit6_conv3\n",
      "Set for [107]: Conv1D stage2_unit6_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [108]: Add add_58\n",
      "Set for [108]: Add add_8\n",
      "Warning: different names!\n",
      "Extract for [109]: BatchNormalization stage2_unit7_bn1\n",
      "Set for [109]: BatchNormalization stage2_unit7_bn1\n",
      "Extract for [110]: Activation stage2_unit7_relu1\n",
      "Set for [110]: Activation stage2_unit7_relu1\n",
      "Extract for [111]: Conv2D stage2_unit7_conv1\n",
      "Set for [111]: Conv1D stage2_unit7_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [112]: BatchNormalization stage2_unit7_bn2\n",
      "Set for [112]: BatchNormalization stage2_unit7_bn2\n",
      "Extract for [113]: Activation stage2_unit7_relu2\n",
      "Set for [113]: Activation stage2_unit7_relu2\n",
      "Extract for [114]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [114]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [115]: Conv2D stage2_unit7_conv2\n",
      "Set for [115]: Conv1D stage2_unit7_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [116]: BatchNormalization stage2_unit7_bn3\n",
      "Set for [116]: BatchNormalization stage2_unit7_bn3\n",
      "Extract for [117]: Activation stage2_unit7_relu3\n",
      "Set for [117]: Activation stage2_unit7_relu3\n",
      "Extract for [118]: Conv2D stage2_unit7_conv3\n",
      "Set for [118]: Conv1D stage2_unit7_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [119]: Add add_59\n",
      "Set for [119]: Add add_9\n",
      "Warning: different names!\n",
      "Extract for [120]: BatchNormalization stage2_unit8_bn1\n",
      "Set for [120]: BatchNormalization stage2_unit8_bn1\n",
      "Extract for [121]: Activation stage2_unit8_relu1\n",
      "Set for [121]: Activation stage2_unit8_relu1\n",
      "Extract for [122]: Conv2D stage2_unit8_conv1\n",
      "Set for [122]: Conv1D stage2_unit8_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 128) (1, 512, 128)\n",
      "Extract for [123]: BatchNormalization stage2_unit8_bn2\n",
      "Set for [123]: BatchNormalization stage2_unit8_bn2\n",
      "Extract for [124]: Activation stage2_unit8_relu2\n",
      "Set for [124]: Activation stage2_unit8_relu2\n",
      "Extract for [125]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [125]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [126]: Conv2D stage2_unit8_conv2\n",
      "Set for [126]: Conv1D stage2_unit8_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [127]: BatchNormalization stage2_unit8_bn3\n",
      "Set for [127]: BatchNormalization stage2_unit8_bn3\n",
      "Extract for [128]: Activation stage2_unit8_relu3\n",
      "Set for [128]: Activation stage2_unit8_relu3\n",
      "Extract for [129]: Conv2D stage2_unit8_conv3\n",
      "Set for [129]: Conv1D stage2_unit8_conv3\n",
      "<class 'list'> 1 (1, 1, 128, 512) (1, 128, 512)\n",
      "Extract for [130]: Add add_60\n",
      "Set for [130]: Add add_10\n",
      "Warning: different names!\n",
      "Extract for [131]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [131]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [132]: Activation stage3_unit1_relu1\n",
      "Set for [132]: Activation stage3_unit1_relu1\n",
      "Extract for [133]: Conv2D stage3_unit1_conv1\n",
      "Set for [133]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 512, 256) (1, 512, 256)\n",
      "Extract for [134]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [134]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [135]: Activation stage3_unit1_relu2\n",
      "Set for [135]: Activation stage3_unit1_relu2\n",
      "Extract for [136]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [136]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [137]: Conv2D stage3_unit1_conv2\n",
      "Set for [137]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [138]: BatchNormalization stage3_unit1_bn3\n",
      "Set for [138]: BatchNormalization stage3_unit1_bn3\n",
      "Extract for [139]: Activation stage3_unit1_relu3\n",
      "Set for [139]: Activation stage3_unit1_relu3\n",
      "Extract for [140]: Conv2D stage3_unit1_conv3\n",
      "Set for [140]: Conv1D stage3_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [141]: Conv2D stage3_unit1_sc\n",
      "Set for [141]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 512, 1024) (1, 512, 1024)\n",
      "Extract for [142]: Add add_61\n",
      "Set for [142]: Add add_11\n",
      "Warning: different names!\n",
      "Extract for [143]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [143]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [144]: Activation stage3_unit2_relu1\n",
      "Set for [144]: Activation stage3_unit2_relu1\n",
      "Extract for [145]: Conv2D stage3_unit2_conv1\n",
      "Set for [145]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [146]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [146]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [147]: Activation stage3_unit2_relu2\n",
      "Set for [147]: Activation stage3_unit2_relu2\n",
      "Extract for [148]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [148]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [149]: Conv2D stage3_unit2_conv2\n",
      "Set for [149]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [150]: BatchNormalization stage3_unit2_bn3\n",
      "Set for [150]: BatchNormalization stage3_unit2_bn3\n",
      "Extract for [151]: Activation stage3_unit2_relu3\n",
      "Set for [151]: Activation stage3_unit2_relu3\n",
      "Extract for [152]: Conv2D stage3_unit2_conv3\n",
      "Set for [152]: Conv1D stage3_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [153]: Add add_62\n",
      "Set for [153]: Add add_12\n",
      "Warning: different names!\n",
      "Extract for [154]: BatchNormalization stage3_unit3_bn1\n",
      "Set for [154]: BatchNormalization stage3_unit3_bn1\n",
      "Extract for [155]: Activation stage3_unit3_relu1\n",
      "Set for [155]: Activation stage3_unit3_relu1\n",
      "Extract for [156]: Conv2D stage3_unit3_conv1\n",
      "Set for [156]: Conv1D stage3_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [157]: BatchNormalization stage3_unit3_bn2\n",
      "Set for [157]: BatchNormalization stage3_unit3_bn2\n",
      "Extract for [158]: Activation stage3_unit3_relu2\n",
      "Set for [158]: Activation stage3_unit3_relu2\n",
      "Extract for [159]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [159]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [160]: Conv2D stage3_unit3_conv2\n",
      "Set for [160]: Conv1D stage3_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [161]: BatchNormalization stage3_unit3_bn3\n",
      "Set for [161]: BatchNormalization stage3_unit3_bn3\n",
      "Extract for [162]: Activation stage3_unit3_relu3\n",
      "Set for [162]: Activation stage3_unit3_relu3\n",
      "Extract for [163]: Conv2D stage3_unit3_conv3\n",
      "Set for [163]: Conv1D stage3_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [164]: Add add_63\n",
      "Set for [164]: Add add_13\n",
      "Warning: different names!\n",
      "Extract for [165]: BatchNormalization stage3_unit4_bn1\n",
      "Set for [165]: BatchNormalization stage3_unit4_bn1\n",
      "Extract for [166]: Activation stage3_unit4_relu1\n",
      "Set for [166]: Activation stage3_unit4_relu1\n",
      "Extract for [167]: Conv2D stage3_unit4_conv1\n",
      "Set for [167]: Conv1D stage3_unit4_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [168]: BatchNormalization stage3_unit4_bn2\n",
      "Set for [168]: BatchNormalization stage3_unit4_bn2\n",
      "Extract for [169]: Activation stage3_unit4_relu2\n",
      "Set for [169]: Activation stage3_unit4_relu2\n",
      "Extract for [170]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [170]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [171]: Conv2D stage3_unit4_conv2\n",
      "Set for [171]: Conv1D stage3_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [172]: BatchNormalization stage3_unit4_bn3\n",
      "Set for [172]: BatchNormalization stage3_unit4_bn3\n",
      "Extract for [173]: Activation stage3_unit4_relu3\n",
      "Set for [173]: Activation stage3_unit4_relu3\n",
      "Extract for [174]: Conv2D stage3_unit4_conv3\n",
      "Set for [174]: Conv1D stage3_unit4_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [175]: Add add_64\n",
      "Set for [175]: Add add_14\n",
      "Warning: different names!\n",
      "Extract for [176]: BatchNormalization stage3_unit5_bn1\n",
      "Set for [176]: BatchNormalization stage3_unit5_bn1\n",
      "Extract for [177]: Activation stage3_unit5_relu1\n",
      "Set for [177]: Activation stage3_unit5_relu1\n",
      "Extract for [178]: Conv2D stage3_unit5_conv1\n",
      "Set for [178]: Conv1D stage3_unit5_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [179]: BatchNormalization stage3_unit5_bn2\n",
      "Set for [179]: BatchNormalization stage3_unit5_bn2\n",
      "Extract for [180]: Activation stage3_unit5_relu2\n",
      "Set for [180]: Activation stage3_unit5_relu2\n",
      "Extract for [181]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [181]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [182]: Conv2D stage3_unit5_conv2\n",
      "Set for [182]: Conv1D stage3_unit5_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [183]: BatchNormalization stage3_unit5_bn3\n",
      "Set for [183]: BatchNormalization stage3_unit5_bn3\n",
      "Extract for [184]: Activation stage3_unit5_relu3\n",
      "Set for [184]: Activation stage3_unit5_relu3\n",
      "Extract for [185]: Conv2D stage3_unit5_conv3\n",
      "Set for [185]: Conv1D stage3_unit5_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [186]: Add add_65\n",
      "Set for [186]: Add add_15\n",
      "Warning: different names!\n",
      "Extract for [187]: BatchNormalization stage3_unit6_bn1\n",
      "Set for [187]: BatchNormalization stage3_unit6_bn1\n",
      "Extract for [188]: Activation stage3_unit6_relu1\n",
      "Set for [188]: Activation stage3_unit6_relu1\n",
      "Extract for [189]: Conv2D stage3_unit6_conv1\n",
      "Set for [189]: Conv1D stage3_unit6_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [190]: BatchNormalization stage3_unit6_bn2\n",
      "Set for [190]: BatchNormalization stage3_unit6_bn2\n",
      "Extract for [191]: Activation stage3_unit6_relu2\n",
      "Set for [191]: Activation stage3_unit6_relu2\n",
      "Extract for [192]: ZeroPadding2D zero_padding2d_18\n",
      "Set for [192]: ZeroPadding1D zero_padding1d_18\n",
      "Warning: different names!\n",
      "Extract for [193]: Conv2D stage3_unit6_conv2\n",
      "Set for [193]: Conv1D stage3_unit6_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [194]: BatchNormalization stage3_unit6_bn3\n",
      "Set for [194]: BatchNormalization stage3_unit6_bn3\n",
      "Extract for [195]: Activation stage3_unit6_relu3\n",
      "Set for [195]: Activation stage3_unit6_relu3\n",
      "Extract for [196]: Conv2D stage3_unit6_conv3\n",
      "Set for [196]: Conv1D stage3_unit6_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [197]: Add add_66\n",
      "Set for [197]: Add add_16\n",
      "Warning: different names!\n",
      "Extract for [198]: BatchNormalization stage3_unit7_bn1\n",
      "Set for [198]: BatchNormalization stage3_unit7_bn1\n",
      "Extract for [199]: Activation stage3_unit7_relu1\n",
      "Set for [199]: Activation stage3_unit7_relu1\n",
      "Extract for [200]: Conv2D stage3_unit7_conv1\n",
      "Set for [200]: Conv1D stage3_unit7_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [201]: BatchNormalization stage3_unit7_bn2\n",
      "Set for [201]: BatchNormalization stage3_unit7_bn2\n",
      "Extract for [202]: Activation stage3_unit7_relu2\n",
      "Set for [202]: Activation stage3_unit7_relu2\n",
      "Extract for [203]: ZeroPadding2D zero_padding2d_19\n",
      "Set for [203]: ZeroPadding1D zero_padding1d_19\n",
      "Warning: different names!\n",
      "Extract for [204]: Conv2D stage3_unit7_conv2\n",
      "Set for [204]: Conv1D stage3_unit7_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [205]: BatchNormalization stage3_unit7_bn3\n",
      "Set for [205]: BatchNormalization stage3_unit7_bn3\n",
      "Extract for [206]: Activation stage3_unit7_relu3\n",
      "Set for [206]: Activation stage3_unit7_relu3\n",
      "Extract for [207]: Conv2D stage3_unit7_conv3\n",
      "Set for [207]: Conv1D stage3_unit7_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [208]: Add add_67\n",
      "Set for [208]: Add add_17\n",
      "Warning: different names!\n",
      "Extract for [209]: BatchNormalization stage3_unit8_bn1\n",
      "Set for [209]: BatchNormalization stage3_unit8_bn1\n",
      "Extract for [210]: Activation stage3_unit8_relu1\n",
      "Set for [210]: Activation stage3_unit8_relu1\n",
      "Extract for [211]: Conv2D stage3_unit8_conv1\n",
      "Set for [211]: Conv1D stage3_unit8_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [212]: BatchNormalization stage3_unit8_bn2\n",
      "Set for [212]: BatchNormalization stage3_unit8_bn2\n",
      "Extract for [213]: Activation stage3_unit8_relu2\n",
      "Set for [213]: Activation stage3_unit8_relu2\n",
      "Extract for [214]: ZeroPadding2D zero_padding2d_20\n",
      "Set for [214]: ZeroPadding1D zero_padding1d_20\n",
      "Warning: different names!\n",
      "Extract for [215]: Conv2D stage3_unit8_conv2\n",
      "Set for [215]: Conv1D stage3_unit8_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [216]: BatchNormalization stage3_unit8_bn3\n",
      "Set for [216]: BatchNormalization stage3_unit8_bn3\n",
      "Extract for [217]: Activation stage3_unit8_relu3\n",
      "Set for [217]: Activation stage3_unit8_relu3\n",
      "Extract for [218]: Conv2D stage3_unit8_conv3\n",
      "Set for [218]: Conv1D stage3_unit8_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [219]: Add add_68\n",
      "Set for [219]: Add add_18\n",
      "Warning: different names!\n",
      "Extract for [220]: BatchNormalization stage3_unit9_bn1\n",
      "Set for [220]: BatchNormalization stage3_unit9_bn1\n",
      "Extract for [221]: Activation stage3_unit9_relu1\n",
      "Set for [221]: Activation stage3_unit9_relu1\n",
      "Extract for [222]: Conv2D stage3_unit9_conv1\n",
      "Set for [222]: Conv1D stage3_unit9_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [223]: BatchNormalization stage3_unit9_bn2\n",
      "Set for [223]: BatchNormalization stage3_unit9_bn2\n",
      "Extract for [224]: Activation stage3_unit9_relu2\n",
      "Set for [224]: Activation stage3_unit9_relu2\n",
      "Extract for [225]: ZeroPadding2D zero_padding2d_21\n",
      "Set for [225]: ZeroPadding1D zero_padding1d_21\n",
      "Warning: different names!\n",
      "Extract for [226]: Conv2D stage3_unit9_conv2\n",
      "Set for [226]: Conv1D stage3_unit9_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [227]: BatchNormalization stage3_unit9_bn3\n",
      "Set for [227]: BatchNormalization stage3_unit9_bn3\n",
      "Extract for [228]: Activation stage3_unit9_relu3\n",
      "Set for [228]: Activation stage3_unit9_relu3\n",
      "Extract for [229]: Conv2D stage3_unit9_conv3\n",
      "Set for [229]: Conv1D stage3_unit9_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [230]: Add add_69\n",
      "Set for [230]: Add add_19\n",
      "Warning: different names!\n",
      "Extract for [231]: BatchNormalization stage3_unit10_bn1\n",
      "Set for [231]: BatchNormalization stage3_unit10_bn1\n",
      "Extract for [232]: Activation stage3_unit10_relu1\n",
      "Set for [232]: Activation stage3_unit10_relu1\n",
      "Extract for [233]: Conv2D stage3_unit10_conv1\n",
      "Set for [233]: Conv1D stage3_unit10_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [234]: BatchNormalization stage3_unit10_bn2\n",
      "Set for [234]: BatchNormalization stage3_unit10_bn2\n",
      "Extract for [235]: Activation stage3_unit10_relu2\n",
      "Set for [235]: Activation stage3_unit10_relu2\n",
      "Extract for [236]: ZeroPadding2D zero_padding2d_22\n",
      "Set for [236]: ZeroPadding1D zero_padding1d_22\n",
      "Warning: different names!\n",
      "Extract for [237]: Conv2D stage3_unit10_conv2\n",
      "Set for [237]: Conv1D stage3_unit10_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [238]: BatchNormalization stage3_unit10_bn3\n",
      "Set for [238]: BatchNormalization stage3_unit10_bn3\n",
      "Extract for [239]: Activation stage3_unit10_relu3\n",
      "Set for [239]: Activation stage3_unit10_relu3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [240]: Conv2D stage3_unit10_conv3\n",
      "Set for [240]: Conv1D stage3_unit10_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [241]: Add add_70\n",
      "Set for [241]: Add add_20\n",
      "Warning: different names!\n",
      "Extract for [242]: BatchNormalization stage3_unit11_bn1\n",
      "Set for [242]: BatchNormalization stage3_unit11_bn1\n",
      "Extract for [243]: Activation stage3_unit11_relu1\n",
      "Set for [243]: Activation stage3_unit11_relu1\n",
      "Extract for [244]: Conv2D stage3_unit11_conv1\n",
      "Set for [244]: Conv1D stage3_unit11_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [245]: BatchNormalization stage3_unit11_bn2\n",
      "Set for [245]: BatchNormalization stage3_unit11_bn2\n",
      "Extract for [246]: Activation stage3_unit11_relu2\n",
      "Set for [246]: Activation stage3_unit11_relu2\n",
      "Extract for [247]: ZeroPadding2D zero_padding2d_23\n",
      "Set for [247]: ZeroPadding1D zero_padding1d_23\n",
      "Warning: different names!\n",
      "Extract for [248]: Conv2D stage3_unit11_conv2\n",
      "Set for [248]: Conv1D stage3_unit11_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [249]: BatchNormalization stage3_unit11_bn3\n",
      "Set for [249]: BatchNormalization stage3_unit11_bn3\n",
      "Extract for [250]: Activation stage3_unit11_relu3\n",
      "Set for [250]: Activation stage3_unit11_relu3\n",
      "Extract for [251]: Conv2D stage3_unit11_conv3\n",
      "Set for [251]: Conv1D stage3_unit11_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [252]: Add add_71\n",
      "Set for [252]: Add add_21\n",
      "Warning: different names!\n",
      "Extract for [253]: BatchNormalization stage3_unit12_bn1\n",
      "Set for [253]: BatchNormalization stage3_unit12_bn1\n",
      "Extract for [254]: Activation stage3_unit12_relu1\n",
      "Set for [254]: Activation stage3_unit12_relu1\n",
      "Extract for [255]: Conv2D stage3_unit12_conv1\n",
      "Set for [255]: Conv1D stage3_unit12_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [256]: BatchNormalization stage3_unit12_bn2\n",
      "Set for [256]: BatchNormalization stage3_unit12_bn2\n",
      "Extract for [257]: Activation stage3_unit12_relu2\n",
      "Set for [257]: Activation stage3_unit12_relu2\n",
      "Extract for [258]: ZeroPadding2D zero_padding2d_24\n",
      "Set for [258]: ZeroPadding1D zero_padding1d_24\n",
      "Warning: different names!\n",
      "Extract for [259]: Conv2D stage3_unit12_conv2\n",
      "Set for [259]: Conv1D stage3_unit12_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [260]: BatchNormalization stage3_unit12_bn3\n",
      "Set for [260]: BatchNormalization stage3_unit12_bn3\n",
      "Extract for [261]: Activation stage3_unit12_relu3\n",
      "Set for [261]: Activation stage3_unit12_relu3\n",
      "Extract for [262]: Conv2D stage3_unit12_conv3\n",
      "Set for [262]: Conv1D stage3_unit12_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [263]: Add add_72\n",
      "Set for [263]: Add add_22\n",
      "Warning: different names!\n",
      "Extract for [264]: BatchNormalization stage3_unit13_bn1\n",
      "Set for [264]: BatchNormalization stage3_unit13_bn1\n",
      "Extract for [265]: Activation stage3_unit13_relu1\n",
      "Set for [265]: Activation stage3_unit13_relu1\n",
      "Extract for [266]: Conv2D stage3_unit13_conv1\n",
      "Set for [266]: Conv1D stage3_unit13_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [267]: BatchNormalization stage3_unit13_bn2\n",
      "Set for [267]: BatchNormalization stage3_unit13_bn2\n",
      "Extract for [268]: Activation stage3_unit13_relu2\n",
      "Set for [268]: Activation stage3_unit13_relu2\n",
      "Extract for [269]: ZeroPadding2D zero_padding2d_25\n",
      "Set for [269]: ZeroPadding1D zero_padding1d_25\n",
      "Warning: different names!\n",
      "Extract for [270]: Conv2D stage3_unit13_conv2\n",
      "Set for [270]: Conv1D stage3_unit13_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [271]: BatchNormalization stage3_unit13_bn3\n",
      "Set for [271]: BatchNormalization stage3_unit13_bn3\n",
      "Extract for [272]: Activation stage3_unit13_relu3\n",
      "Set for [272]: Activation stage3_unit13_relu3\n",
      "Extract for [273]: Conv2D stage3_unit13_conv3\n",
      "Set for [273]: Conv1D stage3_unit13_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [274]: Add add_73\n",
      "Set for [274]: Add add_23\n",
      "Warning: different names!\n",
      "Extract for [275]: BatchNormalization stage3_unit14_bn1\n",
      "Set for [275]: BatchNormalization stage3_unit14_bn1\n",
      "Extract for [276]: Activation stage3_unit14_relu1\n",
      "Set for [276]: Activation stage3_unit14_relu1\n",
      "Extract for [277]: Conv2D stage3_unit14_conv1\n",
      "Set for [277]: Conv1D stage3_unit14_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [278]: BatchNormalization stage3_unit14_bn2\n",
      "Set for [278]: BatchNormalization stage3_unit14_bn2\n",
      "Extract for [279]: Activation stage3_unit14_relu2\n",
      "Set for [279]: Activation stage3_unit14_relu2\n",
      "Extract for [280]: ZeroPadding2D zero_padding2d_26\n",
      "Set for [280]: ZeroPadding1D zero_padding1d_26\n",
      "Warning: different names!\n",
      "Extract for [281]: Conv2D stage3_unit14_conv2\n",
      "Set for [281]: Conv1D stage3_unit14_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [282]: BatchNormalization stage3_unit14_bn3\n",
      "Set for [282]: BatchNormalization stage3_unit14_bn3\n",
      "Extract for [283]: Activation stage3_unit14_relu3\n",
      "Set for [283]: Activation stage3_unit14_relu3\n",
      "Extract for [284]: Conv2D stage3_unit14_conv3\n",
      "Set for [284]: Conv1D stage3_unit14_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [285]: Add add_74\n",
      "Set for [285]: Add add_24\n",
      "Warning: different names!\n",
      "Extract for [286]: BatchNormalization stage3_unit15_bn1\n",
      "Set for [286]: BatchNormalization stage3_unit15_bn1\n",
      "Extract for [287]: Activation stage3_unit15_relu1\n",
      "Set for [287]: Activation stage3_unit15_relu1\n",
      "Extract for [288]: Conv2D stage3_unit15_conv1\n",
      "Set for [288]: Conv1D stage3_unit15_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [289]: BatchNormalization stage3_unit15_bn2\n",
      "Set for [289]: BatchNormalization stage3_unit15_bn2\n",
      "Extract for [290]: Activation stage3_unit15_relu2\n",
      "Set for [290]: Activation stage3_unit15_relu2\n",
      "Extract for [291]: ZeroPadding2D zero_padding2d_27\n",
      "Set for [291]: ZeroPadding1D zero_padding1d_27\n",
      "Warning: different names!\n",
      "Extract for [292]: Conv2D stage3_unit15_conv2\n",
      "Set for [292]: Conv1D stage3_unit15_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [293]: BatchNormalization stage3_unit15_bn3\n",
      "Set for [293]: BatchNormalization stage3_unit15_bn3\n",
      "Extract for [294]: Activation stage3_unit15_relu3\n",
      "Set for [294]: Activation stage3_unit15_relu3\n",
      "Extract for [295]: Conv2D stage3_unit15_conv3\n",
      "Set for [295]: Conv1D stage3_unit15_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [296]: Add add_75\n",
      "Set for [296]: Add add_25\n",
      "Warning: different names!\n",
      "Extract for [297]: BatchNormalization stage3_unit16_bn1\n",
      "Set for [297]: BatchNormalization stage3_unit16_bn1\n",
      "Extract for [298]: Activation stage3_unit16_relu1\n",
      "Set for [298]: Activation stage3_unit16_relu1\n",
      "Extract for [299]: Conv2D stage3_unit16_conv1\n",
      "Set for [299]: Conv1D stage3_unit16_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [300]: BatchNormalization stage3_unit16_bn2\n",
      "Set for [300]: BatchNormalization stage3_unit16_bn2\n",
      "Extract for [301]: Activation stage3_unit16_relu2\n",
      "Set for [301]: Activation stage3_unit16_relu2\n",
      "Extract for [302]: ZeroPadding2D zero_padding2d_28\n",
      "Set for [302]: ZeroPadding1D zero_padding1d_28\n",
      "Warning: different names!\n",
      "Extract for [303]: Conv2D stage3_unit16_conv2\n",
      "Set for [303]: Conv1D stage3_unit16_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [304]: BatchNormalization stage3_unit16_bn3\n",
      "Set for [304]: BatchNormalization stage3_unit16_bn3\n",
      "Extract for [305]: Activation stage3_unit16_relu3\n",
      "Set for [305]: Activation stage3_unit16_relu3\n",
      "Extract for [306]: Conv2D stage3_unit16_conv3\n",
      "Set for [306]: Conv1D stage3_unit16_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [307]: Add add_76\n",
      "Set for [307]: Add add_26\n",
      "Warning: different names!\n",
      "Extract for [308]: BatchNormalization stage3_unit17_bn1\n",
      "Set for [308]: BatchNormalization stage3_unit17_bn1\n",
      "Extract for [309]: Activation stage3_unit17_relu1\n",
      "Set for [309]: Activation stage3_unit17_relu1\n",
      "Extract for [310]: Conv2D stage3_unit17_conv1\n",
      "Set for [310]: Conv1D stage3_unit17_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [311]: BatchNormalization stage3_unit17_bn2\n",
      "Set for [311]: BatchNormalization stage3_unit17_bn2\n",
      "Extract for [312]: Activation stage3_unit17_relu2\n",
      "Set for [312]: Activation stage3_unit17_relu2\n",
      "Extract for [313]: ZeroPadding2D zero_padding2d_29\n",
      "Set for [313]: ZeroPadding1D zero_padding1d_29\n",
      "Warning: different names!\n",
      "Extract for [314]: Conv2D stage3_unit17_conv2\n",
      "Set for [314]: Conv1D stage3_unit17_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [315]: BatchNormalization stage3_unit17_bn3\n",
      "Set for [315]: BatchNormalization stage3_unit17_bn3\n",
      "Extract for [316]: Activation stage3_unit17_relu3\n",
      "Set for [316]: Activation stage3_unit17_relu3\n",
      "Extract for [317]: Conv2D stage3_unit17_conv3\n",
      "Set for [317]: Conv1D stage3_unit17_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [318]: Add add_77\n",
      "Set for [318]: Add add_27\n",
      "Warning: different names!\n",
      "Extract for [319]: BatchNormalization stage3_unit18_bn1\n",
      "Set for [319]: BatchNormalization stage3_unit18_bn1\n",
      "Extract for [320]: Activation stage3_unit18_relu1\n",
      "Set for [320]: Activation stage3_unit18_relu1\n",
      "Extract for [321]: Conv2D stage3_unit18_conv1\n",
      "Set for [321]: Conv1D stage3_unit18_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [322]: BatchNormalization stage3_unit18_bn2\n",
      "Set for [322]: BatchNormalization stage3_unit18_bn2\n",
      "Extract for [323]: Activation stage3_unit18_relu2\n",
      "Set for [323]: Activation stage3_unit18_relu2\n",
      "Extract for [324]: ZeroPadding2D zero_padding2d_30\n",
      "Set for [324]: ZeroPadding1D zero_padding1d_30\n",
      "Warning: different names!\n",
      "Extract for [325]: Conv2D stage3_unit18_conv2\n",
      "Set for [325]: Conv1D stage3_unit18_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [326]: BatchNormalization stage3_unit18_bn3\n",
      "Set for [326]: BatchNormalization stage3_unit18_bn3\n",
      "Extract for [327]: Activation stage3_unit18_relu3\n",
      "Set for [327]: Activation stage3_unit18_relu3\n",
      "Extract for [328]: Conv2D stage3_unit18_conv3\n",
      "Set for [328]: Conv1D stage3_unit18_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [329]: Add add_78\n",
      "Set for [329]: Add add_28\n",
      "Warning: different names!\n",
      "Extract for [330]: BatchNormalization stage3_unit19_bn1\n",
      "Set for [330]: BatchNormalization stage3_unit19_bn1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [331]: Activation stage3_unit19_relu1\n",
      "Set for [331]: Activation stage3_unit19_relu1\n",
      "Extract for [332]: Conv2D stage3_unit19_conv1\n",
      "Set for [332]: Conv1D stage3_unit19_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [333]: BatchNormalization stage3_unit19_bn2\n",
      "Set for [333]: BatchNormalization stage3_unit19_bn2\n",
      "Extract for [334]: Activation stage3_unit19_relu2\n",
      "Set for [334]: Activation stage3_unit19_relu2\n",
      "Extract for [335]: ZeroPadding2D zero_padding2d_31\n",
      "Set for [335]: ZeroPadding1D zero_padding1d_31\n",
      "Warning: different names!\n",
      "Extract for [336]: Conv2D stage3_unit19_conv2\n",
      "Set for [336]: Conv1D stage3_unit19_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [337]: BatchNormalization stage3_unit19_bn3\n",
      "Set for [337]: BatchNormalization stage3_unit19_bn3\n",
      "Extract for [338]: Activation stage3_unit19_relu3\n",
      "Set for [338]: Activation stage3_unit19_relu3\n",
      "Extract for [339]: Conv2D stage3_unit19_conv3\n",
      "Set for [339]: Conv1D stage3_unit19_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [340]: Add add_79\n",
      "Set for [340]: Add add_29\n",
      "Warning: different names!\n",
      "Extract for [341]: BatchNormalization stage3_unit20_bn1\n",
      "Set for [341]: BatchNormalization stage3_unit20_bn1\n",
      "Extract for [342]: Activation stage3_unit20_relu1\n",
      "Set for [342]: Activation stage3_unit20_relu1\n",
      "Extract for [343]: Conv2D stage3_unit20_conv1\n",
      "Set for [343]: Conv1D stage3_unit20_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [344]: BatchNormalization stage3_unit20_bn2\n",
      "Set for [344]: BatchNormalization stage3_unit20_bn2\n",
      "Extract for [345]: Activation stage3_unit20_relu2\n",
      "Set for [345]: Activation stage3_unit20_relu2\n",
      "Extract for [346]: ZeroPadding2D zero_padding2d_32\n",
      "Set for [346]: ZeroPadding1D zero_padding1d_32\n",
      "Warning: different names!\n",
      "Extract for [347]: Conv2D stage3_unit20_conv2\n",
      "Set for [347]: Conv1D stage3_unit20_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [348]: BatchNormalization stage3_unit20_bn3\n",
      "Set for [348]: BatchNormalization stage3_unit20_bn3\n",
      "Extract for [349]: Activation stage3_unit20_relu3\n",
      "Set for [349]: Activation stage3_unit20_relu3\n",
      "Extract for [350]: Conv2D stage3_unit20_conv3\n",
      "Set for [350]: Conv1D stage3_unit20_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [351]: Add add_80\n",
      "Set for [351]: Add add_30\n",
      "Warning: different names!\n",
      "Extract for [352]: BatchNormalization stage3_unit21_bn1\n",
      "Set for [352]: BatchNormalization stage3_unit21_bn1\n",
      "Extract for [353]: Activation stage3_unit21_relu1\n",
      "Set for [353]: Activation stage3_unit21_relu1\n",
      "Extract for [354]: Conv2D stage3_unit21_conv1\n",
      "Set for [354]: Conv1D stage3_unit21_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [355]: BatchNormalization stage3_unit21_bn2\n",
      "Set for [355]: BatchNormalization stage3_unit21_bn2\n",
      "Extract for [356]: Activation stage3_unit21_relu2\n",
      "Set for [356]: Activation stage3_unit21_relu2\n",
      "Extract for [357]: ZeroPadding2D zero_padding2d_33\n",
      "Set for [357]: ZeroPadding1D zero_padding1d_33\n",
      "Warning: different names!\n",
      "Extract for [358]: Conv2D stage3_unit21_conv2\n",
      "Set for [358]: Conv1D stage3_unit21_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [359]: BatchNormalization stage3_unit21_bn3\n",
      "Set for [359]: BatchNormalization stage3_unit21_bn3\n",
      "Extract for [360]: Activation stage3_unit21_relu3\n",
      "Set for [360]: Activation stage3_unit21_relu3\n",
      "Extract for [361]: Conv2D stage3_unit21_conv3\n",
      "Set for [361]: Conv1D stage3_unit21_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [362]: Add add_81\n",
      "Set for [362]: Add add_31\n",
      "Warning: different names!\n",
      "Extract for [363]: BatchNormalization stage3_unit22_bn1\n",
      "Set for [363]: BatchNormalization stage3_unit22_bn1\n",
      "Extract for [364]: Activation stage3_unit22_relu1\n",
      "Set for [364]: Activation stage3_unit22_relu1\n",
      "Extract for [365]: Conv2D stage3_unit22_conv1\n",
      "Set for [365]: Conv1D stage3_unit22_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [366]: BatchNormalization stage3_unit22_bn2\n",
      "Set for [366]: BatchNormalization stage3_unit22_bn2\n",
      "Extract for [367]: Activation stage3_unit22_relu2\n",
      "Set for [367]: Activation stage3_unit22_relu2\n",
      "Extract for [368]: ZeroPadding2D zero_padding2d_34\n",
      "Set for [368]: ZeroPadding1D zero_padding1d_34\n",
      "Warning: different names!\n",
      "Extract for [369]: Conv2D stage3_unit22_conv2\n",
      "Set for [369]: Conv1D stage3_unit22_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [370]: BatchNormalization stage3_unit22_bn3\n",
      "Set for [370]: BatchNormalization stage3_unit22_bn3\n",
      "Extract for [371]: Activation stage3_unit22_relu3\n",
      "Set for [371]: Activation stage3_unit22_relu3\n",
      "Extract for [372]: Conv2D stage3_unit22_conv3\n",
      "Set for [372]: Conv1D stage3_unit22_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [373]: Add add_82\n",
      "Set for [373]: Add add_32\n",
      "Warning: different names!\n",
      "Extract for [374]: BatchNormalization stage3_unit23_bn1\n",
      "Set for [374]: BatchNormalization stage3_unit23_bn1\n",
      "Extract for [375]: Activation stage3_unit23_relu1\n",
      "Set for [375]: Activation stage3_unit23_relu1\n",
      "Extract for [376]: Conv2D stage3_unit23_conv1\n",
      "Set for [376]: Conv1D stage3_unit23_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [377]: BatchNormalization stage3_unit23_bn2\n",
      "Set for [377]: BatchNormalization stage3_unit23_bn2\n",
      "Extract for [378]: Activation stage3_unit23_relu2\n",
      "Set for [378]: Activation stage3_unit23_relu2\n",
      "Extract for [379]: ZeroPadding2D zero_padding2d_35\n",
      "Set for [379]: ZeroPadding1D zero_padding1d_35\n",
      "Warning: different names!\n",
      "Extract for [380]: Conv2D stage3_unit23_conv2\n",
      "Set for [380]: Conv1D stage3_unit23_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [381]: BatchNormalization stage3_unit23_bn3\n",
      "Set for [381]: BatchNormalization stage3_unit23_bn3\n",
      "Extract for [382]: Activation stage3_unit23_relu3\n",
      "Set for [382]: Activation stage3_unit23_relu3\n",
      "Extract for [383]: Conv2D stage3_unit23_conv3\n",
      "Set for [383]: Conv1D stage3_unit23_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [384]: Add add_83\n",
      "Set for [384]: Add add_33\n",
      "Warning: different names!\n",
      "Extract for [385]: BatchNormalization stage3_unit24_bn1\n",
      "Set for [385]: BatchNormalization stage3_unit24_bn1\n",
      "Extract for [386]: Activation stage3_unit24_relu1\n",
      "Set for [386]: Activation stage3_unit24_relu1\n",
      "Extract for [387]: Conv2D stage3_unit24_conv1\n",
      "Set for [387]: Conv1D stage3_unit24_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [388]: BatchNormalization stage3_unit24_bn2\n",
      "Set for [388]: BatchNormalization stage3_unit24_bn2\n",
      "Extract for [389]: Activation stage3_unit24_relu2\n",
      "Set for [389]: Activation stage3_unit24_relu2\n",
      "Extract for [390]: ZeroPadding2D zero_padding2d_36\n",
      "Set for [390]: ZeroPadding1D zero_padding1d_36\n",
      "Warning: different names!\n",
      "Extract for [391]: Conv2D stage3_unit24_conv2\n",
      "Set for [391]: Conv1D stage3_unit24_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [392]: BatchNormalization stage3_unit24_bn3\n",
      "Set for [392]: BatchNormalization stage3_unit24_bn3\n",
      "Extract for [393]: Activation stage3_unit24_relu3\n",
      "Set for [393]: Activation stage3_unit24_relu3\n",
      "Extract for [394]: Conv2D stage3_unit24_conv3\n",
      "Set for [394]: Conv1D stage3_unit24_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [395]: Add add_84\n",
      "Set for [395]: Add add_34\n",
      "Warning: different names!\n",
      "Extract for [396]: BatchNormalization stage3_unit25_bn1\n",
      "Set for [396]: BatchNormalization stage3_unit25_bn1\n",
      "Extract for [397]: Activation stage3_unit25_relu1\n",
      "Set for [397]: Activation stage3_unit25_relu1\n",
      "Extract for [398]: Conv2D stage3_unit25_conv1\n",
      "Set for [398]: Conv1D stage3_unit25_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [399]: BatchNormalization stage3_unit25_bn2\n",
      "Set for [399]: BatchNormalization stage3_unit25_bn2\n",
      "Extract for [400]: Activation stage3_unit25_relu2\n",
      "Set for [400]: Activation stage3_unit25_relu2\n",
      "Extract for [401]: ZeroPadding2D zero_padding2d_37\n",
      "Set for [401]: ZeroPadding1D zero_padding1d_37\n",
      "Warning: different names!\n",
      "Extract for [402]: Conv2D stage3_unit25_conv2\n",
      "Set for [402]: Conv1D stage3_unit25_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [403]: BatchNormalization stage3_unit25_bn3\n",
      "Set for [403]: BatchNormalization stage3_unit25_bn3\n",
      "Extract for [404]: Activation stage3_unit25_relu3\n",
      "Set for [404]: Activation stage3_unit25_relu3\n",
      "Extract for [405]: Conv2D stage3_unit25_conv3\n",
      "Set for [405]: Conv1D stage3_unit25_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [406]: Add add_85\n",
      "Set for [406]: Add add_35\n",
      "Warning: different names!\n",
      "Extract for [407]: BatchNormalization stage3_unit26_bn1\n",
      "Set for [407]: BatchNormalization stage3_unit26_bn1\n",
      "Extract for [408]: Activation stage3_unit26_relu1\n",
      "Set for [408]: Activation stage3_unit26_relu1\n",
      "Extract for [409]: Conv2D stage3_unit26_conv1\n",
      "Set for [409]: Conv1D stage3_unit26_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [410]: BatchNormalization stage3_unit26_bn2\n",
      "Set for [410]: BatchNormalization stage3_unit26_bn2\n",
      "Extract for [411]: Activation stage3_unit26_relu2\n",
      "Set for [411]: Activation stage3_unit26_relu2\n",
      "Extract for [412]: ZeroPadding2D zero_padding2d_38\n",
      "Set for [412]: ZeroPadding1D zero_padding1d_38\n",
      "Warning: different names!\n",
      "Extract for [413]: Conv2D stage3_unit26_conv2\n",
      "Set for [413]: Conv1D stage3_unit26_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [414]: BatchNormalization stage3_unit26_bn3\n",
      "Set for [414]: BatchNormalization stage3_unit26_bn3\n",
      "Extract for [415]: Activation stage3_unit26_relu3\n",
      "Set for [415]: Activation stage3_unit26_relu3\n",
      "Extract for [416]: Conv2D stage3_unit26_conv3\n",
      "Set for [416]: Conv1D stage3_unit26_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [417]: Add add_86\n",
      "Set for [417]: Add add_36\n",
      "Warning: different names!\n",
      "Extract for [418]: BatchNormalization stage3_unit27_bn1\n",
      "Set for [418]: BatchNormalization stage3_unit27_bn1\n",
      "Extract for [419]: Activation stage3_unit27_relu1\n",
      "Set for [419]: Activation stage3_unit27_relu1\n",
      "Extract for [420]: Conv2D stage3_unit27_conv1\n",
      "Set for [420]: Conv1D stage3_unit27_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [421]: BatchNormalization stage3_unit27_bn2\n",
      "Set for [421]: BatchNormalization stage3_unit27_bn2\n",
      "Extract for [422]: Activation stage3_unit27_relu2\n",
      "Set for [422]: Activation stage3_unit27_relu2\n",
      "Extract for [423]: ZeroPadding2D zero_padding2d_39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set for [423]: ZeroPadding1D zero_padding1d_39\n",
      "Warning: different names!\n",
      "Extract for [424]: Conv2D stage3_unit27_conv2\n",
      "Set for [424]: Conv1D stage3_unit27_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [425]: BatchNormalization stage3_unit27_bn3\n",
      "Set for [425]: BatchNormalization stage3_unit27_bn3\n",
      "Extract for [426]: Activation stage3_unit27_relu3\n",
      "Set for [426]: Activation stage3_unit27_relu3\n",
      "Extract for [427]: Conv2D stage3_unit27_conv3\n",
      "Set for [427]: Conv1D stage3_unit27_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [428]: Add add_87\n",
      "Set for [428]: Add add_37\n",
      "Warning: different names!\n",
      "Extract for [429]: BatchNormalization stage3_unit28_bn1\n",
      "Set for [429]: BatchNormalization stage3_unit28_bn1\n",
      "Extract for [430]: Activation stage3_unit28_relu1\n",
      "Set for [430]: Activation stage3_unit28_relu1\n",
      "Extract for [431]: Conv2D stage3_unit28_conv1\n",
      "Set for [431]: Conv1D stage3_unit28_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [432]: BatchNormalization stage3_unit28_bn2\n",
      "Set for [432]: BatchNormalization stage3_unit28_bn2\n",
      "Extract for [433]: Activation stage3_unit28_relu2\n",
      "Set for [433]: Activation stage3_unit28_relu2\n",
      "Extract for [434]: ZeroPadding2D zero_padding2d_40\n",
      "Set for [434]: ZeroPadding1D zero_padding1d_40\n",
      "Warning: different names!\n",
      "Extract for [435]: Conv2D stage3_unit28_conv2\n",
      "Set for [435]: Conv1D stage3_unit28_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [436]: BatchNormalization stage3_unit28_bn3\n",
      "Set for [436]: BatchNormalization stage3_unit28_bn3\n",
      "Extract for [437]: Activation stage3_unit28_relu3\n",
      "Set for [437]: Activation stage3_unit28_relu3\n",
      "Extract for [438]: Conv2D stage3_unit28_conv3\n",
      "Set for [438]: Conv1D stage3_unit28_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [439]: Add add_88\n",
      "Set for [439]: Add add_38\n",
      "Warning: different names!\n",
      "Extract for [440]: BatchNormalization stage3_unit29_bn1\n",
      "Set for [440]: BatchNormalization stage3_unit29_bn1\n",
      "Extract for [441]: Activation stage3_unit29_relu1\n",
      "Set for [441]: Activation stage3_unit29_relu1\n",
      "Extract for [442]: Conv2D stage3_unit29_conv1\n",
      "Set for [442]: Conv1D stage3_unit29_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [443]: BatchNormalization stage3_unit29_bn2\n",
      "Set for [443]: BatchNormalization stage3_unit29_bn2\n",
      "Extract for [444]: Activation stage3_unit29_relu2\n",
      "Set for [444]: Activation stage3_unit29_relu2\n",
      "Extract for [445]: ZeroPadding2D zero_padding2d_41\n",
      "Set for [445]: ZeroPadding1D zero_padding1d_41\n",
      "Warning: different names!\n",
      "Extract for [446]: Conv2D stage3_unit29_conv2\n",
      "Set for [446]: Conv1D stage3_unit29_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [447]: BatchNormalization stage3_unit29_bn3\n",
      "Set for [447]: BatchNormalization stage3_unit29_bn3\n",
      "Extract for [448]: Activation stage3_unit29_relu3\n",
      "Set for [448]: Activation stage3_unit29_relu3\n",
      "Extract for [449]: Conv2D stage3_unit29_conv3\n",
      "Set for [449]: Conv1D stage3_unit29_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [450]: Add add_89\n",
      "Set for [450]: Add add_39\n",
      "Warning: different names!\n",
      "Extract for [451]: BatchNormalization stage3_unit30_bn1\n",
      "Set for [451]: BatchNormalization stage3_unit30_bn1\n",
      "Extract for [452]: Activation stage3_unit30_relu1\n",
      "Set for [452]: Activation stage3_unit30_relu1\n",
      "Extract for [453]: Conv2D stage3_unit30_conv1\n",
      "Set for [453]: Conv1D stage3_unit30_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [454]: BatchNormalization stage3_unit30_bn2\n",
      "Set for [454]: BatchNormalization stage3_unit30_bn2\n",
      "Extract for [455]: Activation stage3_unit30_relu2\n",
      "Set for [455]: Activation stage3_unit30_relu2\n",
      "Extract for [456]: ZeroPadding2D zero_padding2d_42\n",
      "Set for [456]: ZeroPadding1D zero_padding1d_42\n",
      "Warning: different names!\n",
      "Extract for [457]: Conv2D stage3_unit30_conv2\n",
      "Set for [457]: Conv1D stage3_unit30_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [458]: BatchNormalization stage3_unit30_bn3\n",
      "Set for [458]: BatchNormalization stage3_unit30_bn3\n",
      "Extract for [459]: Activation stage3_unit30_relu3\n",
      "Set for [459]: Activation stage3_unit30_relu3\n",
      "Extract for [460]: Conv2D stage3_unit30_conv3\n",
      "Set for [460]: Conv1D stage3_unit30_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [461]: Add add_90\n",
      "Set for [461]: Add add_40\n",
      "Warning: different names!\n",
      "Extract for [462]: BatchNormalization stage3_unit31_bn1\n",
      "Set for [462]: BatchNormalization stage3_unit31_bn1\n",
      "Extract for [463]: Activation stage3_unit31_relu1\n",
      "Set for [463]: Activation stage3_unit31_relu1\n",
      "Extract for [464]: Conv2D stage3_unit31_conv1\n",
      "Set for [464]: Conv1D stage3_unit31_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [465]: BatchNormalization stage3_unit31_bn2\n",
      "Set for [465]: BatchNormalization stage3_unit31_bn2\n",
      "Extract for [466]: Activation stage3_unit31_relu2\n",
      "Set for [466]: Activation stage3_unit31_relu2\n",
      "Extract for [467]: ZeroPadding2D zero_padding2d_43\n",
      "Set for [467]: ZeroPadding1D zero_padding1d_43\n",
      "Warning: different names!\n",
      "Extract for [468]: Conv2D stage3_unit31_conv2\n",
      "Set for [468]: Conv1D stage3_unit31_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [469]: BatchNormalization stage3_unit31_bn3\n",
      "Set for [469]: BatchNormalization stage3_unit31_bn3\n",
      "Extract for [470]: Activation stage3_unit31_relu3\n",
      "Set for [470]: Activation stage3_unit31_relu3\n",
      "Extract for [471]: Conv2D stage3_unit31_conv3\n",
      "Set for [471]: Conv1D stage3_unit31_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [472]: Add add_91\n",
      "Set for [472]: Add add_41\n",
      "Warning: different names!\n",
      "Extract for [473]: BatchNormalization stage3_unit32_bn1\n",
      "Set for [473]: BatchNormalization stage3_unit32_bn1\n",
      "Extract for [474]: Activation stage3_unit32_relu1\n",
      "Set for [474]: Activation stage3_unit32_relu1\n",
      "Extract for [475]: Conv2D stage3_unit32_conv1\n",
      "Set for [475]: Conv1D stage3_unit32_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [476]: BatchNormalization stage3_unit32_bn2\n",
      "Set for [476]: BatchNormalization stage3_unit32_bn2\n",
      "Extract for [477]: Activation stage3_unit32_relu2\n",
      "Set for [477]: Activation stage3_unit32_relu2\n",
      "Extract for [478]: ZeroPadding2D zero_padding2d_44\n",
      "Set for [478]: ZeroPadding1D zero_padding1d_44\n",
      "Warning: different names!\n",
      "Extract for [479]: Conv2D stage3_unit32_conv2\n",
      "Set for [479]: Conv1D stage3_unit32_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [480]: BatchNormalization stage3_unit32_bn3\n",
      "Set for [480]: BatchNormalization stage3_unit32_bn3\n",
      "Extract for [481]: Activation stage3_unit32_relu3\n",
      "Set for [481]: Activation stage3_unit32_relu3\n",
      "Extract for [482]: Conv2D stage3_unit32_conv3\n",
      "Set for [482]: Conv1D stage3_unit32_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [483]: Add add_92\n",
      "Set for [483]: Add add_42\n",
      "Warning: different names!\n",
      "Extract for [484]: BatchNormalization stage3_unit33_bn1\n",
      "Set for [484]: BatchNormalization stage3_unit33_bn1\n",
      "Extract for [485]: Activation stage3_unit33_relu1\n",
      "Set for [485]: Activation stage3_unit33_relu1\n",
      "Extract for [486]: Conv2D stage3_unit33_conv1\n",
      "Set for [486]: Conv1D stage3_unit33_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [487]: BatchNormalization stage3_unit33_bn2\n",
      "Set for [487]: BatchNormalization stage3_unit33_bn2\n",
      "Extract for [488]: Activation stage3_unit33_relu2\n",
      "Set for [488]: Activation stage3_unit33_relu2\n",
      "Extract for [489]: ZeroPadding2D zero_padding2d_45\n",
      "Set for [489]: ZeroPadding1D zero_padding1d_45\n",
      "Warning: different names!\n",
      "Extract for [490]: Conv2D stage3_unit33_conv2\n",
      "Set for [490]: Conv1D stage3_unit33_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [491]: BatchNormalization stage3_unit33_bn3\n",
      "Set for [491]: BatchNormalization stage3_unit33_bn3\n",
      "Extract for [492]: Activation stage3_unit33_relu3\n",
      "Set for [492]: Activation stage3_unit33_relu3\n",
      "Extract for [493]: Conv2D stage3_unit33_conv3\n",
      "Set for [493]: Conv1D stage3_unit33_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [494]: Add add_93\n",
      "Set for [494]: Add add_43\n",
      "Warning: different names!\n",
      "Extract for [495]: BatchNormalization stage3_unit34_bn1\n",
      "Set for [495]: BatchNormalization stage3_unit34_bn1\n",
      "Extract for [496]: Activation stage3_unit34_relu1\n",
      "Set for [496]: Activation stage3_unit34_relu1\n",
      "Extract for [497]: Conv2D stage3_unit34_conv1\n",
      "Set for [497]: Conv1D stage3_unit34_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [498]: BatchNormalization stage3_unit34_bn2\n",
      "Set for [498]: BatchNormalization stage3_unit34_bn2\n",
      "Extract for [499]: Activation stage3_unit34_relu2\n",
      "Set for [499]: Activation stage3_unit34_relu2\n",
      "Extract for [500]: ZeroPadding2D zero_padding2d_46\n",
      "Set for [500]: ZeroPadding1D zero_padding1d_46\n",
      "Warning: different names!\n",
      "Extract for [501]: Conv2D stage3_unit34_conv2\n",
      "Set for [501]: Conv1D stage3_unit34_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [502]: BatchNormalization stage3_unit34_bn3\n",
      "Set for [502]: BatchNormalization stage3_unit34_bn3\n",
      "Extract for [503]: Activation stage3_unit34_relu3\n",
      "Set for [503]: Activation stage3_unit34_relu3\n",
      "Extract for [504]: Conv2D stage3_unit34_conv3\n",
      "Set for [504]: Conv1D stage3_unit34_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [505]: Add add_94\n",
      "Set for [505]: Add add_44\n",
      "Warning: different names!\n",
      "Extract for [506]: BatchNormalization stage3_unit35_bn1\n",
      "Set for [506]: BatchNormalization stage3_unit35_bn1\n",
      "Extract for [507]: Activation stage3_unit35_relu1\n",
      "Set for [507]: Activation stage3_unit35_relu1\n",
      "Extract for [508]: Conv2D stage3_unit35_conv1\n",
      "Set for [508]: Conv1D stage3_unit35_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [509]: BatchNormalization stage3_unit35_bn2\n",
      "Set for [509]: BatchNormalization stage3_unit35_bn2\n",
      "Extract for [510]: Activation stage3_unit35_relu2\n",
      "Set for [510]: Activation stage3_unit35_relu2\n",
      "Extract for [511]: ZeroPadding2D zero_padding2d_47\n",
      "Set for [511]: ZeroPadding1D zero_padding1d_47\n",
      "Warning: different names!\n",
      "Extract for [512]: Conv2D stage3_unit35_conv2\n",
      "Set for [512]: Conv1D stage3_unit35_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [513]: BatchNormalization stage3_unit35_bn3\n",
      "Set for [513]: BatchNormalization stage3_unit35_bn3\n",
      "Extract for [514]: Activation stage3_unit35_relu3\n",
      "Set for [514]: Activation stage3_unit35_relu3\n",
      "Extract for [515]: Conv2D stage3_unit35_conv3\n",
      "Set for [515]: Conv1D stage3_unit35_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [516]: Add add_95\n",
      "Set for [516]: Add add_45\n",
      "Warning: different names!\n",
      "Extract for [517]: BatchNormalization stage3_unit36_bn1\n",
      "Set for [517]: BatchNormalization stage3_unit36_bn1\n",
      "Extract for [518]: Activation stage3_unit36_relu1\n",
      "Set for [518]: Activation stage3_unit36_relu1\n",
      "Extract for [519]: Conv2D stage3_unit36_conv1\n",
      "Set for [519]: Conv1D stage3_unit36_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 256) (1, 1024, 256)\n",
      "Extract for [520]: BatchNormalization stage3_unit36_bn2\n",
      "Set for [520]: BatchNormalization stage3_unit36_bn2\n",
      "Extract for [521]: Activation stage3_unit36_relu2\n",
      "Set for [521]: Activation stage3_unit36_relu2\n",
      "Extract for [522]: ZeroPadding2D zero_padding2d_48\n",
      "Set for [522]: ZeroPadding1D zero_padding1d_48\n",
      "Warning: different names!\n",
      "Extract for [523]: Conv2D stage3_unit36_conv2\n",
      "Set for [523]: Conv1D stage3_unit36_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [524]: BatchNormalization stage3_unit36_bn3\n",
      "Set for [524]: BatchNormalization stage3_unit36_bn3\n",
      "Extract for [525]: Activation stage3_unit36_relu3\n",
      "Set for [525]: Activation stage3_unit36_relu3\n",
      "Extract for [526]: Conv2D stage3_unit36_conv3\n",
      "Set for [526]: Conv1D stage3_unit36_conv3\n",
      "<class 'list'> 1 (1, 1, 256, 1024) (1, 256, 1024)\n",
      "Extract for [527]: Add add_96\n",
      "Set for [527]: Add add_46\n",
      "Warning: different names!\n",
      "Extract for [528]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [528]: BatchNormalization stage4_unit1_bn1\n",
      "Extract for [529]: Activation stage4_unit1_relu1\n",
      "Set for [529]: Activation stage4_unit1_relu1\n",
      "Extract for [530]: Conv2D stage4_unit1_conv1\n",
      "Set for [530]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (1, 1, 1024, 512) (1, 1024, 512)\n",
      "Extract for [531]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [531]: BatchNormalization stage4_unit1_bn2\n",
      "Extract for [532]: Activation stage4_unit1_relu2\n",
      "Set for [532]: Activation stage4_unit1_relu2\n",
      "Extract for [533]: ZeroPadding2D zero_padding2d_49\n",
      "Set for [533]: ZeroPadding1D zero_padding1d_49\n",
      "Warning: different names!\n",
      "Extract for [534]: Conv2D stage4_unit1_conv2\n",
      "Set for [534]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [535]: BatchNormalization stage4_unit1_bn3\n",
      "Set for [535]: BatchNormalization stage4_unit1_bn3\n",
      "Extract for [536]: Activation stage4_unit1_relu3\n",
      "Set for [536]: Activation stage4_unit1_relu3\n",
      "Extract for [537]: Conv2D stage4_unit1_conv3\n",
      "Set for [537]: Conv1D stage4_unit1_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [538]: Conv2D stage4_unit1_sc\n",
      "Set for [538]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 1024, 2048) (1, 1024, 2048)\n",
      "Extract for [539]: Add add_97\n",
      "Set for [539]: Add add_47\n",
      "Warning: different names!\n",
      "Extract for [540]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [540]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [541]: Activation stage4_unit2_relu1\n",
      "Set for [541]: Activation stage4_unit2_relu1\n",
      "Extract for [542]: Conv2D stage4_unit2_conv1\n",
      "Set for [542]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (1, 1, 2048, 512) (1, 2048, 512)\n",
      "Extract for [543]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [543]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [544]: Activation stage4_unit2_relu2\n",
      "Set for [544]: Activation stage4_unit2_relu2\n",
      "Extract for [545]: ZeroPadding2D zero_padding2d_50\n",
      "Set for [545]: ZeroPadding1D zero_padding1d_50\n",
      "Warning: different names!\n",
      "Extract for [546]: Conv2D stage4_unit2_conv2\n",
      "Set for [546]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [547]: BatchNormalization stage4_unit2_bn3\n",
      "Set for [547]: BatchNormalization stage4_unit2_bn3\n",
      "Extract for [548]: Activation stage4_unit2_relu3\n",
      "Set for [548]: Activation stage4_unit2_relu3\n",
      "Extract for [549]: Conv2D stage4_unit2_conv3\n",
      "Set for [549]: Conv1D stage4_unit2_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [550]: Add add_98\n",
      "Set for [550]: Add add_48\n",
      "Warning: different names!\n",
      "Extract for [551]: BatchNormalization stage4_unit3_bn1\n",
      "Set for [551]: BatchNormalization stage4_unit3_bn1\n",
      "Extract for [552]: Activation stage4_unit3_relu1\n",
      "Set for [552]: Activation stage4_unit3_relu1\n",
      "Extract for [553]: Conv2D stage4_unit3_conv1\n",
      "Set for [553]: Conv1D stage4_unit3_conv1\n",
      "<class 'list'> 1 (1, 1, 2048, 512) (1, 2048, 512)\n",
      "Extract for [554]: BatchNormalization stage4_unit3_bn2\n",
      "Set for [554]: BatchNormalization stage4_unit3_bn2\n",
      "Extract for [555]: Activation stage4_unit3_relu2\n",
      "Set for [555]: Activation stage4_unit3_relu2\n",
      "Extract for [556]: ZeroPadding2D zero_padding2d_51\n",
      "Set for [556]: ZeroPadding1D zero_padding1d_51\n",
      "Warning: different names!\n",
      "Extract for [557]: Conv2D stage4_unit3_conv2\n",
      "Set for [557]: Conv1D stage4_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [558]: BatchNormalization stage4_unit3_bn3\n",
      "Set for [558]: BatchNormalization stage4_unit3_bn3\n",
      "Extract for [559]: Activation stage4_unit3_relu3\n",
      "Set for [559]: Activation stage4_unit3_relu3\n",
      "Extract for [560]: Conv2D stage4_unit3_conv3\n",
      "Set for [560]: Conv1D stage4_unit3_conv3\n",
      "<class 'list'> 1 (1, 1, 512, 2048) (1, 512, 2048)\n",
      "Extract for [561]: Add add_99\n",
      "Set for [561]: Add add_49\n",
      "Warning: different names!\n",
      "Extract for [562]: BatchNormalization bn1\n",
      "Set for [562]: BatchNormalization bn1\n",
      "Extract for [563]: Activation relu1\n",
      "Set for [563]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model 1D: seresnet18 Mem single: 0.06\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/seresnet18_imagenet_1000_no_top.h5\n",
      "45351256/45351256 [==============================] - 9s 0us/step\n",
      "Model 2D: seresnet18 Mem single: 0.09\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [10]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [11]: Conv2D stage1_unit1_conv1\n",
      "Set for [11]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [13]: Activation stage1_unit1_relu2\n",
      "Set for [13]: Activation stage1_unit1_relu2\n",
      "Extract for [14]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [14]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [15]: Conv2D stage1_unit1_conv2\n",
      "Set for [15]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [16]: GlobalAveragePooling2D global_average_pooling2d\n",
      "Set for [16]: GlobalAveragePooling1D global_average_pooling1d\n",
      "Warning: different names!\n",
      "Extract for [17]: Lambda lambda_8\n",
      "Set for [17]: Lambda lambda\n",
      "Warning: different names!\n",
      "Extract for [18]: Conv2D conv2d\n",
      "Set for [18]: Conv1D conv1d\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 64, 4) (1, 64, 4)\n",
      "(4,) (4,)\n",
      "Extract for [19]: Activation activation_16\n",
      "Set for [19]: Activation activation\n",
      "Warning: different names!\n",
      "Extract for [20]: Conv2D conv2d_1\n",
      "Set for [20]: Conv1D conv1d_1\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 4, 64) (1, 4, 64)\n",
      "(64,) (64,)\n",
      "Extract for [21]: Activation activation_17\n",
      "Set for [21]: Activation activation_1\n",
      "Warning: different names!\n",
      "Extract for [22]: Multiply multiply_8\n",
      "Set for [22]: Multiply multiply\n",
      "Warning: different names!\n",
      "Extract for [23]: Conv2D stage1_unit1_sc\n",
      "Set for [23]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [24]: Add add_8\n",
      "Set for [24]: Add add\n",
      "Warning: different names!\n",
      "Extract for [25]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [25]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [26]: Activation stage1_unit2_relu1\n",
      "Set for [26]: Activation stage1_unit2_relu1\n",
      "Extract for [27]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [27]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [28]: Conv2D stage1_unit2_conv1\n",
      "Set for [28]: Conv1D stage1_unit2_conv1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [29]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [29]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [30]: Activation stage1_unit2_relu2\n",
      "Set for [30]: Activation stage1_unit2_relu2\n",
      "Extract for [31]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [31]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [32]: Conv2D stage1_unit2_conv2\n",
      "Set for [32]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [33]: GlobalAveragePooling2D global_average_pooling2d_1\n",
      "Set for [33]: GlobalAveragePooling1D global_average_pooling1d_1\n",
      "Warning: different names!\n",
      "Extract for [34]: Lambda lambda_9\n",
      "Set for [34]: Lambda lambda_1\n",
      "Warning: different names!\n",
      "Extract for [35]: Conv2D conv2d_2\n",
      "Set for [35]: Conv1D conv1d_2\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 64, 4) (1, 64, 4)\n",
      "(4,) (4,)\n",
      "Extract for [36]: Activation activation_18\n",
      "Set for [36]: Activation activation_2\n",
      "Warning: different names!\n",
      "Extract for [37]: Conv2D conv2d_3\n",
      "Set for [37]: Conv1D conv1d_3\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 4, 64) (1, 4, 64)\n",
      "(64,) (64,)\n",
      "Extract for [38]: Activation activation_19\n",
      "Set for [38]: Activation activation_3\n",
      "Warning: different names!\n",
      "Extract for [39]: Multiply multiply_9\n",
      "Set for [39]: Multiply multiply_1\n",
      "Warning: different names!\n",
      "Extract for [40]: Add add_9\n",
      "Set for [40]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [41]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [41]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [42]: Activation stage2_unit1_relu1\n",
      "Set for [42]: Activation stage2_unit1_relu1\n",
      "Extract for [43]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [43]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [44]: Conv2D stage2_unit1_conv1\n",
      "Set for [44]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 128) (3, 64, 128)\n",
      "Extract for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [45]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [46]: Activation stage2_unit1_relu2\n",
      "Set for [46]: Activation stage2_unit1_relu2\n",
      "Extract for [47]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [47]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n",
      "Extract for [48]: Conv2D stage2_unit1_conv2\n",
      "Set for [48]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [49]: GlobalAveragePooling2D global_average_pooling2d_2\n",
      "Set for [49]: GlobalAveragePooling1D global_average_pooling1d_2\n",
      "Warning: different names!\n",
      "Extract for [50]: Lambda lambda_10\n",
      "Set for [50]: Lambda lambda_2\n",
      "Warning: different names!\n",
      "Extract for [51]: Conv2D conv2d_4\n",
      "Set for [51]: Conv1D conv1d_4\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 128, 8) (1, 128, 8)\n",
      "(8,) (8,)\n",
      "Extract for [52]: Activation activation_20\n",
      "Set for [52]: Activation activation_4\n",
      "Warning: different names!\n",
      "Extract for [53]: Conv2D conv2d_5\n",
      "Set for [53]: Conv1D conv1d_5\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 8, 128) (1, 8, 128)\n",
      "(128,) (128,)\n",
      "Extract for [54]: Activation activation_21\n",
      "Set for [54]: Activation activation_5\n",
      "Warning: different names!\n",
      "Extract for [55]: Multiply multiply_10\n",
      "Set for [55]: Multiply multiply_2\n",
      "Warning: different names!\n",
      "Extract for [56]: Conv2D stage2_unit1_sc\n",
      "Set for [56]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 128) (1, 64, 128)\n",
      "Extract for [57]: Add add_10\n",
      "Set for [57]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [58]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [58]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [59]: Activation stage2_unit2_relu1\n",
      "Set for [59]: Activation stage2_unit2_relu1\n",
      "Extract for [60]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [60]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [61]: Conv2D stage2_unit2_conv1\n",
      "Set for [61]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [62]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [62]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [63]: Activation stage2_unit2_relu2\n",
      "Set for [63]: Activation stage2_unit2_relu2\n",
      "Extract for [64]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [64]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [65]: Conv2D stage2_unit2_conv2\n",
      "Set for [65]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [66]: GlobalAveragePooling2D global_average_pooling2d_3\n",
      "Set for [66]: GlobalAveragePooling1D global_average_pooling1d_3\n",
      "Warning: different names!\n",
      "Extract for [67]: Lambda lambda_11\n",
      "Set for [67]: Lambda lambda_3\n",
      "Warning: different names!\n",
      "Extract for [68]: Conv2D conv2d_6\n",
      "Set for [68]: Conv1D conv1d_6\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 128, 8) (1, 128, 8)\n",
      "(8,) (8,)\n",
      "Extract for [69]: Activation activation_22\n",
      "Set for [69]: Activation activation_6\n",
      "Warning: different names!\n",
      "Extract for [70]: Conv2D conv2d_7\n",
      "Set for [70]: Conv1D conv1d_7\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 8, 128) (1, 8, 128)\n",
      "(128,) (128,)\n",
      "Extract for [71]: Activation activation_23\n",
      "Set for [71]: Activation activation_7\n",
      "Warning: different names!\n",
      "Extract for [72]: Multiply multiply_11\n",
      "Set for [72]: Multiply multiply_3\n",
      "Warning: different names!\n",
      "Extract for [73]: Add add_11\n",
      "Set for [73]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [74]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [74]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [75]: Activation stage3_unit1_relu1\n",
      "Set for [75]: Activation stage3_unit1_relu1\n",
      "Extract for [76]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [76]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [77]: Conv2D stage3_unit1_conv1\n",
      "Set for [77]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 256) (3, 128, 256)\n",
      "Extract for [78]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [78]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [79]: Activation stage3_unit1_relu2\n",
      "Set for [79]: Activation stage3_unit1_relu2\n",
      "Extract for [80]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [80]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [81]: Conv2D stage3_unit1_conv2\n",
      "Set for [81]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [82]: GlobalAveragePooling2D global_average_pooling2d_4\n",
      "Set for [82]: GlobalAveragePooling1D global_average_pooling1d_4\n",
      "Warning: different names!\n",
      "Extract for [83]: Lambda lambda_12\n",
      "Set for [83]: Lambda lambda_4\n",
      "Warning: different names!\n",
      "Extract for [84]: Conv2D conv2d_8\n",
      "Set for [84]: Conv1D conv1d_8\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [85]: Activation activation_24\n",
      "Set for [85]: Activation activation_8\n",
      "Warning: different names!\n",
      "Extract for [86]: Conv2D conv2d_9\n",
      "Set for [86]: Conv1D conv1d_9\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [87]: Activation activation_25\n",
      "Set for [87]: Activation activation_9\n",
      "Warning: different names!\n",
      "Extract for [88]: Multiply multiply_12\n",
      "Set for [88]: Multiply multiply_4\n",
      "Warning: different names!\n",
      "Extract for [89]: Conv2D stage3_unit1_sc\n",
      "Set for [89]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 128, 256) (1, 128, 256)\n",
      "Extract for [90]: Add add_12\n",
      "Set for [90]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [91]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [91]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [92]: Activation stage3_unit2_relu1\n",
      "Set for [92]: Activation stage3_unit2_relu1\n",
      "Extract for [93]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [93]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [94]: Conv2D stage3_unit2_conv1\n",
      "Set for [94]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [95]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [95]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [96]: Activation stage3_unit2_relu2\n",
      "Set for [96]: Activation stage3_unit2_relu2\n",
      "Extract for [97]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [97]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [98]: Conv2D stage3_unit2_conv2\n",
      "Set for [98]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [99]: GlobalAveragePooling2D global_average_pooling2d_5\n",
      "Set for [99]: GlobalAveragePooling1D global_average_pooling1d_5\n",
      "Warning: different names!\n",
      "Extract for [100]: Lambda lambda_13\n",
      "Set for [100]: Lambda lambda_5\n",
      "Warning: different names!\n",
      "Extract for [101]: Conv2D conv2d_10\n",
      "Set for [101]: Conv1D conv1d_10\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [102]: Activation activation_26\n",
      "Set for [102]: Activation activation_10\n",
      "Warning: different names!\n",
      "Extract for [103]: Conv2D conv2d_11\n",
      "Set for [103]: Conv1D conv1d_11\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [104]: Activation activation_27\n",
      "Set for [104]: Activation activation_11\n",
      "Warning: different names!\n",
      "Extract for [105]: Multiply multiply_13\n",
      "Set for [105]: Multiply multiply_5\n",
      "Warning: different names!\n",
      "Extract for [106]: Add add_13\n",
      "Set for [106]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [107]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [107]: BatchNormalization stage4_unit1_bn1\n",
      "Extract for [108]: Activation stage4_unit1_relu1\n",
      "Set for [108]: Activation stage4_unit1_relu1\n",
      "Extract for [109]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [109]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [110]: Conv2D stage4_unit1_conv1\n",
      "Set for [110]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 512) (3, 256, 512)\n",
      "Extract for [111]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [111]: BatchNormalization stage4_unit1_bn2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [112]: Activation stage4_unit1_relu2\n",
      "Set for [112]: Activation stage4_unit1_relu2\n",
      "Extract for [113]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [113]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [114]: Conv2D stage4_unit1_conv2\n",
      "Set for [114]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [115]: GlobalAveragePooling2D global_average_pooling2d_6\n",
      "Set for [115]: GlobalAveragePooling1D global_average_pooling1d_6\n",
      "Warning: different names!\n",
      "Extract for [116]: Lambda lambda_14\n",
      "Set for [116]: Lambda lambda_6\n",
      "Warning: different names!\n",
      "Extract for [117]: Conv2D conv2d_12\n",
      "Set for [117]: Conv1D conv1d_12\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 512, 32) (1, 512, 32)\n",
      "(32,) (32,)\n",
      "Extract for [118]: Activation activation_28\n",
      "Set for [118]: Activation activation_12\n",
      "Warning: different names!\n",
      "Extract for [119]: Conv2D conv2d_13\n",
      "Set for [119]: Conv1D conv1d_13\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 32, 512) (1, 32, 512)\n",
      "(512,) (512,)\n",
      "Extract for [120]: Activation activation_29\n",
      "Set for [120]: Activation activation_13\n",
      "Warning: different names!\n",
      "Extract for [121]: Multiply multiply_14\n",
      "Set for [121]: Multiply multiply_6\n",
      "Warning: different names!\n",
      "Extract for [122]: Conv2D stage4_unit1_sc\n",
      "Set for [122]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n",
      "Extract for [123]: Add add_14\n",
      "Set for [123]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [124]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [124]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [125]: Activation stage4_unit2_relu1\n",
      "Set for [125]: Activation stage4_unit2_relu1\n",
      "Extract for [126]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [126]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [127]: Conv2D stage4_unit2_conv1\n",
      "Set for [127]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [128]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [128]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [129]: Activation stage4_unit2_relu2\n",
      "Set for [129]: Activation stage4_unit2_relu2\n",
      "Extract for [130]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [130]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [131]: Conv2D stage4_unit2_conv2\n",
      "Set for [131]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [132]: GlobalAveragePooling2D global_average_pooling2d_7\n",
      "Set for [132]: GlobalAveragePooling1D global_average_pooling1d_7\n",
      "Warning: different names!\n",
      "Extract for [133]: Lambda lambda_15\n",
      "Set for [133]: Lambda lambda_7\n",
      "Warning: different names!\n",
      "Extract for [134]: Conv2D conv2d_14\n",
      "Set for [134]: Conv1D conv1d_14\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 512, 32) (1, 512, 32)\n",
      "(32,) (32,)\n",
      "Extract for [135]: Activation activation_30\n",
      "Set for [135]: Activation activation_14\n",
      "Warning: different names!\n",
      "Extract for [136]: Conv2D conv2d_15\n",
      "Set for [136]: Conv1D conv1d_15\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 32, 512) (1, 32, 512)\n",
      "(512,) (512,)\n",
      "Extract for [137]: Activation activation_31\n",
      "Set for [137]: Activation activation_15\n",
      "Warning: different names!\n",
      "Extract for [138]: Multiply multiply_15\n",
      "Set for [138]: Multiply multiply_7\n",
      "Warning: different names!\n",
      "Extract for [139]: Add add_15\n",
      "Set for [139]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [140]: BatchNormalization bn1\n",
      "Set for [140]: BatchNormalization bn1\n",
      "Extract for [141]: Activation relu1\n",
      "Set for [141]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model 1D: seresnet34 Mem single: 0.10\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/seresnet34_imagenet_1000_no_top.h5\n",
      "86315168/86315168 [==============================] - 14s 0us/step\n",
      "Model 2D: seresnet34 Mem single: 0.15\n",
      "Start: model_1\n",
      "Extract for [0]: InputLayer data\n",
      "Set for [0]: InputLayer data\n",
      "Extract for [1]: BatchNormalization bn_data\n",
      "Set for [1]: BatchNormalization bn_data\n",
      "Convert first batchNorm layer!\n",
      "(3,) (3,) (3,) (3,)\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'bn_data', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([2]), 'momentum': 0.99, 'epsilon': 2e-05, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "Extract for [2]: ZeroPadding2D zero_padding2d\n",
      "Set for [2]: ZeroPadding1D zero_padding1d\n",
      "Warning: different names!\n",
      "Extract for [3]: Conv2D conv0\n",
      "Set for [3]: Conv1D conv0\n",
      "<class 'list'> 1 (7, 7, 3, 64) (49, 2, 64)\n",
      "Extract for [4]: BatchNormalization bn0\n",
      "Set for [4]: BatchNormalization bn0\n",
      "Extract for [5]: Activation relu0\n",
      "Set for [5]: Activation relu0\n",
      "Extract for [6]: ZeroPadding2D zero_padding2d_1\n",
      "Set for [6]: ZeroPadding1D zero_padding1d_1\n",
      "Warning: different names!\n",
      "Extract for [7]: MaxPooling2D pooling0\n",
      "Set for [7]: MaxPooling1D pooling0\n",
      "Extract for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Set for [8]: BatchNormalization stage1_unit1_bn1\n",
      "Extract for [9]: Activation stage1_unit1_relu1\n",
      "Set for [9]: Activation stage1_unit1_relu1\n",
      "Extract for [10]: ZeroPadding2D zero_padding2d_2\n",
      "Set for [10]: ZeroPadding1D zero_padding1d_2\n",
      "Warning: different names!\n",
      "Extract for [11]: Conv2D stage1_unit1_conv1\n",
      "Set for [11]: Conv1D stage1_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Set for [12]: BatchNormalization stage1_unit1_bn2\n",
      "Extract for [13]: Activation stage1_unit1_relu2\n",
      "Set for [13]: Activation stage1_unit1_relu2\n",
      "Extract for [14]: ZeroPadding2D zero_padding2d_3\n",
      "Set for [14]: ZeroPadding1D zero_padding1d_3\n",
      "Warning: different names!\n",
      "Extract for [15]: Conv2D stage1_unit1_conv2\n",
      "Set for [15]: Conv1D stage1_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [16]: GlobalAveragePooling2D global_average_pooling2d\n",
      "Set for [16]: GlobalAveragePooling1D global_average_pooling1d\n",
      "Warning: different names!\n",
      "Extract for [17]: Lambda lambda_16\n",
      "Set for [17]: Lambda lambda\n",
      "Warning: different names!\n",
      "Extract for [18]: Conv2D conv2d\n",
      "Set for [18]: Conv1D conv1d\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 64, 4) (1, 64, 4)\n",
      "(4,) (4,)\n",
      "Extract for [19]: Activation activation_32\n",
      "Set for [19]: Activation activation\n",
      "Warning: different names!\n",
      "Extract for [20]: Conv2D conv2d_1\n",
      "Set for [20]: Conv1D conv1d_1\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 4, 64) (1, 4, 64)\n",
      "(64,) (64,)\n",
      "Extract for [21]: Activation activation_33\n",
      "Set for [21]: Activation activation_1\n",
      "Warning: different names!\n",
      "Extract for [22]: Multiply multiply_16\n",
      "Set for [22]: Multiply multiply\n",
      "Warning: different names!\n",
      "Extract for [23]: Conv2D stage1_unit1_sc\n",
      "Set for [23]: Conv1D stage1_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 64) (1, 64, 64)\n",
      "Extract for [24]: Add add_16\n",
      "Set for [24]: Add add\n",
      "Warning: different names!\n",
      "Extract for [25]: BatchNormalization stage1_unit2_bn1\n",
      "Set for [25]: BatchNormalization stage1_unit2_bn1\n",
      "Extract for [26]: Activation stage1_unit2_relu1\n",
      "Set for [26]: Activation stage1_unit2_relu1\n",
      "Extract for [27]: ZeroPadding2D zero_padding2d_4\n",
      "Set for [27]: ZeroPadding1D zero_padding1d_4\n",
      "Warning: different names!\n",
      "Extract for [28]: Conv2D stage1_unit2_conv1\n",
      "Set for [28]: Conv1D stage1_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [29]: BatchNormalization stage1_unit2_bn2\n",
      "Set for [29]: BatchNormalization stage1_unit2_bn2\n",
      "Extract for [30]: Activation stage1_unit2_relu2\n",
      "Set for [30]: Activation stage1_unit2_relu2\n",
      "Extract for [31]: ZeroPadding2D zero_padding2d_5\n",
      "Set for [31]: ZeroPadding1D zero_padding1d_5\n",
      "Warning: different names!\n",
      "Extract for [32]: Conv2D stage1_unit2_conv2\n",
      "Set for [32]: Conv1D stage1_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [33]: GlobalAveragePooling2D global_average_pooling2d_1\n",
      "Set for [33]: GlobalAveragePooling1D global_average_pooling1d_1\n",
      "Warning: different names!\n",
      "Extract for [34]: Lambda lambda_17\n",
      "Set for [34]: Lambda lambda_1\n",
      "Warning: different names!\n",
      "Extract for [35]: Conv2D conv2d_2\n",
      "Set for [35]: Conv1D conv1d_2\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 64, 4) (1, 64, 4)\n",
      "(4,) (4,)\n",
      "Extract for [36]: Activation activation_34\n",
      "Set for [36]: Activation activation_2\n",
      "Warning: different names!\n",
      "Extract for [37]: Conv2D conv2d_3\n",
      "Set for [37]: Conv1D conv1d_3\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 4, 64) (1, 4, 64)\n",
      "(64,) (64,)\n",
      "Extract for [38]: Activation activation_35\n",
      "Set for [38]: Activation activation_3\n",
      "Warning: different names!\n",
      "Extract for [39]: Multiply multiply_17\n",
      "Set for [39]: Multiply multiply_1\n",
      "Warning: different names!\n",
      "Extract for [40]: Add add_17\n",
      "Set for [40]: Add add_1\n",
      "Warning: different names!\n",
      "Extract for [41]: BatchNormalization stage1_unit3_bn1\n",
      "Set for [41]: BatchNormalization stage1_unit3_bn1\n",
      "Extract for [42]: Activation stage1_unit3_relu1\n",
      "Set for [42]: Activation stage1_unit3_relu1\n",
      "Extract for [43]: ZeroPadding2D zero_padding2d_6\n",
      "Set for [43]: ZeroPadding1D zero_padding1d_6\n",
      "Warning: different names!\n",
      "Extract for [44]: Conv2D stage1_unit3_conv1\n",
      "Set for [44]: Conv1D stage1_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [45]: BatchNormalization stage1_unit3_bn2\n",
      "Set for [45]: BatchNormalization stage1_unit3_bn2\n",
      "Extract for [46]: Activation stage1_unit3_relu2\n",
      "Set for [46]: Activation stage1_unit3_relu2\n",
      "Extract for [47]: ZeroPadding2D zero_padding2d_7\n",
      "Set for [47]: ZeroPadding1D zero_padding1d_7\n",
      "Warning: different names!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [48]: Conv2D stage1_unit3_conv2\n",
      "Set for [48]: Conv1D stage1_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 64, 64) (3, 64, 64)\n",
      "Extract for [49]: GlobalAveragePooling2D global_average_pooling2d_2\n",
      "Set for [49]: GlobalAveragePooling1D global_average_pooling1d_2\n",
      "Warning: different names!\n",
      "Extract for [50]: Lambda lambda_18\n",
      "Set for [50]: Lambda lambda_2\n",
      "Warning: different names!\n",
      "Extract for [51]: Conv2D conv2d_4\n",
      "Set for [51]: Conv1D conv1d_4\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 64, 4) (1, 64, 4)\n",
      "(4,) (4,)\n",
      "Extract for [52]: Activation activation_36\n",
      "Set for [52]: Activation activation_4\n",
      "Warning: different names!\n",
      "Extract for [53]: Conv2D conv2d_5\n",
      "Set for [53]: Conv1D conv1d_5\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 4, 64) (1, 4, 64)\n",
      "(64,) (64,)\n",
      "Extract for [54]: Activation activation_37\n",
      "Set for [54]: Activation activation_5\n",
      "Warning: different names!\n",
      "Extract for [55]: Multiply multiply_18\n",
      "Set for [55]: Multiply multiply_2\n",
      "Warning: different names!\n",
      "Extract for [56]: Add add_18\n",
      "Set for [56]: Add add_2\n",
      "Warning: different names!\n",
      "Extract for [57]: BatchNormalization stage2_unit1_bn1\n",
      "Set for [57]: BatchNormalization stage2_unit1_bn1\n",
      "Extract for [58]: Activation stage2_unit1_relu1\n",
      "Set for [58]: Activation stage2_unit1_relu1\n",
      "Extract for [59]: ZeroPadding2D zero_padding2d_8\n",
      "Set for [59]: ZeroPadding1D zero_padding1d_8\n",
      "Warning: different names!\n",
      "Extract for [60]: Conv2D stage2_unit1_conv1\n",
      "Set for [60]: Conv1D stage2_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 64, 128) (3, 64, 128)\n",
      "Extract for [61]: BatchNormalization stage2_unit1_bn2\n",
      "Set for [61]: BatchNormalization stage2_unit1_bn2\n",
      "Extract for [62]: Activation stage2_unit1_relu2\n",
      "Set for [62]: Activation stage2_unit1_relu2\n",
      "Extract for [63]: ZeroPadding2D zero_padding2d_9\n",
      "Set for [63]: ZeroPadding1D zero_padding1d_9\n",
      "Warning: different names!\n",
      "Extract for [64]: Conv2D stage2_unit1_conv2\n",
      "Set for [64]: Conv1D stage2_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [65]: GlobalAveragePooling2D global_average_pooling2d_3\n",
      "Set for [65]: GlobalAveragePooling1D global_average_pooling1d_3\n",
      "Warning: different names!\n",
      "Extract for [66]: Lambda lambda_19\n",
      "Set for [66]: Lambda lambda_3\n",
      "Warning: different names!\n",
      "Extract for [67]: Conv2D conv2d_6\n",
      "Set for [67]: Conv1D conv1d_6\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 128, 8) (1, 128, 8)\n",
      "(8,) (8,)\n",
      "Extract for [68]: Activation activation_38\n",
      "Set for [68]: Activation activation_6\n",
      "Warning: different names!\n",
      "Extract for [69]: Conv2D conv2d_7\n",
      "Set for [69]: Conv1D conv1d_7\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 8, 128) (1, 8, 128)\n",
      "(128,) (128,)\n",
      "Extract for [70]: Activation activation_39\n",
      "Set for [70]: Activation activation_7\n",
      "Warning: different names!\n",
      "Extract for [71]: Multiply multiply_19\n",
      "Set for [71]: Multiply multiply_3\n",
      "Warning: different names!\n",
      "Extract for [72]: Conv2D stage2_unit1_sc\n",
      "Set for [72]: Conv1D stage2_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 64, 128) (1, 64, 128)\n",
      "Extract for [73]: Add add_19\n",
      "Set for [73]: Add add_3\n",
      "Warning: different names!\n",
      "Extract for [74]: BatchNormalization stage2_unit2_bn1\n",
      "Set for [74]: BatchNormalization stage2_unit2_bn1\n",
      "Extract for [75]: Activation stage2_unit2_relu1\n",
      "Set for [75]: Activation stage2_unit2_relu1\n",
      "Extract for [76]: ZeroPadding2D zero_padding2d_10\n",
      "Set for [76]: ZeroPadding1D zero_padding1d_10\n",
      "Warning: different names!\n",
      "Extract for [77]: Conv2D stage2_unit2_conv1\n",
      "Set for [77]: Conv1D stage2_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [78]: BatchNormalization stage2_unit2_bn2\n",
      "Set for [78]: BatchNormalization stage2_unit2_bn2\n",
      "Extract for [79]: Activation stage2_unit2_relu2\n",
      "Set for [79]: Activation stage2_unit2_relu2\n",
      "Extract for [80]: ZeroPadding2D zero_padding2d_11\n",
      "Set for [80]: ZeroPadding1D zero_padding1d_11\n",
      "Warning: different names!\n",
      "Extract for [81]: Conv2D stage2_unit2_conv2\n",
      "Set for [81]: Conv1D stage2_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [82]: GlobalAveragePooling2D global_average_pooling2d_4\n",
      "Set for [82]: GlobalAveragePooling1D global_average_pooling1d_4\n",
      "Warning: different names!\n",
      "Extract for [83]: Lambda lambda_20\n",
      "Set for [83]: Lambda lambda_4\n",
      "Warning: different names!\n",
      "Extract for [84]: Conv2D conv2d_8\n",
      "Set for [84]: Conv1D conv1d_8\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 128, 8) (1, 128, 8)\n",
      "(8,) (8,)\n",
      "Extract for [85]: Activation activation_40\n",
      "Set for [85]: Activation activation_8\n",
      "Warning: different names!\n",
      "Extract for [86]: Conv2D conv2d_9\n",
      "Set for [86]: Conv1D conv1d_9\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 8, 128) (1, 8, 128)\n",
      "(128,) (128,)\n",
      "Extract for [87]: Activation activation_41\n",
      "Set for [87]: Activation activation_9\n",
      "Warning: different names!\n",
      "Extract for [88]: Multiply multiply_20\n",
      "Set for [88]: Multiply multiply_4\n",
      "Warning: different names!\n",
      "Extract for [89]: Add add_20\n",
      "Set for [89]: Add add_4\n",
      "Warning: different names!\n",
      "Extract for [90]: BatchNormalization stage2_unit3_bn1\n",
      "Set for [90]: BatchNormalization stage2_unit3_bn1\n",
      "Extract for [91]: Activation stage2_unit3_relu1\n",
      "Set for [91]: Activation stage2_unit3_relu1\n",
      "Extract for [92]: ZeroPadding2D zero_padding2d_12\n",
      "Set for [92]: ZeroPadding1D zero_padding1d_12\n",
      "Warning: different names!\n",
      "Extract for [93]: Conv2D stage2_unit3_conv1\n",
      "Set for [93]: Conv1D stage2_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [94]: BatchNormalization stage2_unit3_bn2\n",
      "Set for [94]: BatchNormalization stage2_unit3_bn2\n",
      "Extract for [95]: Activation stage2_unit3_relu2\n",
      "Set for [95]: Activation stage2_unit3_relu2\n",
      "Extract for [96]: ZeroPadding2D zero_padding2d_13\n",
      "Set for [96]: ZeroPadding1D zero_padding1d_13\n",
      "Warning: different names!\n",
      "Extract for [97]: Conv2D stage2_unit3_conv2\n",
      "Set for [97]: Conv1D stage2_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [98]: GlobalAveragePooling2D global_average_pooling2d_5\n",
      "Set for [98]: GlobalAveragePooling1D global_average_pooling1d_5\n",
      "Warning: different names!\n",
      "Extract for [99]: Lambda lambda_21\n",
      "Set for [99]: Lambda lambda_5\n",
      "Warning: different names!\n",
      "Extract for [100]: Conv2D conv2d_10\n",
      "Set for [100]: Conv1D conv1d_10\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 128, 8) (1, 128, 8)\n",
      "(8,) (8,)\n",
      "Extract for [101]: Activation activation_42\n",
      "Set for [101]: Activation activation_10\n",
      "Warning: different names!\n",
      "Extract for [102]: Conv2D conv2d_11\n",
      "Set for [102]: Conv1D conv1d_11\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 8, 128) (1, 8, 128)\n",
      "(128,) (128,)\n",
      "Extract for [103]: Activation activation_43\n",
      "Set for [103]: Activation activation_11\n",
      "Warning: different names!\n",
      "Extract for [104]: Multiply multiply_21\n",
      "Set for [104]: Multiply multiply_5\n",
      "Warning: different names!\n",
      "Extract for [105]: Add add_21\n",
      "Set for [105]: Add add_5\n",
      "Warning: different names!\n",
      "Extract for [106]: BatchNormalization stage2_unit4_bn1\n",
      "Set for [106]: BatchNormalization stage2_unit4_bn1\n",
      "Extract for [107]: Activation stage2_unit4_relu1\n",
      "Set for [107]: Activation stage2_unit4_relu1\n",
      "Extract for [108]: ZeroPadding2D zero_padding2d_14\n",
      "Set for [108]: ZeroPadding1D zero_padding1d_14\n",
      "Warning: different names!\n",
      "Extract for [109]: Conv2D stage2_unit4_conv1\n",
      "Set for [109]: Conv1D stage2_unit4_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [110]: BatchNormalization stage2_unit4_bn2\n",
      "Set for [110]: BatchNormalization stage2_unit4_bn2\n",
      "Extract for [111]: Activation stage2_unit4_relu2\n",
      "Set for [111]: Activation stage2_unit4_relu2\n",
      "Extract for [112]: ZeroPadding2D zero_padding2d_15\n",
      "Set for [112]: ZeroPadding1D zero_padding1d_15\n",
      "Warning: different names!\n",
      "Extract for [113]: Conv2D stage2_unit4_conv2\n",
      "Set for [113]: Conv1D stage2_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 128, 128) (3, 128, 128)\n",
      "Extract for [114]: GlobalAveragePooling2D global_average_pooling2d_6\n",
      "Set for [114]: GlobalAveragePooling1D global_average_pooling1d_6\n",
      "Warning: different names!\n",
      "Extract for [115]: Lambda lambda_22\n",
      "Set for [115]: Lambda lambda_6\n",
      "Warning: different names!\n",
      "Extract for [116]: Conv2D conv2d_12\n",
      "Set for [116]: Conv1D conv1d_12\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 128, 8) (1, 128, 8)\n",
      "(8,) (8,)\n",
      "Extract for [117]: Activation activation_44\n",
      "Set for [117]: Activation activation_12\n",
      "Warning: different names!\n",
      "Extract for [118]: Conv2D conv2d_13\n",
      "Set for [118]: Conv1D conv1d_13\n",
      "Warning: different names!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2 (1, 1, 8, 128) (1, 8, 128)\n",
      "(128,) (128,)\n",
      "Extract for [119]: Activation activation_45\n",
      "Set for [119]: Activation activation_13\n",
      "Warning: different names!\n",
      "Extract for [120]: Multiply multiply_22\n",
      "Set for [120]: Multiply multiply_6\n",
      "Warning: different names!\n",
      "Extract for [121]: Add add_22\n",
      "Set for [121]: Add add_6\n",
      "Warning: different names!\n",
      "Extract for [122]: BatchNormalization stage3_unit1_bn1\n",
      "Set for [122]: BatchNormalization stage3_unit1_bn1\n",
      "Extract for [123]: Activation stage3_unit1_relu1\n",
      "Set for [123]: Activation stage3_unit1_relu1\n",
      "Extract for [124]: ZeroPadding2D zero_padding2d_16\n",
      "Set for [124]: ZeroPadding1D zero_padding1d_16\n",
      "Warning: different names!\n",
      "Extract for [125]: Conv2D stage3_unit1_conv1\n",
      "Set for [125]: Conv1D stage3_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 128, 256) (3, 128, 256)\n",
      "Extract for [126]: BatchNormalization stage3_unit1_bn2\n",
      "Set for [126]: BatchNormalization stage3_unit1_bn2\n",
      "Extract for [127]: Activation stage3_unit1_relu2\n",
      "Set for [127]: Activation stage3_unit1_relu2\n",
      "Extract for [128]: ZeroPadding2D zero_padding2d_17\n",
      "Set for [128]: ZeroPadding1D zero_padding1d_17\n",
      "Warning: different names!\n",
      "Extract for [129]: Conv2D stage3_unit1_conv2\n",
      "Set for [129]: Conv1D stage3_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [130]: GlobalAveragePooling2D global_average_pooling2d_7\n",
      "Set for [130]: GlobalAveragePooling1D global_average_pooling1d_7\n",
      "Warning: different names!\n",
      "Extract for [131]: Lambda lambda_23\n",
      "Set for [131]: Lambda lambda_7\n",
      "Warning: different names!\n",
      "Extract for [132]: Conv2D conv2d_14\n",
      "Set for [132]: Conv1D conv1d_14\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [133]: Activation activation_46\n",
      "Set for [133]: Activation activation_14\n",
      "Warning: different names!\n",
      "Extract for [134]: Conv2D conv2d_15\n",
      "Set for [134]: Conv1D conv1d_15\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [135]: Activation activation_47\n",
      "Set for [135]: Activation activation_15\n",
      "Warning: different names!\n",
      "Extract for [136]: Multiply multiply_23\n",
      "Set for [136]: Multiply multiply_7\n",
      "Warning: different names!\n",
      "Extract for [137]: Conv2D stage3_unit1_sc\n",
      "Set for [137]: Conv1D stage3_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 128, 256) (1, 128, 256)\n",
      "Extract for [138]: Add add_23\n",
      "Set for [138]: Add add_7\n",
      "Warning: different names!\n",
      "Extract for [139]: BatchNormalization stage3_unit2_bn1\n",
      "Set for [139]: BatchNormalization stage3_unit2_bn1\n",
      "Extract for [140]: Activation stage3_unit2_relu1\n",
      "Set for [140]: Activation stage3_unit2_relu1\n",
      "Extract for [141]: ZeroPadding2D zero_padding2d_18\n",
      "Set for [141]: ZeroPadding1D zero_padding1d_18\n",
      "Warning: different names!\n",
      "Extract for [142]: Conv2D stage3_unit2_conv1\n",
      "Set for [142]: Conv1D stage3_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [143]: BatchNormalization stage3_unit2_bn2\n",
      "Set for [143]: BatchNormalization stage3_unit2_bn2\n",
      "Extract for [144]: Activation stage3_unit2_relu2\n",
      "Set for [144]: Activation stage3_unit2_relu2\n",
      "Extract for [145]: ZeroPadding2D zero_padding2d_19\n",
      "Set for [145]: ZeroPadding1D zero_padding1d_19\n",
      "Warning: different names!\n",
      "Extract for [146]: Conv2D stage3_unit2_conv2\n",
      "Set for [146]: Conv1D stage3_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [147]: GlobalAveragePooling2D global_average_pooling2d_8\n",
      "Set for [147]: GlobalAveragePooling1D global_average_pooling1d_8\n",
      "Warning: different names!\n",
      "Extract for [148]: Lambda lambda_24\n",
      "Set for [148]: Lambda lambda_8\n",
      "Warning: different names!\n",
      "Extract for [149]: Conv2D conv2d_16\n",
      "Set for [149]: Conv1D conv1d_16\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [150]: Activation activation_48\n",
      "Set for [150]: Activation activation_16\n",
      "Warning: different names!\n",
      "Extract for [151]: Conv2D conv2d_17\n",
      "Set for [151]: Conv1D conv1d_17\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [152]: Activation activation_49\n",
      "Set for [152]: Activation activation_17\n",
      "Warning: different names!\n",
      "Extract for [153]: Multiply multiply_24\n",
      "Set for [153]: Multiply multiply_8\n",
      "Warning: different names!\n",
      "Extract for [154]: Add add_24\n",
      "Set for [154]: Add add_8\n",
      "Warning: different names!\n",
      "Extract for [155]: BatchNormalization stage3_unit3_bn1\n",
      "Set for [155]: BatchNormalization stage3_unit3_bn1\n",
      "Extract for [156]: Activation stage3_unit3_relu1\n",
      "Set for [156]: Activation stage3_unit3_relu1\n",
      "Extract for [157]: ZeroPadding2D zero_padding2d_20\n",
      "Set for [157]: ZeroPadding1D zero_padding1d_20\n",
      "Warning: different names!\n",
      "Extract for [158]: Conv2D stage3_unit3_conv1\n",
      "Set for [158]: Conv1D stage3_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [159]: BatchNormalization stage3_unit3_bn2\n",
      "Set for [159]: BatchNormalization stage3_unit3_bn2\n",
      "Extract for [160]: Activation stage3_unit3_relu2\n",
      "Set for [160]: Activation stage3_unit3_relu2\n",
      "Extract for [161]: ZeroPadding2D zero_padding2d_21\n",
      "Set for [161]: ZeroPadding1D zero_padding1d_21\n",
      "Warning: different names!\n",
      "Extract for [162]: Conv2D stage3_unit3_conv2\n",
      "Set for [162]: Conv1D stage3_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [163]: GlobalAveragePooling2D global_average_pooling2d_9\n",
      "Set for [163]: GlobalAveragePooling1D global_average_pooling1d_9\n",
      "Warning: different names!\n",
      "Extract for [164]: Lambda lambda_25\n",
      "Set for [164]: Lambda lambda_9\n",
      "Warning: different names!\n",
      "Extract for [165]: Conv2D conv2d_18\n",
      "Set for [165]: Conv1D conv1d_18\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [166]: Activation activation_50\n",
      "Set for [166]: Activation activation_18\n",
      "Warning: different names!\n",
      "Extract for [167]: Conv2D conv2d_19\n",
      "Set for [167]: Conv1D conv1d_19\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [168]: Activation activation_51\n",
      "Set for [168]: Activation activation_19\n",
      "Warning: different names!\n",
      "Extract for [169]: Multiply multiply_25\n",
      "Set for [169]: Multiply multiply_9\n",
      "Warning: different names!\n",
      "Extract for [170]: Add add_25\n",
      "Set for [170]: Add add_9\n",
      "Warning: different names!\n",
      "Extract for [171]: BatchNormalization stage3_unit4_bn1\n",
      "Set for [171]: BatchNormalization stage3_unit4_bn1\n",
      "Extract for [172]: Activation stage3_unit4_relu1\n",
      "Set for [172]: Activation stage3_unit4_relu1\n",
      "Extract for [173]: ZeroPadding2D zero_padding2d_22\n",
      "Set for [173]: ZeroPadding1D zero_padding1d_22\n",
      "Warning: different names!\n",
      "Extract for [174]: Conv2D stage3_unit4_conv1\n",
      "Set for [174]: Conv1D stage3_unit4_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [175]: BatchNormalization stage3_unit4_bn2\n",
      "Set for [175]: BatchNormalization stage3_unit4_bn2\n",
      "Extract for [176]: Activation stage3_unit4_relu2\n",
      "Set for [176]: Activation stage3_unit4_relu2\n",
      "Extract for [177]: ZeroPadding2D zero_padding2d_23\n",
      "Set for [177]: ZeroPadding1D zero_padding1d_23\n",
      "Warning: different names!\n",
      "Extract for [178]: Conv2D stage3_unit4_conv2\n",
      "Set for [178]: Conv1D stage3_unit4_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [179]: GlobalAveragePooling2D global_average_pooling2d_10\n",
      "Set for [179]: GlobalAveragePooling1D global_average_pooling1d_10\n",
      "Warning: different names!\n",
      "Extract for [180]: Lambda lambda_26\n",
      "Set for [180]: Lambda lambda_10\n",
      "Warning: different names!\n",
      "Extract for [181]: Conv2D conv2d_20\n",
      "Set for [181]: Conv1D conv1d_20\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [182]: Activation activation_52\n",
      "Set for [182]: Activation activation_20\n",
      "Warning: different names!\n",
      "Extract for [183]: Conv2D conv2d_21\n",
      "Set for [183]: Conv1D conv1d_21\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [184]: Activation activation_53\n",
      "Set for [184]: Activation activation_21\n",
      "Warning: different names!\n",
      "Extract for [185]: Multiply multiply_26\n",
      "Set for [185]: Multiply multiply_10\n",
      "Warning: different names!\n",
      "Extract for [186]: Add add_26\n",
      "Set for [186]: Add add_10\n",
      "Warning: different names!\n",
      "Extract for [187]: BatchNormalization stage3_unit5_bn1\n",
      "Set for [187]: BatchNormalization stage3_unit5_bn1\n",
      "Extract for [188]: Activation stage3_unit5_relu1\n",
      "Set for [188]: Activation stage3_unit5_relu1\n",
      "Extract for [189]: ZeroPadding2D zero_padding2d_24\n",
      "Set for [189]: ZeroPadding1D zero_padding1d_24\n",
      "Warning: different names!\n",
      "Extract for [190]: Conv2D stage3_unit5_conv1\n",
      "Set for [190]: Conv1D stage3_unit5_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [191]: BatchNormalization stage3_unit5_bn2\n",
      "Set for [191]: BatchNormalization stage3_unit5_bn2\n",
      "Extract for [192]: Activation stage3_unit5_relu2\n",
      "Set for [192]: Activation stage3_unit5_relu2\n",
      "Extract for [193]: ZeroPadding2D zero_padding2d_25\n",
      "Set for [193]: ZeroPadding1D zero_padding1d_25\n",
      "Warning: different names!\n",
      "Extract for [194]: Conv2D stage3_unit5_conv2\n",
      "Set for [194]: Conv1D stage3_unit5_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [195]: GlobalAveragePooling2D global_average_pooling2d_11\n",
      "Set for [195]: GlobalAveragePooling1D global_average_pooling1d_11\n",
      "Warning: different names!\n",
      "Extract for [196]: Lambda lambda_27\n",
      "Set for [196]: Lambda lambda_11\n",
      "Warning: different names!\n",
      "Extract for [197]: Conv2D conv2d_22\n",
      "Set for [197]: Conv1D conv1d_22\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n",
      "Extract for [198]: Activation activation_54\n",
      "Set for [198]: Activation activation_22\n",
      "Warning: different names!\n",
      "Extract for [199]: Conv2D conv2d_23\n",
      "Set for [199]: Conv1D conv1d_23\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [200]: Activation activation_55\n",
      "Set for [200]: Activation activation_23\n",
      "Warning: different names!\n",
      "Extract for [201]: Multiply multiply_27\n",
      "Set for [201]: Multiply multiply_11\n",
      "Warning: different names!\n",
      "Extract for [202]: Add add_27\n",
      "Set for [202]: Add add_11\n",
      "Warning: different names!\n",
      "Extract for [203]: BatchNormalization stage3_unit6_bn1\n",
      "Set for [203]: BatchNormalization stage3_unit6_bn1\n",
      "Extract for [204]: Activation stage3_unit6_relu1\n",
      "Set for [204]: Activation stage3_unit6_relu1\n",
      "Extract for [205]: ZeroPadding2D zero_padding2d_26\n",
      "Set for [205]: ZeroPadding1D zero_padding1d_26\n",
      "Warning: different names!\n",
      "Extract for [206]: Conv2D stage3_unit6_conv1\n",
      "Set for [206]: Conv1D stage3_unit6_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [207]: BatchNormalization stage3_unit6_bn2\n",
      "Set for [207]: BatchNormalization stage3_unit6_bn2\n",
      "Extract for [208]: Activation stage3_unit6_relu2\n",
      "Set for [208]: Activation stage3_unit6_relu2\n",
      "Extract for [209]: ZeroPadding2D zero_padding2d_27\n",
      "Set for [209]: ZeroPadding1D zero_padding1d_27\n",
      "Warning: different names!\n",
      "Extract for [210]: Conv2D stage3_unit6_conv2\n",
      "Set for [210]: Conv1D stage3_unit6_conv2\n",
      "<class 'list'> 1 (3, 3, 256, 256) (3, 256, 256)\n",
      "Extract for [211]: GlobalAveragePooling2D global_average_pooling2d_12\n",
      "Set for [211]: GlobalAveragePooling1D global_average_pooling1d_12\n",
      "Warning: different names!\n",
      "Extract for [212]: Lambda lambda_28\n",
      "Set for [212]: Lambda lambda_12\n",
      "Warning: different names!\n",
      "Extract for [213]: Conv2D conv2d_24\n",
      "Set for [213]: Conv1D conv1d_24\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 256, 16) (1, 256, 16)\n",
      "(16,) (16,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract for [214]: Activation activation_56\n",
      "Set for [214]: Activation activation_24\n",
      "Warning: different names!\n",
      "Extract for [215]: Conv2D conv2d_25\n",
      "Set for [215]: Conv1D conv1d_25\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 16, 256) (1, 16, 256)\n",
      "(256,) (256,)\n",
      "Extract for [216]: Activation activation_57\n",
      "Set for [216]: Activation activation_25\n",
      "Warning: different names!\n",
      "Extract for [217]: Multiply multiply_28\n",
      "Set for [217]: Multiply multiply_12\n",
      "Warning: different names!\n",
      "Extract for [218]: Add add_28\n",
      "Set for [218]: Add add_12\n",
      "Warning: different names!\n",
      "Extract for [219]: BatchNormalization stage4_unit1_bn1\n",
      "Set for [219]: BatchNormalization stage4_unit1_bn1\n",
      "Extract for [220]: Activation stage4_unit1_relu1\n",
      "Set for [220]: Activation stage4_unit1_relu1\n",
      "Extract for [221]: ZeroPadding2D zero_padding2d_28\n",
      "Set for [221]: ZeroPadding1D zero_padding1d_28\n",
      "Warning: different names!\n",
      "Extract for [222]: Conv2D stage4_unit1_conv1\n",
      "Set for [222]: Conv1D stage4_unit1_conv1\n",
      "<class 'list'> 1 (3, 3, 256, 512) (3, 256, 512)\n",
      "Extract for [223]: BatchNormalization stage4_unit1_bn2\n",
      "Set for [223]: BatchNormalization stage4_unit1_bn2\n",
      "Extract for [224]: Activation stage4_unit1_relu2\n",
      "Set for [224]: Activation stage4_unit1_relu2\n",
      "Extract for [225]: ZeroPadding2D zero_padding2d_29\n",
      "Set for [225]: ZeroPadding1D zero_padding1d_29\n",
      "Warning: different names!\n",
      "Extract for [226]: Conv2D stage4_unit1_conv2\n",
      "Set for [226]: Conv1D stage4_unit1_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [227]: GlobalAveragePooling2D global_average_pooling2d_13\n",
      "Set for [227]: GlobalAveragePooling1D global_average_pooling1d_13\n",
      "Warning: different names!\n",
      "Extract for [228]: Lambda lambda_29\n",
      "Set for [228]: Lambda lambda_13\n",
      "Warning: different names!\n",
      "Extract for [229]: Conv2D conv2d_26\n",
      "Set for [229]: Conv1D conv1d_26\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 512, 32) (1, 512, 32)\n",
      "(32,) (32,)\n",
      "Extract for [230]: Activation activation_58\n",
      "Set for [230]: Activation activation_26\n",
      "Warning: different names!\n",
      "Extract for [231]: Conv2D conv2d_27\n",
      "Set for [231]: Conv1D conv1d_27\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 32, 512) (1, 32, 512)\n",
      "(512,) (512,)\n",
      "Extract for [232]: Activation activation_59\n",
      "Set for [232]: Activation activation_27\n",
      "Warning: different names!\n",
      "Extract for [233]: Multiply multiply_29\n",
      "Set for [233]: Multiply multiply_13\n",
      "Warning: different names!\n",
      "Extract for [234]: Conv2D stage4_unit1_sc\n",
      "Set for [234]: Conv1D stage4_unit1_sc\n",
      "<class 'list'> 1 (1, 1, 256, 512) (1, 256, 512)\n",
      "Extract for [235]: Add add_29\n",
      "Set for [235]: Add add_13\n",
      "Warning: different names!\n",
      "Extract for [236]: BatchNormalization stage4_unit2_bn1\n",
      "Set for [236]: BatchNormalization stage4_unit2_bn1\n",
      "Extract for [237]: Activation stage4_unit2_relu1\n",
      "Set for [237]: Activation stage4_unit2_relu1\n",
      "Extract for [238]: ZeroPadding2D zero_padding2d_30\n",
      "Set for [238]: ZeroPadding1D zero_padding1d_30\n",
      "Warning: different names!\n",
      "Extract for [239]: Conv2D stage4_unit2_conv1\n",
      "Set for [239]: Conv1D stage4_unit2_conv1\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [240]: BatchNormalization stage4_unit2_bn2\n",
      "Set for [240]: BatchNormalization stage4_unit2_bn2\n",
      "Extract for [241]: Activation stage4_unit2_relu2\n",
      "Set for [241]: Activation stage4_unit2_relu2\n",
      "Extract for [242]: ZeroPadding2D zero_padding2d_31\n",
      "Set for [242]: ZeroPadding1D zero_padding1d_31\n",
      "Warning: different names!\n",
      "Extract for [243]: Conv2D stage4_unit2_conv2\n",
      "Set for [243]: Conv1D stage4_unit2_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [244]: GlobalAveragePooling2D global_average_pooling2d_14\n",
      "Set for [244]: GlobalAveragePooling1D global_average_pooling1d_14\n",
      "Warning: different names!\n",
      "Extract for [245]: Lambda lambda_30\n",
      "Set for [245]: Lambda lambda_14\n",
      "Warning: different names!\n",
      "Extract for [246]: Conv2D conv2d_28\n",
      "Set for [246]: Conv1D conv1d_28\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 512, 32) (1, 512, 32)\n",
      "(32,) (32,)\n",
      "Extract for [247]: Activation activation_60\n",
      "Set for [247]: Activation activation_28\n",
      "Warning: different names!\n",
      "Extract for [248]: Conv2D conv2d_29\n",
      "Set for [248]: Conv1D conv1d_29\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 32, 512) (1, 32, 512)\n",
      "(512,) (512,)\n",
      "Extract for [249]: Activation activation_61\n",
      "Set for [249]: Activation activation_29\n",
      "Warning: different names!\n",
      "Extract for [250]: Multiply multiply_30\n",
      "Set for [250]: Multiply multiply_14\n",
      "Warning: different names!\n",
      "Extract for [251]: Add add_30\n",
      "Set for [251]: Add add_14\n",
      "Warning: different names!\n",
      "Extract for [252]: BatchNormalization stage4_unit3_bn1\n",
      "Set for [252]: BatchNormalization stage4_unit3_bn1\n",
      "Extract for [253]: Activation stage4_unit3_relu1\n",
      "Set for [253]: Activation stage4_unit3_relu1\n",
      "Extract for [254]: ZeroPadding2D zero_padding2d_32\n",
      "Set for [254]: ZeroPadding1D zero_padding1d_32\n",
      "Warning: different names!\n",
      "Extract for [255]: Conv2D stage4_unit3_conv1\n",
      "Set for [255]: Conv1D stage4_unit3_conv1\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [256]: BatchNormalization stage4_unit3_bn2\n",
      "Set for [256]: BatchNormalization stage4_unit3_bn2\n",
      "Extract for [257]: Activation stage4_unit3_relu2\n",
      "Set for [257]: Activation stage4_unit3_relu2\n",
      "Extract for [258]: ZeroPadding2D zero_padding2d_33\n",
      "Set for [258]: ZeroPadding1D zero_padding1d_33\n",
      "Warning: different names!\n",
      "Extract for [259]: Conv2D stage4_unit3_conv2\n",
      "Set for [259]: Conv1D stage4_unit3_conv2\n",
      "<class 'list'> 1 (3, 3, 512, 512) (3, 512, 512)\n",
      "Extract for [260]: GlobalAveragePooling2D global_average_pooling2d_15\n",
      "Set for [260]: GlobalAveragePooling1D global_average_pooling1d_15\n",
      "Warning: different names!\n",
      "Extract for [261]: Lambda lambda_31\n",
      "Set for [261]: Lambda lambda_15\n",
      "Warning: different names!\n",
      "Extract for [262]: Conv2D conv2d_30\n",
      "Set for [262]: Conv1D conv1d_30\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 512, 32) (1, 512, 32)\n",
      "(32,) (32,)\n",
      "Extract for [263]: Activation activation_62\n",
      "Set for [263]: Activation activation_30\n",
      "Warning: different names!\n",
      "Extract for [264]: Conv2D conv2d_31\n",
      "Set for [264]: Conv1D conv1d_31\n",
      "Warning: different names!\n",
      "<class 'list'> 2 (1, 1, 32, 512) (1, 32, 512)\n",
      "(512,) (512,)\n",
      "Extract for [265]: Activation activation_63\n",
      "Set for [265]: Activation activation_31\n",
      "Warning: different names!\n",
      "Extract for [266]: Multiply multiply_31\n",
      "Set for [266]: Multiply multiply_15\n",
      "Warning: different names!\n",
      "Extract for [267]: Add add_31\n",
      "Set for [267]: Add add_15\n",
      "Warning: different names!\n",
      "Extract for [268]: BatchNormalization bn1\n",
      "Set for [268]: BatchNormalization bn1\n",
      "Extract for [269]: Activation relu1\n",
      "Set for [269]: Activation relu1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model 1D: seresnet50 Mem single: 0.23\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/seresnet50_imagenet_1000_no_top.h5\n",
      "  4112384/104934688 [>.............................] - ETA: 14s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete or corrupted file detected. The md5 file hash does not match the provided value of 043777781b0d5ca756474d60bf115ef1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 278>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[43mconvert_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     gen_text_with_links()\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mconvert_models\u001b[1;34m()\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     model2D, preprocess_input \u001b[38;5;241m=\u001b[39m Classifiers_2D\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m--> 223\u001b[0m     model2D \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_size_2D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m mem \u001b[38;5;241m=\u001b[39m get_model_memory_usage(\u001b[38;5;241m1\u001b[39m, model2D)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 2D: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Mem single: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(t, mem))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\classification_models\\models_factory.py:78\u001b[0m, in \u001b[0;36mModelsFactory.inject_submodules.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m modules_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_kwargs()\n\u001b[0;32m     77\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(modules_kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\classification_models\\models\\senet.py:363\u001b[0m, in \u001b[0;36mSEResNet50\u001b[1;34m(input_shape, input_tensor, weights, classes, include_top, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSEResNet50\u001b[39m(input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, input_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SENet(\n\u001b[0;32m    364\u001b[0m         MODELS_PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseresnet50\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    365\u001b[0m         input_shape\u001b[38;5;241m=\u001b[39minput_shape,\n\u001b[0;32m    366\u001b[0m         input_tensor\u001b[38;5;241m=\u001b[39minput_tensor,\n\u001b[0;32m    367\u001b[0m         include_top\u001b[38;5;241m=\u001b[39minclude_top,\n\u001b[0;32m    368\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    369\u001b[0m         weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    371\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\classification_models\\models\\senet.py:319\u001b[0m, in \u001b[0;36mSENet\u001b[1;34m(model_params, input_tensor, input_shape, include_top, classes, weights, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m         model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m         load_model_weights(model, model_params\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    320\u001b[0m                            weights, classes, include_top, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\classification_models\\weights.py:25\u001b[0m, in \u001b[0;36mload_model_weights\u001b[1;34m(model, model_name, dataset, classes, include_top, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m classes:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` and `include_top`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as true, `classes` should be \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m---> 25\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmd5_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmd5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py:298\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    296\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fpath) \u001b[38;5;129;01mand\u001b[39;00m file_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validate_file(fpath, file_hash, algorithm\u001b[38;5;241m=\u001b[39mhash_algorithm):\n\u001b[1;32m--> 298\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    299\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncomplete or corrupted file detected. The \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    300\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile hash does not match the provided value of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m untar:\n\u001b[0;32m    303\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(untar_fpath):\n",
      "\u001b[1;31mValueError\u001b[0m: Incomplete or corrupted file detected. The md5 file hash does not match the provided value of 043777781b0d5ca756474d60bf115ef1."
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "\n",
    "    gpu_use = 4\n",
    "    print('GPU use: {}'.format(gpu_use))\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(gpu_use)\n",
    "\n",
    "\n",
    "# tf keras\n",
    "from tensorflow.keras import backend as K\n",
    "from classification_models.tfkeras import Classifiers as Classifiers_2D\n",
    "from classification_models_1D.tfkeras import Classifiers as Classifiers_1D\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.efficientnet import EfficientNetB1\n",
    "from keras.applications.efficientnet import EfficientNetB2\n",
    "from keras.applications.efficientnet import EfficientNetB3\n",
    "from keras.applications.efficientnet import EfficientNetB4\n",
    "from keras.applications.efficientnet import EfficientNetB5\n",
    "from keras.applications.efficientnet import EfficientNetB6\n",
    "from keras.applications.efficientnet import EfficientNetB7\n",
    "from keras.applications.efficientnet_v2 import *\n",
    "\n",
    "print('Use TF keras...')\n",
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODELS_PATH = './'\n",
    "OUTPUT_PATH_CONVERTER = MODELS_PATH + 'converter/'\n",
    "if not os.path.isdir(OUTPUT_PATH_CONVERTER):\n",
    "    os.mkdir(OUTPUT_PATH_CONVERTER)\n",
    "\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        out_shape = l.output_shape\n",
    "        if type(out_shape) is list:\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "        number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "        number_size = 8.0\n",
    "\n",
    "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes\n",
    "\n",
    "\n",
    "def convert_weights(m2, m1, kernel_size, out_path):\n",
    "    print('Start: {}'.format(m2.name))\n",
    "    for i in range(len(m2.layers)):\n",
    "        layer_2D = m2.layers[i]\n",
    "        layer_1D = m1.layers[i]\n",
    "        print('Extract for [{}]: {} {}'.format(i, layer_2D.__class__.__name__, layer_2D.name))\n",
    "        print('Set for [{}]: {} {}'.format(i, layer_1D.__class__.__name__, layer_1D.name))\n",
    "\n",
    "        if layer_2D.name != layer_1D.name:\n",
    "            print('Warning: different names!')\n",
    "\n",
    "        weights_2D = layer_2D.get_weights()\n",
    "        weights_1D = layer_1D.get_weights()\n",
    "        if layer_2D.__class__.__name__ == 'Conv2D' or \\\n",
    "                layer_2D.__class__.__name__ == 'DepthwiseConv2D':\n",
    "            print(type(weights_2D), len(weights_2D), weights_2D[0].shape, weights_1D[0].shape)\n",
    "\n",
    "            # Weights\n",
    "            weights_1D[0][...] = 0\n",
    "            for j in range(weights_1D[0].shape[-2]):\n",
    "                if weights_2D[0].shape[0]*weights_2D[0].shape[1] == weights_1D[0].shape[0]:\n",
    "                    # Case when we flatten weights (e.g. kernel size for 1D == 9)\n",
    "                    part = weights_2D[0][:, :, j, :].reshape((weights_2D[0].shape[0]*weights_2D[0].shape[1], weights_2D[0].shape[-1]))\n",
    "                else:\n",
    "                    # Case when we use sum of weights (e.g. kernel size for 1D == 3)\n",
    "                    part = weights_2D[0][:, :, j, :].sum(axis=1)\n",
    "\n",
    "                part = (part * weights_2D[0].shape[-2]) / weights_1D[0].shape[-2]\n",
    "                weights_1D[0][:, j, :] = part\n",
    "\n",
    "            # Bias\n",
    "            if len(weights_1D) > 1:\n",
    "                print(weights_1D[1].shape, weights_2D[1].shape)\n",
    "                weights_1D[1] = weights_2D[1][:weights_1D[1].shape[0]]\n",
    "\n",
    "            m1.layers[i].set_weights(weights_1D)\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Ð•ÑÐ»Ð¸ Ð¿ÐµÑ€Ð²Ñ‹Ð¼ ÑÐ»Ð¾ÐµÐ¼ Ð¸Ð´Ñ‘Ñ‚ BatchNormalization. ÐšÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸ Ð¿Ð¾Ð´Ð°ÑŽÑ‚ÑÑ ÐºÐ°Ðº ÐµÑÑ‚ÑŒ \n",
    "            (ÑÐ¿Ñ€Ð°Ð²ÐµÐ´Ð»Ð¸Ð²Ð¾ Ð´Ð»Ñ Resnet). Ð—Ð½Ð°Ñ‡Ð¸Ñ‚ Ð²Ñ…Ð¾Ð´ Ð¾Ñ‚ 0 Ð´Ð¾ 255. Ð—Ð²ÑƒÐº Ð½Ð° Ð¿Ñ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚ÐºÐµ \n",
    "            Ð¾Ñ‚ -1 Ð´Ð¾ 1. Ð”Ð»Ñ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿ÐµÑ€ÐµÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ \n",
    "            gamma1 = gamma2 * 127.5\n",
    "            mean1 = (mean2 - 127.5) / 127.5\n",
    "            \"\"\"\n",
    "            if layer_2D.__class__.__name__ == 'BatchNormalization' and i == 1:\n",
    "                print('Convert first batchNorm layer!')\n",
    "                if len(weights_2D) == 3:\n",
    "                    beta2, run_mean2, run_std2 = weights_2D\n",
    "                    gamma2 = np.ones(len(beta2), dtype=np.float32)\n",
    "                else:\n",
    "                    gamma2, beta2, run_mean2, run_std2 = weights_2D\n",
    "\n",
    "                print(gamma2.shape, beta2.shape, run_mean2.shape, run_std2.shape)\n",
    "                gamma2 = gamma2 * 127.5\n",
    "                run_mean2 = (run_mean2 - 127.5) / 127.5\n",
    "                conf = m1.layers[i].get_config()\n",
    "                print(conf)\n",
    "                conf = m1.layers[i].get_config()\n",
    "                print(conf)\n",
    "                if m1.layers[i].input.shape[-1] <= m2.layers[i].input.shape[-1]:\n",
    "                    gamma2 = gamma2[:m1.layers[i].input.shape[-1]]\n",
    "                    beta2 = beta2[:m1.layers[i].input.shape[-1]]\n",
    "                    run_mean2 = run_mean2[:m1.layers[i].input.shape[-1]]\n",
    "                    run_std2 = run_std2[:m1.layers[i].input.shape[-1]]\n",
    "                m1.layers[i].set_weights([gamma2, beta2, run_mean2, run_std2])\n",
    "            elif layer_2D.__class__.__name__ == 'Normalization' and i == 2:\n",
    "                if len(weights_1D) > 0:\n",
    "                    # EffNet v1\n",
    "                    weights_1D[0] = weights_2D[0][:len(weights_1D[0])]\n",
    "                    weights_1D[1] = weights_2D[1][:len(weights_1D[1])]\n",
    "                    print(weights_2D)\n",
    "                    print(weights_1D)\n",
    "                    m1.layers[i].set_weights(weights_1D)\n",
    "                else:\n",
    "                    # Effnet v2 (it's in parameters)\n",
    "                    pass\n",
    "            else:\n",
    "                m1.layers[i].set_weights(weights_2D)\n",
    "    m1.save(out_path)\n",
    "\n",
    "\n",
    "def convert_models():\n",
    "    include_top = False\n",
    "    shape_size_1D = (224 * 224, 2)\n",
    "    shape_size_2D = (224, 224, 3)\n",
    "    list_to_check = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'seresnet18',\n",
    "                      'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', 'seresnext50',\n",
    "                      'seresnext101', 'senet154', 'resnext50', 'resnext101', 'vgg16', 'vgg19',\n",
    "                      'densenet121', 'densenet169', 'densenet201', 'mobilenet', 'mobilenetv2',\n",
    "                      'EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2',\n",
    "                      'EfficientNetB3', 'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7',\n",
    "                      'EfficientNetV2B0', 'EfficientNetV2B1', 'EfficientNetV2B2', 'EfficientNetV2B3',\n",
    "                      'EfficientNetV2S', 'EfficientNetV2M', 'EfficientNetV2L']\n",
    "\n",
    "    for kernel_size in [3, 9]:\n",
    "        for t in list_to_check:\n",
    "            out_path = MODELS_PATH + 'converter/{}_channel_{}_kernel_{}_top_{}.h5'.format(t, shape_size_1D[-1], kernel_size, include_top)\n",
    "            if os.path.isfile(out_path):\n",
    "                print('Already exists: {}!'.format(out_path))\n",
    "                continue\n",
    "\n",
    "            model1D, preprocess_input = Classifiers_1D.get(t)\n",
    "            model1D = model1D(\n",
    "                include_top=include_top,\n",
    "                weights=None,\n",
    "                input_shape=shape_size_1D,\n",
    "                pooling='avg',\n",
    "                kernel_size=kernel_size,\n",
    "            )\n",
    "            mem = get_model_memory_usage(1, model1D)\n",
    "            print('Model 1D: {} Mem single: {:.2f}'.format(t, mem))\n",
    "\n",
    "            if t in ['EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3',\n",
    "                     'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7']:\n",
    "\n",
    "                func = {\n",
    "                    'EfficientNetB0': EfficientNetB0,\n",
    "                    'EfficientNetB1': EfficientNetB1,\n",
    "                    'EfficientNetB2': EfficientNetB2,\n",
    "                    'EfficientNetB3': EfficientNetB3,\n",
    "                    'EfficientNetB4': EfficientNetB4,\n",
    "                    'EfficientNetB5': EfficientNetB5,\n",
    "                    'EfficientNetB6': EfficientNetB6,\n",
    "                    'EfficientNetB7': EfficientNetB7,\n",
    "                }\n",
    "\n",
    "                model2D = func[t](\n",
    "                    include_top=include_top,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=shape_size_2D,\n",
    "                    pooling='avg',\n",
    "                )\n",
    "            elif t in ['EfficientNetV2B0', 'EfficientNetV2B1', 'EfficientNetV2B2', 'EfficientNetV2B3',\n",
    "                      'EfficientNetV2S', 'EfficientNetV2M', 'EfficientNetV2L']:\n",
    "\n",
    "                func = {\n",
    "                    'EfficientNetV2B0': EfficientNetV2B0,\n",
    "                    'EfficientNetV2B1': EfficientNetV2B1,\n",
    "                    'EfficientNetV2B2': EfficientNetV2B2,\n",
    "                    'EfficientNetV2B3': EfficientNetV2B3,\n",
    "                    'EfficientNetV2S': EfficientNetV2S,\n",
    "                    'EfficientNetV2M': EfficientNetV2M,\n",
    "                    'EfficientNetV2L': EfficientNetV2L,\n",
    "                }\n",
    "\n",
    "                model2D = func[t](\n",
    "                    include_top=include_top,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=shape_size_2D,\n",
    "                    pooling='avg',\n",
    "                )\n",
    "            else:\n",
    "                model2D, preprocess_input = Classifiers_2D.get(t)\n",
    "                model2D = model2D(\n",
    "                    include_top=include_top,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=shape_size_2D,\n",
    "                    pooling='avg',\n",
    "                )\n",
    "            mem = get_model_memory_usage(1, model2D)\n",
    "            print('Model 2D: {} Mem single: {:.2f}'.format(t, mem))\n",
    "            convert_weights(\n",
    "                model2D,\n",
    "                model1D,\n",
    "                kernel_size,\n",
    "                out_path,\n",
    "            )\n",
    "            K.clear_session()\n",
    "\n",
    "\n",
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "def gen_text_with_links():\n",
    "    list_to_check = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'seresnet18',\n",
    "                      'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', 'seresnext50',\n",
    "                      'seresnext101', 'senet154', 'resnext50', 'resnext101', 'vgg16', 'vgg19',\n",
    "                      'densenet121', 'densenet169', 'densenet201', 'mobilenet', 'mobilenetv2',\n",
    "                      'inceptionresnetv2', 'inceptionv3', 'EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2',\n",
    "                      'EfficientNetB3', 'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7',\n",
    "                      'EfficientNetV2B0', 'EfficientNetV2B1', 'EfficientNetV2B2', 'EfficientNetV2B3',\n",
    "                      'EfficientNetV2S', 'EfficientNetV2M', 'EfficientNetV2L']\n",
    "    for model_name in list_to_check:\n",
    "        files = glob.glob('./converter/{}_*.h5'.format(model_name))\n",
    "        for f in files:\n",
    "            file_name = os.path.basename(f)\n",
    "            arr = file_name[:-3].split('_')\n",
    "            m5 = md5(f)\n",
    "\n",
    "            print('# {}'.format(model_name))\n",
    "            print('{')\n",
    "            print('    \\'model\\': \\'{}\\','.format(model_name))\n",
    "            print('    \\'dataset\\': \\'imagenet\\','.format(model_name))\n",
    "            print('    \\'classes\\': 1000,'.format(model_name))\n",
    "            print('    \\'include_top\\': {},'.format(arr[-1]))\n",
    "            print('    \\'kernel_size\\': {},'.format(arr[-3]))\n",
    "            print('    \\'channel\\': {},'.format(arr[-5]))\n",
    "            print('    \\'url\\': \\'https://github.com/ZFTurbo/classification_models_1D/releases/download/v1.0.0/{}\\','.format(file_name))\n",
    "            print('    \\'name\\': \\'{}\\','.format(file_name))\n",
    "            print('    \\'md5\\': \\'{}\\','.format(m5))\n",
    "            print('},')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_models()\n",
    "    gen_text_with_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3aa768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models_1D.tfkeras import Classifiers\n",
    "\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "model = ResNet18(input_shape=(3841, 2), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640a926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
